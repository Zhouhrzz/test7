webpackJsonp([0],{"+Dnu":function(t,e,a){t.exports=a.p+"static/img/nieweizhi.94878c0.jpg"},"+ajF":function(t,e){},"+skl":function(t,e){},"/9p7":function(t,e){},"00Uz":function(t,e,a){"use strict";var i={render:function(){var t=this,e=t.$createElement,i=t._self._c||e;return i("div",[i("Row",{staticClass:"row1"},[i("Col",{staticClass:"col-left",attrs:{span:"14"}},[i("div",[i("a",[i("h2",[t._v("Cross-media Content Understanding")])])]),t._v(" "),i("div",[i("p",{staticClass:"lead",staticStyle:{"margin-top":"30px"}},[i("Icon",{attrs:{type:"ios-square"}}),i("i"),t._v("  Visual semantic concept modeling visual semantic concept modeling."),i("br"),t._v(" "),i("Icon",{attrs:{type:"ios-square"}}),i("i"),t._v("  Visual relation detection and recognition."),i("br"),t._v(" "),i("Icon",{attrs:{type:"ios-square"}}),i("i"),t._v("  Visual humanoid description."),i("br")],1)]),t._v(" "),i("div",[i("p",{staticClass:"introduction"},[t._v("\n          In recent years, with the rapid development of network technology, especially the popularization of public security monitoring system and network video sharing platform, visual data has shown explosive growth. In the era of big data, how to visual information contained in the complex semantics for automatic parsing, to realize semantic concepts from independent recognition to the class, the formation of human natural language description is current research hotspot in the field of computer vision and artificial intelligence, risk prevention for public safety, Internet culture market regulation, and other fields has important application value.\n        ")])])]),t._v(" "),i("Col",{attrs:{span:"10"}},[i("div",[i("a",[i("img",{staticStyle:{height:"304px",width:"457px"},attrs:{src:a("zBUN")}})])])])],1),t._v(" "),i("hr",{staticClass:"research-line",staticStyle:{margin:"70px"}}),t._v(" "),i("Row",{staticClass:"row2"},[i("Col",{staticClass:"col-left",attrs:{span:"14"}},[i("div",[i("a",[i("h2",[t._v("3d Model Retrieval")])])]),t._v(" "),i("div",[i("p",{staticClass:"lead",staticStyle:{"margin-top":"30px"}},[i("Icon",{attrs:{type:"ios-square"}}),i("i"),t._v("  High resolution characterization of multi-view visual features of 3d model."),i("br"),t._v(" "),i("Icon",{attrs:{type:"ios-square"}}),i("i"),t._v("  Similarity measurement between three dimensional models."),i("br")],1)]),t._v(" "),i("div",[i("p",{staticClass:"introduction"},[t._v("\n          In recent years, with the rapid development of multimedia acquisition equipment and 3d modeling technology, the number of 3d models has exploded. According to statistics, there are more than 100 million 3d models in the global manufacturing industry. Especially with the popularization of 3D printing technology, users have a strong demand for 3D models and urgently need convenient access to 3D models. Therefore, driven by the new data, the academia and industry urgently need a new theory of artificial intelligence-based 3d model retrieval to achieve convenient 3d model big data management.\n        ")])])]),t._v(" "),i("Col",{attrs:{span:"10"}},[i("div",[i("a",[i("img",{staticStyle:{width:"457px"},attrs:{src:a("Wo+Z")}})])])])],1),t._v(" "),i("hr",{staticClass:"research-line",staticStyle:{margin:"70px"}}),t._v(" "),i("Row",{staticClass:"row3"},[i("Col",{staticClass:"col-left",attrs:{span:"14"}},[i("div",[i("a",[i("h2",[t._v("Cell Image Analysis")])])]),t._v(" "),i("div",[i("p",{staticClass:"lead",staticStyle:{"margin-top":"30px"}},[i("Icon",{attrs:{type:"ios-square"}}),i("i"),t._v("  Mitosis event recognition."),i("br"),t._v(" "),i("Icon",{attrs:{type:"ios-square"}}),i("i"),t._v("  Mitosis event localization."),i("br"),t._v(" "),i("Icon",{attrs:{type:"ios-square"}}),i("i"),t._v("  Mitosis sequence segmentation."),i("br")],1)]),t._v(" "),i("div",[i("p",{staticClass:"introduction"},[t._v("\n          In recent years, with the development of medical information collection technology, it is often necessary to process a large amount of medical image data in the process of medical diagnosis and biological research. In the era of medical big data, using machine learning methods and artificial intelligence technology to fully analyze and mine massive medical image data will bring new promotion to the development of medical diagnosis and biological research. The cell image analysis group of M2I laboratory focuses on the identification, localization and segmentation of mitotic events in cell microscope images using computer vision and machine learning methods.\n        ")])])]),t._v(" "),i("Col",{attrs:{span:"10"}},[i("div",[i("a",[i("img",{staticStyle:{width:"457px"},attrs:{src:a("bqn7"),height:"304px"}})])])])],1),t._v(" "),i("hr",{staticClass:"research-line",staticStyle:{margin:"70px"}}),t._v(" "),i("Row",{staticClass:"row4"},[i("Col",{staticClass:"col-left",attrs:{span:"14"}},[i("div",[i("a",[i("h2",[t._v("3D Body Reconstruction for Ordinary Users")])])]),t._v(" "),i("div",[i("p",{staticClass:"lead",staticStyle:{"margin-top":"30px"}},[i("Icon",{attrs:{type:"ios-square"}}),i("i"),t._v("  Dress size estimation for the dress image."),i("br"),t._v(" "),i("Icon",{attrs:{type:"ios-square"}}),i("i"),t._v("  3D reconstruction of the human body based on the clothing image."),i("br"),t._v(" "),i("Icon",{attrs:{type:"ios-square"}}),i("i"),t._v("  Convenient 3d human body reconstruction for ordinary users."),i("br")],1)]),t._v(" "),i("div",[i("p",{staticClass:"introduction"},[t._v("\n          In recent years, with the development of medical information collection technology, it is often necessary to process a large amount of medical image data in the process of medical diagnosis and biological research. In the era of medical big data, using machine learning methods and artificial intelligence technology to fully analyze and mine massive medical image data will bring new promotion to the development of medical diagnosis and biological research. The cell image analysis group of M2I laboratory focuses on the identification, localization and segmentation of mitotic events in cell microscope images using computer vision and machine learning methods.\n        ")])])]),t._v(" "),i("Col",{attrs:{span:"10"}},[i("div",[i("a",[i("img",{staticStyle:{width:"457px"},attrs:{src:a("cram"),height:"300px"}})])])])],1),t._v(" "),i("hr",{staticClass:"research-line",staticStyle:{margin:"70px"}}),t._v(" "),i("Row",{staticClass:"row5"},[i("Col",{staticClass:"col-left",attrs:{span:"14"}},[i("div",[i("a",[i("h2",[t._v("Social Media Analysis")])])]),t._v(" "),i("div",[i("p",{staticClass:"lead",staticStyle:{"margin-top":"30px"}},[i("Icon",{attrs:{type:"ios-square"}}),i("i"),t._v("  Tensor Decomposition."),i("br"),t._v(" "),i("Icon",{attrs:{type:"ios-square"}}),i("i"),t._v("  Visual semantic understanding."),i("br")],1)]),t._v(" "),i("div",[i("p",{staticClass:"introduction"},[t._v("\n          With the development of the information age and the update of the needs of The Times, the explosive growth of multimedia visual information, the analysis and understanding of visual semantics gradually come into people's vision. The analysis and understanding of visual semantics are mainly applied to video classification, video recommendation, emotional analysis, visual memory analysis and other environments with practical application value in today's multimedia environment. It USES tools such as tensor decomposition to analyze and process visual information. In the field of tensor decomposition, the laboratory mainly focuses on time series analysis, video sequence classification and so on. In the field of visual semantic understanding, the laboratory mainly focuses on video event detection, emotional analysis of visual information, memory of visual information and so on.\n        ")])])]),t._v(" "),i("Col",{attrs:{span:"10"}},[i("div",[i("a",[i("img",{staticStyle:{width:"457px","margin-top":"40px"},attrs:{src:a("mG6J")}})])])])],1)],1)},staticRenderFns:[]};var s=a("VU/8")({name:"ResearchMenuen"},i,!1,function(t){a("vwFX")},"data-v-126ef636",null);e.a=s.exports},"06nC":function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i=a("byf9"),s=a("6BGy"),n={render:function(){var t=this,e=t.$createElement,i=t._self._c||e;return i("div",{staticClass:"content-box"},[i("div",{staticClass:"breadcrumb"},[i("Breadcrumb",[i("BreadcrumbItem",{attrs:{to:"/home"}},[t._v("主页")]),t._v(" "),i("BreadcrumbItem",{attrs:{to:"/research"}},[t._v("研究方向")]),t._v(" "),i("BreadcrumbItem",[t._v("细胞图像分析")])],1)],1),t._v(" "),i("div",[i("h1",[t._v("    "),i("Icon",{attrs:{type:"ios-fastforward"}}),t._v("  细胞图像分析")],1),t._v(" "),t._m(0)]),t._v(" "),i("Collapse",{staticClass:"collapse",staticStyle:{"font-size":"13px"},model:{value:t.value1,callback:function(e){t.value1=e},expression:"value1"}},[i("Panel",{attrs:{name:"1"}},[t._v("\n        1.简介\n        "),i("p",{staticClass:"me-collapse-content",attrs:{slot:"content"},slot:"content"},[t._v("\n                  近年来，随着医学信息采集技术的发展，在医疗诊断和生物研究的过程当中往往需要处理大量的医学图像数据。在医疗大数据的时代，利用机器学习方法和人工智能技术对海量的医学图像数据进行充分的分析和挖掘，将会对医学诊断和生物研究的发展带来新的促进。M2I实验室细胞图像分析组主要关注利用计算机视觉和机器学习方法对细胞显微镜图像下细胞有丝分裂事件进行识别、定位与分割。\n        ")])]),t._v(" "),i("Panel",{attrs:{name:"2"}},[t._v("\n        2.细胞有丝分裂事件的识别\n        "),i("p",{staticClass:"me-collapse-content",attrs:{slot:"content"},slot:"content"},[i("span",[t._v("\n                      问题描述：对包含有丝分裂事件过程的细胞图像序列进行识别。对于目前细胞显微镜图像数据量大、来源多样的特点，传统的计算机视觉检测方法无法充分利用大数据信息帮助学习有丝分裂细胞的视觉特征表达和动态过程建模。"),i("br"),t._v("\n                          创新：我们提出利用CNN+LSTM深度学习网络，通过将CNN和LSTM深度学习网络进行结合，对有丝分裂过程当中的细胞图像视觉外观特征和时序动态特征进行联合学习，大大提高了当前细胞有丝分裂事件检测方法的准确率和稳定性。从单个细胞图像序列的识别，本方法可以进一步扩展为对整个显微镜图像序列中的有丝分裂事件进行识别和定位。\n            ")]),i("br"),t._v(" "),i("br"),t._v(" "),i("img",{staticClass:"me-img",attrs:{src:a("S0BT"),width:"800px"}}),i("br"),i("br"),t._v(" "),i("img",{staticClass:"me-img",attrs:{src:a("pdB7"),width:"800px"}}),i("br"),i("br")])]),t._v(" "),i("Panel",{attrs:{name:"3"}},[t._v("\n        3.细胞有丝分裂事件的定位\n        "),i("p",{staticClass:"me-collapse-content",attrs:{slot:"content"},slot:"content"},[i("span",[t._v("\n                      问题描述：对有丝分裂细胞图像序列中细胞分裂的时间节点进行准确的定位。由于医学图像数据具有数据量大、数据来源丰富、隐私性的特点，准确的人工标注信息获取相对困难，多变的图像成像条件和细胞形态也为标注信息在不同数据库之间的迁移共享带来困难。"),i("br"),t._v("\n                          创新：针对该问题，我们提出了SSG-DNN深度学习方法，利用弱监督的序列级别标注信息，通过注意力机制充分发掘序列中每帧图像的细胞图像视觉特征关系，从而实现对细胞分裂事件准确的时序定位。在模型训练的过程当中，不需要准确标注细胞图像序列中的每一帧，只需要对序列中是否存在有丝分裂事件进行0/1标注，从而大大减小了人工标注所需的工作量，同时避免了不准确的标注信息所带来的干扰。\n。\n            ")]),i("br"),i("br"),t._v(" "),i("img",{staticClass:"me-img",attrs:{src:a("Cd70"),width:"800px"}}),i("br"),i("br"),t._v(" "),i("img",{staticClass:"me-img",attrs:{src:a("xAkj"),width:"800px"}}),i("br"),i("br")])]),t._v(" "),i("Panel",{attrs:{name:"4"}},[t._v("\n        4.细胞有丝分裂过程分割\n        "),i("p",{staticClass:"me-collapse-content",attrs:{slot:"content"},slot:"content"},[i("span",[t._v("\n                      问题： 通过对显微镜下细胞有丝分裂过程的观察，可以发现细胞有丝分裂过程可以进一步分为四个阶段，每个阶段中的细胞分别具有不同的视觉外观特征。对细胞有丝分裂过程当中的不同阶段进行分割。"),i("br"),t._v("\n                          创新：通过将序列中细胞在有丝分裂过程中不同阶段的状态转换作为半马尔可夫过程(Semi-Markov)进行建模，提出利用SMM (Semi-Markov Model) 图模型的方法对细胞有丝分裂过程当中的四个不同阶段进行分割。\n            ")]),i("br"),i("br"),t._v(" "),i("img",{staticClass:"me-img",attrs:{src:a("2eMu"),width:"800px"}}),i("br"),i("br"),t._v(" "),i("img",{staticClass:"me-img",attrs:{src:a("afHC"),width:"800px"}}),i("br"),i("br")])]),t._v(" "),i("Panel",{attrs:{name:"5"}},[t._v("\n        5.相关论文\n        "),i("p",{staticClass:"me-collapse-content",attrs:{slot:"content"},slot:"content"},[i("span",[t._v("\n[1]\tA. A. Liu, K. Li, and T. Kanade, “A Hierarchical Framework for Mitosis Detection in Time-Lapse Phase Contrast Microscopy Image Sequences of Stem Cell Populations,” IEEE Transactions on Medical Imaging, vol. 31, no. 2, pp. 359–369, 2009."),i("br"),t._v("\n[2]\tA. A. Liu, K. Li, and T. Kanade, “A semi-markov model for mitosis segmentation in time-lapse phase contrast microscopy image sequences of stem cell populations,” IEEE Transactions on Medical Imaging, vol. 31, no. 2, pp. 359–369, 2012."),i("br"),t._v("\n[3] \tA. Liu, T. Hao, Z. Gao, Y. Su, and Z. Yang, “Nonnegative Mixed-Norm Convex Optimization for Mitotic Cell Detection in Phase Contrast Microscopy,” vol. 2013, 2013."),i("br"),t._v('\n[4] \tY. Su, J. Yu, A. Liu, Z. Gao, T. Hao and Z. Yang, "Cell type-independent mitosis event detection via hidden-state conditional neural fields," 2014 IEEE 11th International Symposium on Biomedical Imaging (ISBI), Beijing, 2014, pp. 222-225.'),i("br"),t._v("\n[5]\tA. Liu, Z. Gao, T. Hao, Y. Su, and Z. Yang, “Sparse coding induced transfer learning for HEp-2 cell classification,” Bio-Medical Materials and Engineering, vol. 24, no. 1, pp. 237–243, 2014."),i("br"),t._v("\n[6]\tA. Liu, Y. Lu, W. Nie, Y. Su, and Z. Yang, “HEp-2 cells Classification via clustered multi-task learning,” Neurocomputing, vol. 195, pp. 195–201, 2016."),i("br"),t._v("\n[7]\tWei-Zhi Nie, Wei-Hui Li, An-An Liu, Tong Hao, Yu-Ting Su, “3D Convolutional Networks-Based Mitotic Event Detection in Time-Lapse Phase Contrast Microscopy Image Sequences of Stem Cell Populations,” The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, 2016, pp. 55-62 pp. 1–8, 2016."),i("br"),t._v("\n[8]\tA.-A. Liu, Y. Lu, M. Chen, and Y. Su, “Mitosis Detection in Phase Contrast Microscopy Image Sequences of Stem Cell Populations: A Critical Review,” IEEE Transactions on Big Data, vol. 3, no. 4, pp. 1–1, 2017."),i("br"),t._v("\n[9]\tA. A. Liu, J. Tang, W. Nie, and Y. Su, “Multi-grained random fields for mitosis identification in time-lapse phase contrast microscopy image sequences,” IEEE Transactions on Medical Imaging, vol. 36, no. 8, pp. 1699–1710, 2017."),i("br"),t._v('\n[10] Y. Su, Y. Lu, M. Chen and A. Liu, "Spatiotemporal Joint Mitosis Detection Using CNN-LSTM Network in Time-Lapse Phase Contrast Microscopy Images," in IEEE Access, vol. 5, pp. 18033-18041, 2017. doi: 10.1109/ACCESS.2017.2745544'),i("br"),t._v('\n[11] Y. Lu, A. Liu, M. Chen, W. Nie and Y. Su, "Sequential Saliency Guided Deep Neural Network for Joint Mitosis Identification and Localization in Time-Lapse Phase Contrast Microscopy Images," in IEEE Journal of Biomedical and Health Informatics.'),i("br")]),i("br"),i("br")])]),t._v(" "),i("Panel",{attrs:{name:"6"}},[t._v("\n        6.数据库介绍\n        "),i("p",{staticClass:"me-collapse-content",attrs:{slot:"content"},slot:"content"},[i("span",[t._v("\n              C2C12-16数据库："),i("br"),t._v("\n                          针对当前相差显微镜下细胞有丝分裂事件检测的数据库规模较小的问题，我们在记录小鼠C2C12肌肉干细胞培养过程的16个相差显微镜图像序列上对其中的细胞有丝分裂事件进行了人工标注，得到了目前最大的相差显微镜细胞分裂检测数据库。"),i("br"),t._v("\n                          相对于目前常用的C2C12数据库（在1个C2C12细胞显微镜图像序列中包含679个标注的有丝分裂事件）和C3H10数据库（在5个C3H10细胞显微镜图像序列中共包含409个标注的有丝分裂事件），新提出的C2C12-16数据库包含更多的相差显微镜图像(16×1013张1392×1040分辨率的16位深度显微镜图像)和更多标注的有丝分裂事件（共7159个标注的有丝分裂事件），能够有效地促进细胞有丝分裂事件检测方法的研究在大数据时代下的发展。\n通过在细胞培养过程当中加入不同的生长因子，数据库中的细胞培养环境可分为4组。数据库中的16个细胞图像序列因此可以进一步按照细胞的培养环境分为4组，在每组的4个序列当中，细胞图像呈现不同的外观特征，进一步提高了细胞有丝分裂检测任务的挑战性。\n            ")]),i("br"),i("br"),t._v(" "),i("img",{staticClass:"me-img",attrs:{src:a("NQ74"),width:"800px"}}),i("br"),i("br")])]),t._v(" "),i("Panel",{attrs:{name:"6"}},[t._v("\n        6.比赛网址\n        "),i("p",{staticClass:"me-collapse-content",attrs:{slot:"content"},slot:"content"},[i("span",[t._v("\n                      在提出的C2C12-16数据库的基础上，我们在2018年CVPR CVMI (Computer Vision for Microscopy Image Analysis) workshop 上举办了相差显微镜下细胞有丝分裂事件检测比赛。比赛网址为：\n            ")]),i("br"),i("br"),t._v(" "),i("a",{attrs:{href:"http://media.m2i.ac.cn/mitosisdetection/"}},[t._v("http://media.m2i.ac.cn/mitosisdetection/")])])])],1)],1)},staticRenderFns:[function(){var t=this.$createElement,e=this._self._c||t;return e("p",{staticClass:"research-people"},[e("span",[this._v("团队成员")]),e("br"),this._v(" "),e("span",[e("a",{attrs:{href:"/"}},[this._v("刘安安（教授）")]),e("br"),this._v("\n               路    遥（博士生）"),e("br"),this._v("\n               田宏硕（博士生）    李佳玉（博士生）"),e("br")])])}]};var o={name:"research3",components:{ResearchThreeContent:a("VU/8")({name:"ResearchOneContent"},n,!1,function(t){a("cihS")},"data-v-813ded3e",null).exports,HomeFooter:s.a,HomeHeader:i.a},data:function(){return{activeIndex:"/research/research3"}},methods:{myajaxs:function(){this.$axios({method:"post",url:"/research3"}).then(function(t){console.log(t)}).catch(function(t){console.log(t)})}}},r={render:function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("Layout",[e("Header",{staticStyle:{position:"fixed",right:"0",left:"0","z-index":"1030"}},[e("home-header",{attrs:{"active-name":this.activeIndex}})],1),this._v(" "),e("Content",[e("research-three-content")],1),this._v(" "),e("Footer",[e("home-footer")],1)],1)],1)},staticRenderFns:[]};var l=a("VU/8")(o,r,!1,function(t){a("S0lg")},"data-v-661df5ae",null);e.default=l.exports},"0nMg":function(t,e){},"1uv5":function(t,e){},"1wS6":function(t,e){},"1xpz":function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i=a("E7Bq"),s=a("6BGy"),n={render:function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"content-box"},[a("Row",[a("Col",{attrs:{span:"6"}},[a("Menu",{staticClass:"menu",staticStyle:{width:"200px","background-color":"rgb(245, 247, 249)","margin-top":"50px"},attrs:{theme:"light","active-name":"1"}},[a("MenuItem",{attrs:{name:"1",to:"/publication/publication2019English"}},[a("Icon",{attrs:{type:"md-document"}}),t._v("\n          2019\n        ")],1),t._v(" "),a("MenuItem",{attrs:{name:"2",to:"/publication/publication2018English"}},[a("Icon",{attrs:{type:"md-document"}}),t._v("\n          2018\n        ")],1),t._v(" "),a("MenuItem",{attrs:{name:"3",to:"/publication/publication2017English"}},[a("Icon",{attrs:{type:"md-document"}}),t._v("\n          2017\n        ")],1),t._v(" "),a("MenuItem",{attrs:{name:"4",to:"/publication/publication2016English"}},[a("Icon",{attrs:{type:"md-document"}}),t._v("\n          2016\n        ")],1)],1)],1),t._v(" "),a("Col",{attrs:{span:"18"}},[a("div",{staticClass:"education"},[a("div",{staticClass:"education-block"},[a("h3"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Dual-Level Embedding Alignment Network for 2D Image-Based 3D Object Retrieval")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Heyu Zhou, An-An Liu, Weizhi Nie")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("ACM International Conference on Multimedia, MM 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://acmmm.org/accepted-papers/"}},[t._v("Link")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("MMJN: Multi-Modal Joint Networks for 3D Shape Recognition")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Weizhi Nie, Qi Liang, An-An Liu, Zhendong Mao, Yangyang Li")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("ACM International Conference on Multimedia, MM 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://acmmm.org/accepted-papers/"}},[t._v("Link")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Meta-Transfer Learning for Few-Shot Learning")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Qianru Sun, Yaoyao Liu, Tat-Seng Chua, Bernt Schiele")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE International Conference on Computer Vision and Pattern Recognition, CVPR 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"http://openaccess.thecvf.com/content_CVPR_2019/papers/Sun_Meta-Transfer_Learning_for_Few-Shot_Learning_CVPR_2019_paper.pdf"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Learning to Self-Train for Semi-Supervised Few-Shot Classification")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Xinzhe Li, Qianru Sun, Yaoyao Liu, Shibao Zheng, Qin Zhou, Tat-Seng Chua, Bernt Schiele")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("33rd Conference on Neural Information Processing Systems, NeurIPS 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://arxiv.org/pdf/1906.00562.pdf"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("SHREC 2019-Monocular Image Based 3D Model Retrieval")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Wenhui Li, Anan Liu, Weizhi Nie, Dan Song, Yuqian Li, Weijie Wang, Shu Xiang, Heyu Zhou, et al.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("3D Shape Retrieval Contest, Eurographics Workshop on 3D Object Retrieval, 2019")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://pdfs.semanticscholar.org/7a86/b957168093f1da829e252ba4a4a0faea24f8.pdf"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Hierarchical Deep Neural Network for Image Captioning")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Yuting Su, Yuqian Li, Ning Xu, An-An Liu")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("Neural Processing Letters, 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://link.springer.com/content/pdf/10.1007%2Fs11063-019-09997-5.pdf"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Multi-Guiding Long-Short Term Memory for Video Captioning")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Ning Xu, An-An Liu, Weizhi Nie, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("Multimedia Systems, 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://link.springer.com/article/10.1007%2Fs00530-018-0598-5"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Multi-Domain and Multi-Task Learning for Human Action Recognition")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Ning Xu, Weizhi Nie, Yuting Su, Yongdong Zhang")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Image Processing, TIP 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8476540"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Scene Graph Captioner: Image Captioning Based on Structural Visual Representation")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Ning Xu, An-An Liu, Jing Liu, Weizhi Nie, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("Journal of Visual Communication and Image Representation, 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://www.sciencedirect.com/science/article/pii/S1047320318303535"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Scene Graph Captioner: Image Captioning Based on Structural Visual Representation")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Ning Xu, An-An Liu, Jing Liu, Weizhi Nie, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("Journal of Visual Communication and Image Representation, 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://www.sciencedirect.com/science/article/pii/S1047320318303535"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Sequential Saliency Guided Deep Neural Network for Joint Mitosis Identification and Localization in Time-Lapse Phase Contrast Microscopy Images")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Yao Lu, An-An Liu, Mei Chen, Weizhi Nie, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Journal of Biomedical and Health Informatics, JBHI 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8846748/"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("3D Object Retrieval Based on Multi-View Latent Variable Model")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Weizhi Nie, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Circuits and Systems for Video Technology, TCSVT 2019")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8303699"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Hyper-Clique Graph Matching and Applications")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Weizhi Nie, An-An Liu, Yue Gao, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Circuits and Systems for Video Technology, TCSVT 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8401899"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("BE-CALF: Bit-Depth Enhancement by Concatenating All Level Features of DNN")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jing Liu, Wanning Sun, Yuting Su, Peiguang Jing, Xiaokang Yang")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Image Processing, TIP 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8713480"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Spatiotemporal Symmetric Convolutional Neural Network for Video Bit-Depth Enhancement.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jing Liu, Pingping Liu, Yuting Su, Peiguang Jing, Xiaokang Yang.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Multimedia, TMM 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8703748"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Wearable Computing for Internet of Things: A Discriminant Approach for Human Activity Recognition.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Wei Lu, Fugui Fan, Jinghui Chu, Peiguang Jing, Yuting Su.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Internet of Things Journal, 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8480641"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("High-Order Temporal Correlation Model Learning for Time-Series Prediction.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Peiguang Jing, Yuting Su, Xiao Jin, Chengqian Zhang")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Cybernetics, TCYB 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8359393"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("A Framework of Joint Low-Rank and Sparse Regression for Image Memorability Prediction.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Peiguang Jing, Yuting Su, Liqiang Nie, Huimin Gu, Jing Liu, Meng Wang ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Circuits and Systems for Video Technology, TCSVT 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8359393"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Dual-Stream Recurrent Neural Network for Video Captioning.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Ning Xu, An-An Liu, Yongkang Wong, Yongdong Zhang, Weizhi Nie, Yuting Su, Mohan S. Kankanhalli.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Circuits and Systems for Video Technology, TCSVT 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8359393"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("End-to-End Visual Domain Adaptation Network for Cross-Domain 3D CPS Data Retrieval.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Shu Xiang, Wei-Zhi Nie, Dan Song.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access, 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8812718"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Fast Context-Adaptive Bit-Depth Enhancement via Linear Interpolation")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jing Liu, Bing Yang, Yuting Su, Pingping Liu")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access, 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8703748"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Unsupervised Feature Learning With Graph Embedding for View-Based 3D Model Retrieval")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Yuting Su, Wenhui Li, Weizhi Nie, Dan Song, An-An Liu")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access, 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8770249"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("SRNet: Structured Relevance Feature Learning Network From Skeleton Data for Human Action Recognition")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Weizhi Nie, Wei Wang, Xiangdong Huang")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access, 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8832127"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br")])])])],1)],1)},staticRenderFns:[]};var o={name:"publication2019English",components:{Publication2019Contenten:a("VU/8")({name:"Publication2019Contenten"},n,!1,function(t){a("i7es")},"data-v-f12dea18",null).exports,HomeFooter:s.a,HomeHeaderen:i.a},methods:{myajaxs:function(){this.$axios({method:"post",url:"/publication/publication2019English"}).then(function(t){console.log(t)}).catch(function(t){console.log(t)})}}},r={render:function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("Layout",[e("Header",{staticStyle:{position:"fixed",right:"0",left:"0","z-index":"1030"}},[e("home-headeren",{attrs:{"active-name":this.activeIndex}})],1),this._v(" "),e("Content",[e("publication2019-contenten")],1),this._v(" "),e("Footer",[e("home-footer")],1)],1)],1)},staticRenderFns:[]};var l=a("VU/8")(o,r,!1,function(t){a("/9p7")},"data-v-867b73d2",null);e.default=l.exports},"2/Ij":function(t,e){},"24ZX":function(t,e,a){t.exports=a.p+"static/img/research2-1.23b69dc.jpg"},"26uN":function(t,e,a){t.exports=a.p+"static/img/research4-1.8d2ba01.jpg"},"270D":function(t,e){},"2Da8":function(t,e){},"2e2M":function(t,e){},"2eMu":function(t,e,a){t.exports=a.p+"static/img/research3-5.38d9251.jpg"},"2fq6":function(t,e,a){t.exports=a.p+"static/img/liujing.6bf746c.jpg"},"2iX+":function(t,e,a){t.exports=a.p+"static/img/李佳玉.a34c3aa.jpg"},"2iZJ":function(t,e){},"3Oue":function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i=a("byf9"),s={render:function(){var t=this,e=t.$createElement,i=t._self._c||e;return i("div",[i("div",{staticClass:"breadcrumb"},[i("Breadcrumb",[i("BreadcrumbItem",{attrs:{to:"/"}},[t._v("主页")]),t._v(" "),i("BreadcrumbItem",{attrs:{to:"/people"}},[t._v("团队")]),t._v(" "),i("BreadcrumbItem",[t._v("刘安安")])],1)],1),t._v(" "),i("div",{staticClass:"content-box"},[i("div",[i("Row",[i("Col",{attrs:{span:"5"}},[i("div",{staticClass:"people-img"},[i("img",{attrs:{src:a("3gOL"),width:"143px",height:"189px"}})])]),t._v(" "),i("Col",{attrs:{span:"19"}},[i("div",{staticClass:"people-intro"},[i("span",{staticStyle:{"font-size":"23px",color:"black","font-weight":"bold"}},[t._v("刘安安")]),i("span",{staticStyle:{"padding-left":"20px"}},[t._v("教授/博导")]),i("br"),i("br"),t._v(" "),i("span",[t._v("电气自动化与信息工程学院")]),i("br"),t._v(" "),i("span",[t._v("天津大学")]),i("br"),t._v(" "),i("span",[t._v("邮箱： anan0422@gmail.com")]),i("br")])])],1)],1),t._v(" "),t._m(0),t._v(" "),t._m(1)])])},staticRenderFns:[function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",[a("h2",[t._v("简    介")]),t._v(" "),a("hr",{staticClass:"research-line",staticStyle:{margin:"15px 0"}}),t._v(" "),a("span",{staticClass:"content"},[t._v("03/2010至今，天津大学电气自动化与信息工程学院，电子信息工程系"),a("br"),t._v("\n      03/2016-03/2017  访问学者，新加坡国立大学,计算机学院, 导师: Mohan Kankanhalli (IEEE Fellow)"),a("br"),t._v("\n      09/2008-11/2009  访问学者，美国卡耐机.梅隆大学,计算机学院机器人所, 导师: Takeo Kanade (IEEE/ACM/AAAI Fellow)"),a("br"),t._v("\n      05/2009-11/2009  访问研究员，Intel匹兹堡研究中心，导师：Dr. Mei Chen"),a("br"),t._v("\n      09/2001-03/2010  本硕博连读, 天津大学,电子信息工程学院\n      ")])])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",[a("h2",[t._v("论    文")]),t._v(" "),a("hr",{staticClass:"research-line",staticStyle:{margin:"15px 0"}}),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7423818"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[1]  Hierarchical Clustering Multi-Task Learning for Joint Human Action Grouping and Recognition.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("  An-An Liu, Yu-Ting Su, Wei-Zhi Nie, Mohan Kankanhalli ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Pattern Analysis and Machine Intelligence., Vol. 39, No.1, pp:102-114, 2017. (ESI 热点；ESI高被引；SCI一区，CCF-A, JCR: 9.455)")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7430305"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[2]   Multi-modal clique-graph matching for view-based 3D model retrieval")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" An-An Liu, Wei-Zhi Nie, Yue-Gao , Yu-Ting Su.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Image Processing, vol. 25, no. 5, pp. 2103–2116, 2016. (ESI 热点；ESI高被引；SCI二区，CCF-A, JCR: 5.072)")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://www.ncbi.nlm.nih.gov/pubmed/27429453"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[3]  Benchmarking a Multimodal and Multiview and Interactive Dataset for Human Action Recognition.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" An-An Liu, Ning Xu, Wei-Zhi Nie, Yu-Ting Su, Yongkang Wong, Kankanhalli M.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Cybernetics, Vol. 47, No.7, pp:1781-1794,2017.( ESI高被引；SCI一区，CCF-B, JCR: 8.803)")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://www.ncbi.nlm.nih.gov/pubmed/25167566"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[4]  Multipe/Single-View Human Action Recognition via Part-induced Multi-task Structural Learning.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" An-An Liu, Yu-Ting Su, Ping-Ping Jia, Zan Gao,Tong Hao, Zhao-Xuan Yang ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Cybernetics, Vol. 45, No. 6, pp. 1194-1208, 2015.  (ESI高被引；SCI一区，CCF-B, JCR: 8.803)")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7857115"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[5]  View-Based 3-D Model Retrieval: A Benchmark")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Wei-Zhi Nie, Yue Gao, Yu-Ting Su.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Cybernetics, Vol. 48, No.3, pp:916-928,2018. (SCI一区，CCF-B, JCR: 8.803)")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8476540"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[6]  Multi-Domain and Multi-Task Learning for Human Action Recognition")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" An-An Liu, Ning Xu,Wei-Zhi Nie, Yu-Ting Su, Yong-Dong Zhang ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Image Processing, Vol. 28, No. 2, pp. 853-867, 2019. (SCI二区，CCF-A, JCR: 5.072)")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7885509"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[7]  Multi-Grained Random Fields for Mitosis Identification in Time-Lapse Phase Contrast Microscopy Image Sequences.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" An-An Liu, Jinhui Tang, Weizhi Nie, Yuting Su ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("  IEEE Transactions on Medical Imaging, Vol.36, No.8, pp:1699-1710, 2017. (SCI二区，CCF-B, JCR: 6.131)")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/6026949"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[8]  A Semi-Markov Model for Mitosis Segmentation in Time-Lapse Phase Contrast Microscopy Image Sequences of Stem Cell Populations")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("  An-An Liu, Kang Li, Takeo Kanade ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Medical Imaging,  Vol. 31, No. 2, pp. 359-369, 2012. (SCI二区，CCF-B, JCR: 6.131)")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8303699"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[9]  3D Object Retrieval Based on Multi-View Latent Variable Model")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("  An-An Liu, Wei-Zhi Nie, Yu-Ting Su ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("  IEEE Transactions on Circuits and Systems for Video Technology，2018 (DOI: 10.1109/TCSVT.2018.2810191) (SCI 二区，CCF-B,JCR: 3.599)")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8401899"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[10]  Hyper-Clique Graph Matching and Applications")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" Wei-Zhi Nie, An-An Liu, Yue Gao, Yu-Ting Su ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Circuits and Systems for Video Technology，2018  (SCI 二区，CCF-B,JCR: 3.599)")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8447210"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[11]   Dual-Stream Recurrent Neural Network for Video Captioning")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" Ning Xu, An-An Liu, Yongkang Wong, Yongdong Zhang, Weizhi Nie, Yuting Su,Mohan Kankanhalli")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Circuits and Systems for Video Technology，2018  (SCI 二区，CCF-B,JCR: 3.599)")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8141866"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[12]    Attention-In-Attention Networks for Surveillance Video Understanding in IoT")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" Ning Xu, An-An Liu, Wei-Zhi Nie, Yu-Ting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Internet of Thing Journal,Vol.5, No.5, pp.3419-3429, 2018 (SCI 一区，JCR: 6.735)")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7962189"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[13]   Mitosis Detection in Phase Contrast Microscopy Image Sequences of Stem Cell Populations: A Critical Review")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" An-An Liu, Yao Lu, Mei Chen, Yu-Ting Su ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Big Data, Vol. 3, No. 4, pp. 443-457,  2017 ")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://www.sciencedirect.com/science/article/pii/S1077314217300735"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[14]   Hierarchical & Multimodal Video Captioning: Discovering and Transferring Multimodal Knowledge for Vision to Language")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-AnLiu, Ning Xu, Yongkang Wong, Junnan Li, Yu-Ting Su, Mohan Kankanhalli")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" Computer Vision and Image Understanding, vol. 163, pp. 113-125, 2017")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7299080"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[15]   Clique-graph Matching by Preserving Global & Local Structure")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" Wei-Zhi Nie, An-An Liu, Zan Gao, Yu-Ting Su ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("  IEEE Conference on Computer Vision and Pattern Recognition,4503-4510,2015. ")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://www.ijcai.org/proceedings/2018/115"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[16]   Cross-Domain 3D Model Retrieval via Visual Domain Adaption")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" Anan Liu, Shu Xiang, Wenhui Li, Weizhi Nie, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("  International Joint Conference on Artificial Intelligence, 2018 ")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8844130"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[17]    Multi-Level Policy and Reward Reinforcement Learning for Image Captioning")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("  Ning Xu， Hanwang Zhang， An-An Liu， Weizhi Nie, Yuting Su, Jie Nie, Yongdong Zhang ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" International Joint Conference on Artificial Intelligence, 2018 ")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://www.ijcai.org/proceedings/2018/127"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[18]   Hierarchical Graph Structure Learning for Multi-View 3D Model Retrieval")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" Yuting Su, Wenhui Li, Anan Liu, Weizhi Nie")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" International Joint Conference on Artificial Intelligence, 2018 ")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://www.intechopen.com/books/medical-imaging/a-hierarchical-framework-for-mitosis-detection-in-time-lapse-phase-contrast-microscopy-image-sequenc"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[19]   A Hierarchical Framework for Mitosis Detection in Time-Lapse Phase Contrast Microscopy Image Sequences of Stem Cell Populations.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" Anan Liu, Kang Li")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" Medical Imaging (Chapter 17)，Dec. 2011 (ISBN 978-953-307-774-1)")])])])])}]};var n=a("VU/8")({name:"LiuananContent"},s,!1,function(t){a("nqWu")},"data-v-4be78c66",null).exports,o={name:"liuanan",components:{HomeFooter:a("6BGy").a,LiuananContent:n,HomeHeader:i.a},data:function(){return{activeIndex:"/people"}},methods:{myajaxs:function(){this.$axios({method:"post",url:"/people/liuanan"}).then(function(t){console.log(t)}).catch(function(t){console.log(t)})}}},r={render:function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("Layout",[e("Header",{staticStyle:{position:"fixed",right:"0",left:"0","z-index":"1030"}},[e("home-header",{attrs:{"active-name":this.activeIndex}})],1),this._v(" "),e("Content",[e("liuanan-content")],1),this._v(" "),e("Footer",[e("home-footer")],1)],1)],1)},staticRenderFns:[]};var l=a("VU/8")(o,r,!1,function(t){a("szrY")},"data-v-b2c505c2",null);e.default=l.exports},"3ZIU":function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i=a("E7Bq"),s={render:function(){var t=this,e=t.$createElement,i=t._self._c||e;return i("div",[i("div",{staticClass:"breadcrumb"},[i("Breadcrumb",[i("BreadcrumbItem",{attrs:{to:"/"}},[t._v("HOME")]),t._v(" "),i("BreadcrumbItem",{attrs:{to:"/peopleEnglish"}},[t._v("PEOPLE")]),t._v(" "),i("BreadcrumbItem",[t._v("Dan Song")])],1)],1),t._v(" "),i("div",{staticClass:"content-box"},[i("div",[i("Row",[i("Col",{attrs:{span:"5"}},[i("div",{staticClass:"people-img"},[i("img",{attrs:{src:a("Dk4P"),width:"143px",height:"189px"}})])]),t._v(" "),i("Col",{attrs:{span:"19"}},[i("div",{staticClass:"people-intro"},[i("span",{staticStyle:{"font-size":"23px",color:"black","font-weight":"bold"}},[t._v("Dan Song")]),i("span",{staticStyle:{"padding-left":"20px"}},[t._v("Assistant Professor")]),i("br"),i("br"),t._v(" "),i("span",[t._v("School of Electrical and Information Engineering")]),i("br"),t._v(" "),i("span",[t._v("Tianjin University, China")]),i("br"),t._v(" "),i("span",[t._v("Email：dan.song@tju.edu.cn")]),i("br"),t._v(" "),i("span",[i("router-link",{attrs:{to:"https://github.com/dan-song"}},[t._v("[GitHub]")]),t._v(" "),i("router-link",{attrs:{to:"https://scholar.google.com.hk/citations?hl=zh-CN&user=G-mHRrEAAAAJ"}},[t._v("[Google Scholar]")])],1),i("br")])])],1)],1),t._v(" "),i("div",[i("h2",[t._v("Introduction")]),t._v(" "),i("hr",{staticClass:"research-line",staticStyle:{margin:"15px 0"}}),t._v(" "),i("span",{staticClass:"content"},[i("strong",[t._v("Dan Song")]),t._v(" is currently a lecturer in the School of Electrical and Information Engineering, Tianjin University, China. She is a member of the "),i("router-link",{attrs:{to:"https://www.iti-tju.org/"}},[t._v("Multimedia Institute")]),t._v(". She received her Ph.D. degree from Zhejiang University, China, in 2018. She used to be an academic visitor in the National Centre for Computer Animation (NCCA), United Kingdom. Her research interests include computer graphics, computer vision, machine learning and virtual fitting. Her work has been published in high-quality journals and conferences such as TCSVT, PR, CGF, CAD and so on. She has served as the reviewers for a set of forums, e.g., ACM MM, CVM, MTAP and NEPL.")],1)]),t._v(" "),t._m(0)])])},staticRenderFns:[function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",[a("h2",[t._v("Publication")]),t._v(" "),a("hr",{staticClass:"research-line",staticStyle:{margin:"15px 0"}}),t._v(" "),a("div",[a("span",{staticStyle:{"font-size":"15px",color:"#4590a3"}},[a("strong",[t._v("2019")])])]),a("br"),t._v(" "),a("div",{staticClass:"publication"},[a("p",{staticClass:"p title"},[a("strong",[t._v("[1]   Joint Heterogeneous Feature Learning and Distribution Alignment for 2D Image-Based 3D Object Retrieval. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Su, Y. T., Li, Y. Q., Nie, W. Z., "),a("strong",[t._v("Song, D.")]),t._v(", & Liu, A. A.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Circuits and Systems for Video Technology, 2019. ")])]),t._v(" "),a("div",{staticClass:"publication"},[a("p",{staticClass:"p title"},[a("strong",[t._v("[2]   Illumination-aware Faster R-CNN for Robust Multispectral Pedestrian Detection. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Li, C., "),a("strong",[t._v("Song, D.")]),t._v(", Tong, R., & Tang, M. ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("Pattern Recognition, 85, 161-171, 2019 ")])]),t._v(" "),a("div",{staticClass:"publication"},[a("p",{staticClass:"p title"},[a("strong",[t._v("[3]   A Shell Space Constrained Approach for Curve Design on Surface Meshes. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jin, Y., "),a("strong",[t._v("Song, D.")]),t._v(", Wang, T., Huang, J., Song, Y., & He, L.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("Computer-Aided Design, 113, 24-34, 2019 ")])]),t._v(" "),a("div",{staticClass:"publication"},[a("p",{staticClass:"p title"},[a("strong",[t._v("[4]   Unsupervised Feature Learning With Graph Embedding for View-Based 3D Model Retrieval. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Su, Y., Li, W., Nie, W., "),a("strong",[t._v("Song, D.")]),t._v(", & Liu, A. A.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access, 7, 95285-95296, 2019 ")])]),t._v(" "),a("div",{staticClass:"publication"},[a("p",{staticClass:"p title"},[a("strong",[t._v("[5]   Multi-View Hierarchical Fusion Network for 3D Object Retrieval and Classification. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Liu, A. A., Hu, N., "),a("strong",[t._v("Song, D.")]),t._v(", Guo, F. B., Zhou, H. Y., & Hao, T.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access, 7, 153021-153030, 2019 ")])]),t._v(" "),a("div",{staticClass:"publication"},[a("p",{staticClass:"p title"},[a("strong",[t._v("[6]   Monocular image based 3d model retrieval.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Li, W. H., Liu, A. A., Nie, W. Z., "),a("strong",[t._v("Song, D.")]),t._v(" et al.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("SHREC 2019' MI3DOR ")])]),t._v(" "),a("div",{staticClass:"publication"},[a("p",{staticClass:"p title"},[a("strong",[t._v("[7]   End-to-End Visual Domain Adaptation Network for Cross-Domain 3D CPS Data Retrieval.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Liu, A. A., Xiang, S., Nie W. Z., & "),a("strong",[t._v("Song, D.")]),t._v(".")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access, 7, 118630-118638, 2019 ")])]),t._v(" "),a("div",{staticClass:"publication"},[a("p",{staticClass:"p title"},[a("strong",[t._v("[8]   SP-VITON: shape-preserving image-based virtual try-on network.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[a("strong",[t._v("Song, D.")]),t._v(", Li, T., Mao, Z., & Liu, A. A.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" Multimedia Tools and Applications, 2019 ")])]),t._v(" "),a("div",{staticClass:"publication"},[a("p",{staticClass:"p title"},[a("strong",[t._v("[9]   Location Emotion Recognition for Travel Recommendation based on Social Network.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Nie, W., Ding, H., "),a("strong",[t._v("Song, D.")]),t._v(", & Long, X. ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" Signal, Image and Video Processing, 13(7): 1259-1266, 2019 ")])]),t._v(" "),a("div",[a("span",{staticStyle:{"font-size":"15px",color:"#4590a3"}},[a("strong",[t._v("2018")])])]),a("br"),t._v(" "),a("div",{staticClass:"publication"},[a("p",{staticClass:"p title"},[a("strong",[t._v("[1]   Data-Driven 3-D Human Body Customization With a Mobile Device.  ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[a("strong",[t._v("Song, D.")]),t._v(", Tong, R., Du, J., Zhang, Y., & Jin, Y.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access, 6, 27939-27948, 2018 ")])]),t._v(" "),a("div",{staticClass:"publication"},[a("p",{staticClass:"p title"},[a("strong",[t._v("[2]   Multispectral Pedestrian Detection via Simultaneous Detection and Segmentation.  ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Li, C., "),a("strong",[t._v("Song, D.")]),t._v(", Tong, R., & Tang, M.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("British Machine Vision Conference, 2018 ")])]),t._v(" "),a("div",{staticClass:"publication"},[a("p",{staticClass:"p title"},[a("strong",[t._v("[3]   “Edutainment 2017” a visual and semantic representation of 3D face model for reshaping face in images. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Du J., "),a("strong",[t._v("Song, D.")]),t._v(", Tang Y., Tong, R., & Tang, M.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("British Machine Vision Conference, 2018 ")])]),t._v(" "),a("div",[a("span",{staticStyle:{"font-size":"15px",color:"#4590a3"}},[a("strong",[t._v("2017")])])]),a("br"),t._v(" "),a("div",{staticClass:"publication"},[a("p",{staticClass:"p title"},[a("strong",[t._v("[1]   Clothes size prediction from dressed-human silhouettes.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[a("strong",[t._v("Song, D.")]),t._v(", Tong, R., Chang, J., Wang, T., Du J., Tang, M., & Zhang, J. J.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("Computer Graphics Forum, 35, 7, 147-156, 2016 ")])]),t._v(" "),a("div",[a("span",{staticStyle:{"font-size":"15px",color:"#4590a3"}},[a("strong",[t._v("2016")])])]),a("br"),t._v(" "),a("div",{staticClass:"publication"},[a("p",{staticClass:"p title"},[a("strong",[t._v("[1]   3D Body Shapes Estimation from Dressed-Human Silhouettes.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[a("strong",[t._v("Song, D.")]),t._v(", Tong, R., Chang, J., Yang, X., Tang, M., & Zhang, J. J. ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("Computer Graphics Forum, 35, 7, 147-156, 2016 ")])])])}]};var n=a("VU/8")({name:"SongdanContenten"},s,!1,function(t){a("2iZJ")},"data-v-5897e380",null).exports,o={name:"SongdanEnglish",components:{HomeFooter:a("6BGy").a,SongdanContenten:n,HomeHeaderen:i.a},data:function(){return{activeIndex:"/people"}},methods:{myajaxs:function(){this.$axios({method:"post",url:"/people/songdanEnglish"}).then(function(t){console.log(t)}).catch(function(t){console.log(t)})}}},r={render:function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("Layout",[e("Header",{staticStyle:{position:"fixed",right:"0",left:"0","z-index":"1030"}},[e("home-headeren",{attrs:{"active-name":this.activeIndex}})],1),this._v(" "),e("Content",[e("songdan-contenten")],1),this._v(" "),e("Footer",[e("home-footer")],1)],1)],1)},staticRenderFns:[]};var l=a("VU/8")(o,r,!1,function(t){a("DnbM")},"data-v-c80e9e26",null);e.default=l.exports},"3gOL":function(t,e,a){t.exports=a.p+"static/img/liuanan.610d06d.jpg"},"3ofm":function(t,e,a){t.exports=a.p+"static/img/research4-3.37022f7.jpg"},"4plH":function(t,e){},"553e":function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i=a("E7Bq"),s={render:function(){var t=this.$createElement,e=this._self._c||t;return e("div",{staticClass:"content-box"},[e("div",{staticClass:"content"},[e("Menu",{staticStyle:{"background-color":"rgb(245, 247, 249)"},attrs:{mode:"horizontal",theme:this.theme1,"active-name":"2"}},[e("MenuItem",{staticStyle:{width:"50%",overflow:"hidden","text-overflow":"ellipsis","white-space":"nowrap"},attrs:{name:"1",to:"/contest/contest1English"}},[e("Icon",{attrs:{type:"ios-paper"}}),this._v("\n        SHREC 2015-2020\n      ")],1),this._v(" "),e("MenuItem",{staticStyle:{width:"50%",overflow:"hidden","text-overflow":"ellipsis","white-space":"nowrap"},attrs:{name:"2",to:"/contest/contest2English"}},[e("Icon",{attrs:{type:"ios-ribbon"}}),this._v("\n        CVPR 2019 Contest on Mitosis Detection in Phase Contrast Microscopy Image Sequences\n      ")],1)],1),this._v(" "),this._m(0)],1)])},staticRenderFns:[function(){var t=this,e=t.$createElement,i=t._self._c||e;return i("div",{staticClass:"contest-content"},[i("h2",{staticStyle:{margin:"10px 0"}},[t._v("CVPR 2019 Contest on Mitosis Detection in Phase Contrast Microscopy Image Sequences")]),t._v(" "),i("p",[t._v("        Mitosis detection aims to determine the presence of mitosis in the microscopy image, and then locate the spatial and temporal location of mitotic cells across the microscopy image sequence. Unlike mitotic detection in static images, mitosis detection in phase contrast image dataset requires both spatial and temporal information to be taken into consideration for precise delineation and duration of these events."),i("br"),i("br")]),t._v(" "),i("p",[t._v("        The aim of this challenge is to provide a common benchmark for the evaluation of the mitosis detection algorithms in a new dataset of phase contrast time-lapse microscopy images at low magnification. Low magnification detection of mitosis, in particular, is very challenging due to the lower available information/pixels per cell. However, this is necessary to ensure that the mitotic behavior of an adequate number of cells is monitored. Only then can the acquired data be considered to be representative of the cell population."),i("br"),i("br"),t._v(" "),i("a",{staticStyle:{"font-size":"15px"},attrs:{href:"http://media.m2i.ac.cn/mitosisdetection"}},[t._v("http://media.m2i.ac.cn/mitosisdetection")]),i("br"),i("br")]),t._v(" "),i("img",{staticStyle:{width:"80%","margin-left":"10%"},attrs:{src:a("bqn7")}}),i("br"),i("br")])}]};var n=a("VU/8")({name:"ContestContent2en"},s,!1,function(t){a("4plH")},"data-v-79c6a54c",null).exports,o={name:"Contest2English",components:{HomeFooter:a("6BGy").a,ContestContent2en:n,HomeHeaderen:i.a},data:function(){return{activeIndex:"/research"}},methods:{myajaxs:function(){this.$axios({method:"post",url:"/contest/contest2English"}).then(function(t){console.log(t)}).catch(function(t){console.log(t)})}}},r={render:function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("Layout",[e("Header",{staticStyle:{position:"fixed",right:"0",left:"0","z-index":"1030"}},[e("home-headeren",{attrs:{"active-name":"activeIndex"}})],1),this._v(" "),e("Content",[e("contest-content2en")],1),this._v(" "),e("Footer",[e("home-footer")],1)],1)],1)},staticRenderFns:[]};var l=a("VU/8")(o,r,!1,function(t){a("jTiP")},"data-v-4402c242",null);e.default=l.exports},"58ql":function(t,e){},"5GpU":function(t,e,a){t.exports=a.p+"static/img/李余钱.1be2e17.jpg"},"5S5f":function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i=a("E7Bq"),s=a("6BGy"),n={render:function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"content-box"},[a("Row",[a("Col",{attrs:{span:"6"}},[a("Menu",{staticClass:"menu",staticStyle:{width:"200px","background-color":"rgb(245, 247, 249)","margin-top":"50px"},attrs:{theme:"light","active-name":"4"}},[a("MenuItem",{attrs:{name:"1",to:"/publication/publication2019English"}},[a("Icon",{attrs:{type:"md-document"}}),t._v("\n          2019\n        ")],1),t._v(" "),a("MenuItem",{attrs:{name:"2",to:"/publication/publication2018English"}},[a("Icon",{attrs:{type:"md-document"}}),t._v("\n          2018\n        ")],1),t._v(" "),a("MenuItem",{attrs:{name:"3",to:"/publication/publication2017English"}},[a("Icon",{attrs:{type:"md-document"}}),t._v("\n          2017\n        ")],1),t._v(" "),a("MenuItem",{attrs:{name:"4",to:"/publication/publication2016English"}},[a("Icon",{attrs:{type:"md-document"}}),t._v("\n          2016\n        ")],1)],1)],1),t._v(" "),a("Col",{attrs:{span:"18"}},[a("div",{staticClass:"education"},[a("div",{staticClass:"education-block"},[a("h3"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Multi-Modal Clique-Graph Matching for View-Based 3D Model Retrieval")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Weizhi Nie, Yue Gao, Yuting Su ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Image Processing, TIP 2016.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7430305"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("3D Convolutional Networks-Based Mitotic Event Detection in Time-Lapse Phase Contrast Microscopy Image Sequences of Stem Cell Populations")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Yuting Su, Weizhi Nie, Mohan Kankanhalli")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Conference on Computer Vision and Pattern Recognition Workshops, CVPRW 2016.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7789661"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Predicting Image Memorability Through Adaptive Transfer Learning From External Sources")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Peiguang Jing, Yuting Su, Liqiang Nie, Huimin Gu")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Multimedia, TMM 2016.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7797211"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("SnapVideo: Personalized Video Generation for a Sightseeing Trip")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Luming Zhang, Peiguang Jing, Yuting Su, Chao Zhang, Ling Shaoz")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Cybernetics, TCYB 2016.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7516655"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("HEp-2 Cells Classification via Clustered Multi-task Learning")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Yao Lu, Weizhi Nie, Yuting Su, Zhaoxuan Yang")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("Neurocomputing, 2016.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://www.sciencedirect.com/science/article/pii/S0925231216001235"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("A Tensor-Driven Temporal Correlation Model for Video Sequence Classification")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jing Zhang, Chuanzhong Xu, Peiguang Jing, Chengqian Zhang, Yuting Su  ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Signal Processing Letters, 2016.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7486042"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br")])])])],1)],1)},staticRenderFns:[]};var o={name:"publication2016English",components:{Publication2016Contenten:a("VU/8")({name:"publication2016Contenten"},n,!1,function(t){a("osZ1")},"data-v-cd0481b6",null).exports,HomeFooter:s.a,HomeHeaderen:i.a},methods:{myajaxs:function(){this.$axios({method:"post",url:"/publication/publication2016English"}).then(function(t){console.log(t)}).catch(function(t){console.log(t)})}}},r={render:function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("Layout",[e("Header",{staticStyle:{position:"fixed",right:"0",left:"0","z-index":"1030"}},[e("home-headeren",{attrs:{"active-name":this.activeIndex}})],1),this._v(" "),e("Content",[e("publication2016-contenten")],1),this._v(" "),e("Footer",[e("home-footer")],1)],1)],1)},staticRenderFns:[]};var l=a("VU/8")(o,r,!1,function(t){a("mt/z")},"data-v-667838b1",null);e.default=l.exports},"5gt0":function(t,e){},"5uEz":function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i=a("E7Bq"),s=a("00Uz"),n={name:"researchEnglish",components:{HomeFooter:a("6BGy").a,ResearchMenuen:s.a,HomeHeaderen:i.a},data:function(){return{activeIndex:"/research"}},methods:{myajaxs:function(){this.$axios({method:"post",url:"/researchEnglish"}).then(function(t){console.log(t)}).catch(function(t){console.log(t)})}}},o={render:function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("Layout",[e("Header",{staticStyle:{position:"fixed",right:"0",left:"0","z-index":"1030"}},[e("home-headeren",{attrs:{"active-name":this.activeIndex}})],1),this._v(" "),e("Content",[e("research-menuen")],1),this._v(" "),e("Footer",[e("home-footer")],1)],1)],1)},staticRenderFns:[]};var r=a("VU/8")(n,o,!1,function(t){a("ieDd")},"data-v-39a072d0",null);e.default=r.exports},"62qv":function(t,e){},"6BGy":function(t,e,a){"use strict";var i={render:function(){this.$createElement;this._self._c;return this._m(0)},staticRenderFns:[function(){var t=this.$createElement,e=this._self._c||t;return e("div",{staticClass:"home-footer"},[e("p",{staticClass:"footer-content"},[this._v("© 2019 Institute of Television and Image Information, Ministry of Education. All Rights Reserved.")])])}]};var s=a("VU/8")({name:"HomeFooter"},i,!1,function(t){a("58ql")},"data-v-aba9174c",null);e.a=s.exports},"6IBH":function(t,e){},"6jn2":function(t,e,a){t.exports=a.p+"static/img/research2-3.6b189de.jpg"},"7D6F":function(t,e,a){t.exports=a.p+"static/img/research2-4.bef9d51.jpg"},"7Zyu":function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i=a("byf9"),s=a("6BGy"),n={render:function(){var t=this,e=t.$createElement,i=t._self._c||e;return i("div",{staticClass:"content-box"},[i("div",{staticClass:"breadcrumb"},[i("Breadcrumb",[i("BreadcrumbItem",{attrs:{to:"/"}},[t._v("主页")]),t._v(" "),i("BreadcrumbItem",{attrs:{to:"/people"}},[t._v("团队")]),t._v(" "),i("BreadcrumbItem",[t._v("井佩光")])],1)],1),t._v(" "),i("div",[i("Row",[i("Col",{attrs:{span:"5"}},[i("div",{staticClass:"people-img"},[i("img",{attrs:{src:a("K2Da"),width:"143px",height:"189px"}})])]),t._v(" "),i("Col",{attrs:{span:"19"}},[i("div",{staticClass:"people-intro"},[i("span",{staticStyle:{"font-size":"23px",color:"black","font-weight":"bold"}},[t._v("井佩光")]),i("span",{staticStyle:{"padding-left":"20px"}},[t._v("助理教授/硕导")]),i("br"),i("br"),t._v(" "),i("span",[t._v("电气自动化与信息工程学院")]),i("br"),t._v(" "),i("span",[t._v("天津大学")]),i("br"),t._v(" "),i("span",[t._v("邮箱：pgjing@tju.edu.cn")]),i("br")])])],1)],1),t._v(" "),t._m(0),t._v(" "),t._m(1)])},staticRenderFns:[function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("h2",[this._v("简    介")]),this._v(" "),e("hr",{staticClass:"research-line",staticStyle:{margin:"15px 0"}}),this._v(" "),e("span",{staticClass:"content"},[this._v("井佩光，2013年获天津大学硕士学位，2018年获天津大学博士学位，并于2014年至2015年，在新加坡国立大学进行博士联合培养。现于天津大学电气自动化与信息工程学院担任讲师，硕士生导师。目前的研究方向包括张量分解，多媒体计算，机器学习等。")])])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",[a("h2",[t._v("论    文")]),t._v(" "),a("hr",{staticClass:"research-line",staticStyle:{margin:"15px 0"}}),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8359393"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[1]   High-Order Temporal Correlation Model Learning for Time-Series Prediction. IEEE Transactions on Cybernetics ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Peiguang Jing, Yuting Su, Xiao Jin, Chengqian Zhang.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Cybernetics, 2019, 49(6):2385-2397. ")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8480641"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[2]   Wearable Computing for Internet of Things: A Discriminant Approach for Human Activity Recognition.  ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Wei Lu, Fugui Fan, Jinghui Chu, Peiguang Jing, Yuting Su.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Internet of Things Journal, 2019, 6(2): 2749-2759.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8353302"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[3]   A Framework of Joint Low-Rank and Sparse Regression for Image Memorability Prediction. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" Peiguang Jing, Yuting Su, Liqiang Nie, Huimin Gu, Jing Liu , and Meng Wang.  ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Circuits and Systems for Video Technology, 2019,29(5):1296-1309. ")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8853293"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[4]   Low-rank Regularized Multi-representation Learning for Fashion Compatibility Prediction ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Peiguang Jing, Shu Ye, Liqiang Nie, Jing Liu, Yuting Su.  ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Multimedia, 2019, DOI: 10.1109/TMM.2019.2944749. ")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",[a("p",{staticClass:"p title"},[a("strong",[t._v("[5]   Low-rank regularized tensor discriminant representation for image set classification ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Peiguang Jing, Yuting Su, Zhengnan Li, Jing Liu, Liqiang Nie. ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" Signal Processing, 2019, 156:62-70. ")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",[a("p",{staticClass:"p title"},[a("strong",[t._v("[6]    Personalized Capsule Wardrobe Creation with Garment and User Modeling ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Xue Dong, Xuemeng Song, Fuli Feng, Peiguang Jing, Xin-Shun Xu, Liqiang Nie.   ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" In Proceedings of ACM International Conference on Multimedia, 2019: 302-310.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8233154"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[7]   Low-Rank Multi-View Embedding Learning for Micro-Video Popularity Prediction. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" Peiguang Jing, Yuting Su, Liqiang Nie, Xu Bai, Jing Liu, Meng Wang.  ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Knowledge and Data Engineering, 2018, 30(8): 1519-1532.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",[a("p",{staticClass:"p title"},[a("strong",[t._v("[8]   Structured Low-rank Inverse-covariance Estimation for Visual Sentiment Distribution Prediction. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" Anan Liu, Yingdi Shi, Peiguang Jing, Jing Liu, Yuting Su.  ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("Signal Processing, 2018, 152:206-216. ")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8025385"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[9]   Low-Rank Regularized Heterogeneous Tensor Decomposition for Subspace Clustering. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" Jing Zhang, Xinhui Li, Peiguang Jing, Jing Liu, Yuting Su.  ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Signal Processing Letters, 2018, 25 (3), 333-337.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7486042"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[10]   A Tensor-Driven Temporal Correlation Model for Video Sequence Classification. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" Jing Zhang, Chuanzhong Xu, Peiguang Jing, Chengqian Zhang, Yuting Su.  ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("  IEEE Signal Processing Letters, 2016, 23 (9), 1246 – 1249.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7797211"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[11]   Predicting Image Memorability Through Adaptive Transfer Learning From External Sources. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" Peiguang Jing, Yuting Su, Liqiang Nie, Huimin Gu.  ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("  IEEE Transactions on Multimedia, 2017, 19(5): 1050-1062.")])])])])}]};var o={name:"jingpeiguang",components:{JingpeiguangContent:a("VU/8")({name:"JingpeiguangContent"},n,!1,function(t){a("2e2M")},"data-v-11e2cca8",null).exports,HomeFooter:s.a,HomeHeader:i.a},methods:{myajaxs:function(){this.$axios({method:"post",url:"/people/jingpeiguang"}).then(function(t){console.log(t)}).catch(function(t){console.log(t)})}}},r={render:function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("Layout",[e("Header",{staticStyle:{position:"fixed",right:"0",left:"0","z-index":"1030"}},[e("home-header",{attrs:{"active-name":this.activeIndex}})],1),this._v(" "),e("Content",[e("jingpeiguang-content")],1),this._v(" "),e("Footer",[e("home-footer")],1)],1)],1)},staticRenderFns:[]};var l=a("VU/8")(o,r,!1,function(t){a("T63n")},"data-v-4add28e4",null);e.default=l.exports},"7gKO":function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i=a("byf9"),s={render:function(){var t=this,e=t.$createElement,i=t._self._c||e;return i("div",[i("div",{staticClass:"breadcrumb"},[i("Breadcrumb",[i("BreadcrumbItem",{attrs:{to:"/"}},[t._v("主页")]),t._v(" "),i("BreadcrumbItem",{attrs:{to:"/people"}},[t._v("团队")]),t._v(" "),i("BreadcrumbItem",[t._v("聂为之")])],1)],1),t._v(" "),i("div",{staticClass:"content-box"},[i("div",[i("Row",[i("Col",{attrs:{span:"5"}},[i("div",{staticClass:"people-img"},[i("img",{attrs:{src:a("+Dnu"),width:"143px",height:"189px"}})])]),t._v(" "),i("Col",{attrs:{span:"19"}},[i("div",{staticClass:"people-intro"},[i("span",{staticStyle:{"font-size":"23px",color:"black","font-weight":"bold"}},[t._v("聂为之")]),i("span",{staticStyle:{"padding-left":"20px"}},[t._v("副教授/博导")]),i("br"),i("br"),t._v(" "),i("span",[t._v("电气自动化与信息工程学院")]),i("br"),t._v(" "),i("span",[t._v("天津大学")]),i("br"),t._v(" "),i("span",[t._v("邮箱：weizhinie@tju.edu.cn")]),i("br")])])],1)],1),t._v(" "),t._m(0),t._v(" "),t._m(1)])])},staticRenderFns:[function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("h2",[this._v("简    介")]),this._v(" "),e("hr",{staticClass:"research-line",staticStyle:{margin:"15px 0"}}),this._v(" "),e("span",{staticClass:"content"},[this._v("自2014年起，聂为之任教于天津大学。现任天津大学电气自动化与信息工程学院副教授。他的研究方向包括三维模型检索、计算机视觉、机器学习、多媒体信息处理。")])])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",[a("h2",[t._v("论    文")]),t._v(" "),a("hr",{staticClass:"research-line",staticStyle:{margin:"15px 0"}}),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8832127"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[1]   SRNet: Structured Relevance Feature Learning Network From Skeleton Data for Human Action Recognition.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Weizhi Nie, Wei Wang, Xiangdong Huang.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access. 2019.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8812718"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[2]   End-to-End Visual Domain Adaptation Network for Cross-Domain 3D CPS Data Retrieval.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Shu Xiang, Wei-Zhi Nie, Dan Song.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access. 2019.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8770249"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[3]   Unsupervised Feature Learning With Graph Embedding for View-Based 3D Model Retrieval.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Yuting Su, Wenhui Li, Weizhi Nie, Dan Song, An-An Liu.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access. 2019.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8447210"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[4]   Dual-Stream Recurrent Neural Network for Video Captioning.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Ning Xu, An-An Liu, Yongkang Wong, Yongdong Zhang, Weizhi Nie, Yuting Su, Mohan Kankanhalli.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Circuits and Systems for Video Technology. 2019.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8401899"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[5]  Hyper-Clique Graph Matching and Applications.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Wei-Zhi Nie, An-An Liu, Yue Gao, Yu-Ting Su.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Circuits and Systems for Video Technology. 2018.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8303699"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[6]  3D Object Retrieval Based on Multi-View Latent Variable Model.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Wei-Zhi Nie, Yu-Ting Su.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Circuits and Systems for Video Technology. 2018.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8698722"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[7]   PANORAMA-Based Multi-Scale and Multi-Channel CNN for 3D Model Retrieval.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Weizhi Nie, Kun Wang, Yao Lu, Anan Liu, Yuting Su.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Visual Communications and Image Processing (VCIP). Taichung, Taiwan, China. 2018.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8434092"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[8]  Human Action Recognition Based on Selected Spatio-Temporal Features via Bidirectional LSTM.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Wenhui Li, Weizhi Nie, Yuting Su.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access. 2018.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8141866"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[9]  Attention-in-Attention Networks for Surveillance Video Understanding in Internet of Things.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Ning Xu, An-An Liu, Wei-Zhi Nie, Yu-Ting Su.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Internet of Things Journal. 2017.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7857115"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[10]  View-Based 3-D Model Retrieval: A Benchmark.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Wei-Zhi Nie, Yue Gao, Yu-Ting Su.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Cybernetics. 2017.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7984862"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[11]  Modeling Temporal Information of Mitotic for Mitotic Event Detection.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Weizhi Nie, Huiyun Cheng, Yuting Su.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Big Data. 2017.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7885509"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[12]   Multi-Grained Random Fields for Mitosis Identification in Time-Lapse Phase Contrast Microscopy Image Sequences.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Jinhui Tang, Weizhi Nie, Yuting Su.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Medical Imaging. 2017.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7515012"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[13]   Benchmarking a Multimodal and Multiview and Interactive Dataset for Human Action Recognition.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Ning Xu, Wei-Zhi Nie, Yu-Ting Su, Yongkang Wong, Mohan Kankanhalli.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Cybernetics. 2016.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7423818"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[14]   Hierarchical Clustering Multi-Task Learning for Joint Human Action Grouping and Recognition.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Yu-Ting Su, Wei-Zhi Nie, Mohan Kankanhalli.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Pattern Analysis and Machine Intelligence. 2016.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7789661"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[15]   3D Convolutional Networks-Based Mitotic Event Detection in Time-Lapse Phase Contrast Microscopy Image Sequences of Stem Cell Populations.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Yu-Ting Su, Wei-Zhi Nie, Mohan Kankanhalli.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW). Las Vegas, NV, USA. 2016.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7430305"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[16]   Multi-Modal Clique-Graph Matching for View-Based 3D Model Retrieval.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Wei-Zhi Nie, Yue Gao, Yu-Ting Su.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Image Processing. 2016.")])])])])}]};var n=a("VU/8")({name:"NieweizhiContent"},s,!1,function(t){a("jOVy")},"data-v-ca3c84f8",null).exports,o={name:"nieweizhi",components:{HomeFooter:a("6BGy").a,NieweizhiContent:n,HomeHeader:i.a},data:function(){return{activeIndex:"/people"}},methods:{myajaxs:function(){this.$axios({method:"post",url:"/people/nieweizhi"}).then(function(t){console.log(t)}).catch(function(t){console.log(t)})}}},r={render:function(){var t=this.$createElement,e=this._self._c||t;return e("Layout",[e("Header",{staticStyle:{position:"fixed",right:"0",left:"0","z-index":"1030"}},[e("home-header",{attrs:{"active-name":this.activeIndex}})],1),this._v(" "),e("Content",[e("nieweizhi-content")],1),this._v(" "),e("Footer",[e("home-footer")],1)],1)},staticRenderFns:[]};var l=a("VU/8")(o,r,!1,function(t){a("1wS6")},"data-v-5b6e2402",null);e.default=l.exports},"8Il4":function(t,e){},"8WJj":function(t,e){},"8YpW":function(t,e,a){t.exports=a.p+"static/img/路遥.a40be64.jpg"},"9JLm":function(t,e){},AApq:function(t,e){},ACsK:function(t,e){},AVsf:function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i={render:function(){var t=this,e=t.$createElement,i=t._self._c||e;return i("div",[i("div",{staticClass:"breadcrumb"},[i("Breadcrumb",[i("BreadcrumbItem",{attrs:{to:"/"}},[t._v("HOME")]),t._v(" "),i("BreadcrumbItem",{attrs:{to:"/peopleEnglish"}},[t._v("PEOPLE")]),t._v(" "),i("BreadcrumbItem",[t._v("Ning Xu")])],1)],1),t._v(" "),i("div",{staticClass:"content-box"},[i("div",[i("Row",[i("Col",{attrs:{span:"5"}},[i("div",{staticClass:"people-img"},[i("img",{attrs:{src:a("Cl+F"),width:"143px",height:"189px"}})])]),t._v(" "),i("Col",{attrs:{span:"19"}},[i("div",{staticClass:"people-intro"},[i("span",{staticStyle:{"font-size":"23px",color:"black","font-weight":"bold"}},[t._v("Ning Xu")]),i("span",{staticStyle:{"padding-left":"20px"}},[t._v("Assistant Professor")]),i("br"),i("br"),t._v(" "),i("span",[t._v("School of Electrical and Information Engineering")]),i("br"),t._v(" "),i("span",[t._v("Tianjin University, China")]),i("br"),t._v(" "),i("span",[t._v("Email：ningxu@tju.edu.cn")]),i("br"),t._v(" "),i("span",[t._v("Personal Page：ningxu1990.github.io")]),i("br")])])],1)],1),t._v(" "),t._m(0),t._v(" "),t._m(1)])])},staticRenderFns:[function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("h2",[this._v("Introduction")]),this._v(" "),e("hr",{staticClass:"research-line",staticStyle:{margin:"15px 0"}}),this._v(" "),e("span",{staticClass:"content"},[this._v("I am currently an assistant professor at School of Electrical and Information Engineering, Tianjin University (TJU), China. I received my Ph.D. degree from Tianjin University in 2019, supervised by Prof. An-An Liu, and B.E. degree from Hainan University (Advanced Class) in 2013, respectively. I was a visiting scholar from 2016 to 2017 at the SeSaMe Research Centre of NUS, working with Dr. Mohan Kankanhalli(IEEE Fellow). My recent research interests include machine learning, computer vision, action recognition, relation detection, and image/video captioning.")])])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",[a("h2",[t._v("Publication")]),t._v(" "),a("hr",{staticClass:"research-line",staticStyle:{margin:"15px 0"}}),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8476540"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[1]   Multi-Domain and Multi-Task Learning for Human Action Recognition. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Ning Xu, Weizhi Nie, Yuting Su, Yongdong Zhang.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Image Processing. 2019.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8447210/"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[2]   Dual-Stream Recurrent Neural Network for Video Captioning. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Ning Xu, An-An Liu, Yongkang Wong, Yongdong Zhang, Weizhi Nie, Yuting Su, Mohan S. Kankanhalli.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Circuits and Systems for Video Technology. 2019.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8141866"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[3]   Attention-in-Attention Networks for Surveillance Video Understanding in Internet of Things. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Ning Xu, Weizhi Nie, Yuting Su, Yongkang Wong, Mohan S. Kankanhalli.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Internet of Things Journal.2018.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7515012"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[4]    Benchmarking a Multimodal and Multiview and Interactive Dataset for Human Action Recognition.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Ning Xu, Weizhi Nie, Yuting Su, Yongkang Wong, Mohan S. Kankanhalli.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Cybernetics.2017.")])])])])}]};var s=a("VU/8")({name:"XuningContenten"},i,!1,function(t){a("RWbm")},"data-v-987f4aa2",null).exports,n=a("6BGy"),o={name:"xuningEnglish",components:{HomeHeaderen:a("E7Bq").a,HomeFooter:n.a,XuningContenten:s},data:function(){return{activeIndex:"/people"}},methods:{myajaxs:function(){this.$axios({method:"post",url:"/people/xuningEnglish"}).then(function(t){console.log(t)}).catch(function(t){console.log(t)})}}},r={render:function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("Layout",[e("Header",{staticStyle:{position:"fixed",right:"0",left:"0","z-index":"1030"}},[e("home-headeren",{attrs:{"active-name":this.activeIndex}})],1),this._v(" "),e("Content",[e("xuning-contenten")],1),this._v(" "),e("Footer",[e("home-footer")],1)],1)],1)},staticRenderFns:[]};var l=a("VU/8")(o,r,!1,function(t){a("SdAV")},"data-v-ab8effe6",null);e.default=l.exports},AeLw:function(t,e){},AflV:function(t,e){},Ahpy:function(t,e){},BU5W:function(t,e,a){t.exports=a.p+"static/img/research5-2.534c2e5.jpg"},CFP7:function(t,e,a){t.exports=a.p+"static/img/research1-5.dd5dba3.png"},CQF5:function(t,e){},Cd70:function(t,e,a){t.exports=a.p+"static/img/research3-3.41260db.jpg"},"Cl+F":function(t,e,a){t.exports=a.p+"static/img/xuning.c299b13.jpg"},D6O0:function(t,e,a){t.exports=a.p+"static/img/周雅倩.385c8c7.jpg"},Dk4P:function(t,e,a){t.exports=a.p+"static/img/songdan.f24152c.jpg"},DnbM:function(t,e){},"E2+J":function(t,e,a){t.exports=a.p+"static/img/王岩.04b1fcd.jpg"},E7Bq:function(t,e,a){"use strict";var i={name:"HomeHeaderen",props:{activeIndex:String},data:function(){return{}}},s={render:function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"home-header",staticStyle:{display:"flex",width:"1536px","min-width":"1280px","box-sizing":"border-box"}},[t._m(0),t._v(" "),a("div",{staticClass:"header-menu"},[a("Menu",{staticStyle:{background:"rgb(0,82,140)",width:"480px"},attrs:{mode:"horizontal","active-name":"activeIndex"}},[a("MenuItem",{staticStyle:{color:"white"},attrs:{to:"/",name:"1"}},[t._v("\n        Home\n      ")]),t._v(" "),a("MenuItem",{staticStyle:{color:"white"},attrs:{to:"/peopleEnglish",name:"2"}},[t._v("\n        People\n      ")]),t._v(" "),a("MenuItem",{staticStyle:{color:"white"},attrs:{to:"/researchEnglish",name:"3"}},[t._v("\n        Research\n      ")]),t._v(" "),a("MenuItem",{staticStyle:{color:"white"},attrs:{to:"/publication/publication2019English",name:"5"}},[t._v("\n        Publications\n      ")]),t._v(" "),a("MenuItem",{staticStyle:{color:"white"},attrs:{to:"/contest/contest1English",name:"6"}},[t._v("\n        Contests\n      ")])],1)],1),t._v(" "),a("div",{staticClass:"header-button"},[a("Button",{attrs:{type:"primary ",to:"/home"}},[t._v("中/En")])],1)])},staticRenderFns:[function(){var t=this.$createElement,e=this._self._c||t;return e("div",{staticClass:"header-logo"},[e("img",{staticClass:"logo",attrs:{src:a("uzhG")}})])}]};var n=a("VU/8")(i,s,!1,function(t){a("+ajF")},"data-v-faefdc4a",null);e.a=n.exports},E7wq:function(t,e){},"G+Se":function(t,e,a){t.exports=a.p+"static/img/梁琪.ce054dc.jpg"},GIfL:function(t,e,a){t.exports=a.p+"static/img/research1-3.31bd516.png"},GWBv:function(t,e){},HVvy:function(t,e,a){t.exports=a.p+"static/img/research5-1.41c0d09.png"},JEUR:function(t,e){},JjdV:function(t,e,a){t.exports=a.p+"static/img/杨嵩.534ec33.jpg"},K2Da:function(t,e,a){t.exports=a.p+"static/img/jingpeiguang.7953a73.jpg"},KmP5:function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i=a("byf9"),s=a("6BGy"),n={render:function(){var t=this,e=t.$createElement,i=t._self._c||e;return i("div",[i("div",{staticClass:"guwen"},[t._m(0),t._v(" "),i("hr",{staticClass:"people-line",staticStyle:{margin:"10px 0 40px 0"}}),t._v(" "),i("Row",[i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("tQnf"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("p",{staticStyle:{color:"rgb(100, 100, 100)","text-align":"center","font-size":"16px"}},[t._v("张春田 教授"),i("br"),t._v("中国图象图形学会名誉理事"),i("br"),t._v("天津市图象图形学会副理事长")])])]),t._v(" "),i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("U6CQ"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("p",{staticStyle:{color:"rgb(100, 100, 100)","text-align":"center","font-size":"16px"}},[t._v("杨兆选 教授"),i("br"),t._v("平板显示协会理事"),i("br"),t._v("信息与学科系统带头人")])])])],1)],1),t._v(" "),i("div",{staticClass:"teacher"},[t._m(1),t._v(" "),i("hr",{staticClass:"people-line",staticStyle:{margin:"10px 0 40px 0"}}),t._v(" "),i("Row",[i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("p4HD"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("a",{attrs:{href:"/#/people/suyuting"}},[t._v("苏育挺 教授")])])]),t._v(" "),i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("3gOL"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("a",{attrs:{href:"/#/people/liuanan"}},[t._v("刘安安 教授")])])])],1),t._v(" "),i("Row",[i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("+Dnu"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("a",{attrs:{href:"/#/people/nieweizhi"}},[t._v("聂为之 副教授")])])]),t._v(" "),i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("2fq6"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("a",{attrs:{href:"/#/people/liujing"}},[t._v("刘    婧 副教授")])])])],1),t._v(" "),i("Row",[i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("K2Da"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("a",{attrs:{href:"/#/people/jingpeiguang"}},[t._v("井佩光 助理教授")])])]),t._v(" "),i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("Dk4P"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("a",{attrs:{href:"/#/people/songdan"}},[t._v("宋    丹 助理教授")])])]),t._v(" "),i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("Cl+F"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("a",{attrs:{href:"https://ningxu.iti-tju.org/"}},[t._v("徐    宁 助理教授")])])])],1)],1),t._v(" "),i("div",{staticClass:"phd"},[t._m(2),t._v(" "),i("hr",{staticClass:"people-line",staticStyle:{margin:"10px 0 40px 0"}}),t._v(" "),i("Row",[i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("8YpW"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("p",{staticClass:"people-phd"},[t._v("路    遥（2014级）")])])]),t._v(" "),i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("Yhjq"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("p",{staticClass:"people-phd"},[i("a",{attrs:{href:"https://iti-tju.org/~yyliu"}},[t._v("刘瑶瑶（2015级)")])])])]),t._v(" "),i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("MmyG"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("p",{staticClass:"people-phd"},[t._v("李文辉（2016级）")])])]),t._v(" "),i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("5GpU"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("p",{staticClass:"people-phd"},[t._v("李余钱（2017级）")])])])],1),t._v(" "),i("Row",[i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("bLpp"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("p",{staticClass:"people-phd"},[t._v("田宏硕（2018级）")])])]),t._v(" "),i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("2iX+"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("p",{staticClass:"people-phd"},[t._v("李佳玉（2018级）")])])]),t._v(" "),i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("G+Se"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("p",{staticClass:"people-phd"},[t._v("梁    琪（2019级）")])])]),t._v(" "),i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("JjdV"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("p",{staticClass:"people-phd"},[t._v("杨    嵩（2019级）")])])])],1),t._v(" "),i("Row",[i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("E2+J"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("p",{staticClass:"people-phd"},[t._v("王    岩（2019级）")])])]),t._v(" "),i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("UEL+"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("p",{staticClass:"people-phd"},[t._v("周河宇（2019级）")])])]),t._v(" "),i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("D6O0"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("p",{staticClass:"people-phd"},[t._v("周雅倩（2019级）")])])])],1)],1),t._v(" "),i("hr",{staticClass:"people-line",staticStyle:{margin:"10px 0 40px 0"}}),t._v(" "),i("div",{staticClass:"master"},[t._m(3),t._v(" "),i("hr",{staticClass:"people-line",staticStyle:{margin:"10px 0 40px 0"}}),t._v(" "),i("div",[t._m(4),t._v(" "),i("Row",[i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("闫    严")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("向    姝")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("陈    闯")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("王    坤")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("丁    海")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("刘平平")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("孙婉宁")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("肖萌萌")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("王靖婷")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("龙行健")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("王灏楠")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("张春婷")])],1),t._v(" "),i("Row",[i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("吕锦成")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("刘靖辉")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("商悦晨")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("王明兴")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("王炜杰")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("冯鹏娇")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("叶    澍")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("李    阳")])],1),i("br"),t._v(" "),t._m(5),t._v(" "),i("Row",[i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("王    亚")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("赵    岳")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("祝    平")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("胡    念")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("贾文武")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("赵镇澜")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("郭富宾")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("张千依")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("屈    露")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("王蒙蒙")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("崔天舒")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("洪道政")])],1),t._v(" "),i("Row",[i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("陈    琦")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("张美琪")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("李海钊")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("范慧慧")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("郑博文")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("安时达")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("郝志辉")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("武宇廷")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("王彦晖")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("严昌飞")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("周俊洁")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("李德盛")])],1),t._v(" "),i("Row",[i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("张春萍")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("徐扬扬")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("任敏婕")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("王一心")])],1),t._v(" "),i("br"),t._v(" "),t._m(6),t._v(" "),i("Row",[i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("王    晗")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("袁    民")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("王维康")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("文    昕")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("张佳琪")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("杨紫雯")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("窦倩倩")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("叶徐清")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("李亚鑫")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("陆荣烜")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("张    景")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("张丽娟")])],1),t._v(" "),i("Row",[i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("赵    玮")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("田雯洁")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("周荡荡")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("夏华威")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("韩乾坤")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("樊腾飞")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("袁运新")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("史晓琦")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("高思洁")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("刘    通")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("张    婷")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("翟英晨")])],1),t._v(" "),i("Row",[i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("逯子慕")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("李天宝")])],1),t._v(" "),i("br")],1)]),t._v(" "),i("div",{staticClass:"master"},[t._m(7),t._v(" "),i("hr",{staticClass:"people-line",staticStyle:{margin:"10px 0 40px 0"}}),t._v(" "),i("div",[i("Row",[i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("黄冰洋")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("高文庆")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("李佩佩")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("王海懿")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("王中阳")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("许    勇")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("支美丽")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("赵亚洲")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("蒲婷婷")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("朱校蓉")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("曹    群")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("陈亚伟")])],1),t._v(" "),i("Row",[i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("杜佳星")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("李富武")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("李晓雪")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("李希茜")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("王慧晶")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("王    萍")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("徐传忠")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("赵正宇")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("李    阳")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("于    帆")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("安    阳")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("程会云")])],1),t._v(" "),i("Row",[i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("付建鹏")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("顾慧敏")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("郝雅惠")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("刘楠楠")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("郭洪斌")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("李征楠")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("邵    壮")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("师    阳")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("田    叶")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("徐佳宇")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("许    磊")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("张    欣")])],1),t._v(" "),i("Row",[i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("王    珊")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("白    须")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("陈    耀")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("邓宗慧")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("贺柔冰")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("李梦洁")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("刘琛琛")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("李欣慧")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("彭文娟")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("邱禹瑞")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("史英迪")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("王洪涛")])],1),t._v(" "),i("Row",[i("Col",{staticClass:"people-master",attrs:{span:"2"}},[t._v("石    悦")])],1)],1)])])},staticRenderFns:[function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("p",{staticClass:"people-title"},[this._v("顾    问")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("p",{staticClass:"people-title"},[this._v("教    师")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("p",{staticClass:"people-title"},[this._v("博士生")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("p",{staticClass:"people-title"},[this._v("硕士生")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("span",{staticClass:"people-master"},[this._v("2017级"),e("br")])},function(){var t=this.$createElement,e=this._self._c||t;return e("span",{staticClass:"people-master"},[this._v("2018级"),e("br")])},function(){var t=this.$createElement,e=this._self._c||t;return e("span",{staticClass:"people-master"},[this._v("2019级"),e("br")])},function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("p",{staticClass:"people-title"},[this._v("毕业生")])])}]};var o={name:"people-main",components:{PeopleMenu:a("VU/8")({name:"PeopleMenu"},n,!1,function(t){a("pryb")},"data-v-1005f33a",null).exports,HomeFooter:s.a,HomeHeader:i.a},data:function(){return{activeIndex:"/people"}},methods:{myajaxs:function(){this.$axios({method:"post",url:"/people"}).then(function(t){console.log(t)}).catch(function(t){console.log(t)})}}},r={render:function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("Layout",[e("Header",{staticStyle:{position:"fixed",right:"0",left:"0","z-index":"1030"}},[e("home-header",{attrs:{"active-name":this.activeIndex}})],1),this._v(" "),e("Content",[e("people-menu")],1),this._v(" "),e("Footer",[e("home-footer")],1)],1)],1)},staticRenderFns:[]};var l=a("VU/8")(o,r,!1,function(t){a("M04r")},"data-v-63c99f77",null);e.default=l.exports},Kqwg:function(t,e){},KuYG:function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i={render:function(){var t=this,e=t.$createElement,i=t._self._c||e;return i("div",[i("div",{staticClass:"breadcrumb"},[i("Breadcrumb",[i("BreadcrumbItem",{attrs:{to:"/"}},[t._v("HOME")]),t._v(" "),i("BreadcrumbItem",{attrs:{to:"/peopleEnglish"}},[t._v("PEOPLE")]),t._v(" "),i("BreadcrumbItem",[t._v("Yuting Su")])],1)],1),t._v(" "),i("div",{staticClass:"content-box"},[i("div",[i("Row",[i("Col",{attrs:{span:"5"}},[i("div",{staticClass:"people-img"},[i("img",{attrs:{src:a("p4HD"),width:"143px",height:"189px"}})])]),t._v(" "),i("Col",{attrs:{span:"19"}},[i("div",{staticClass:"people-intro"},[i("span",{staticStyle:{"font-size":"23px",color:"black","font-weight":"bold"}},[t._v("Yuting Su")]),i("span",{staticStyle:{"padding-left":"20px"}},[t._v("Professor")]),i("br"),i("br"),t._v(" "),i("span",[t._v("School of Electrical and Information Engineering")]),i("br"),t._v(" "),i("span",[t._v("Tianjin University, China")]),i("br"),t._v(" "),i("span",[t._v("Email：ytsu@tju.edu.cn")]),i("br")])])],1)],1),t._v(" "),t._m(0),t._v(" "),t._m(1),t._v(" "),t._m(2),t._v(" "),t._m(3)])])},staticRenderFns:[function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("h2",[this._v("Introduction")]),this._v(" "),e("hr",{staticClass:"research-line",staticStyle:{margin:"15px 0"}}),this._v(" "),e("span",{staticClass:"content"},[this._v("Yuting Su has been teaching at tianjin university since 2001. He is currently a professor of electrical automation and information engineering at Tianjin University. His research interests include multimedia information processing, multimedia information security, image/video compression coding, and Internet of things technology.")])])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",[a("h2",[t._v("Publication")]),t._v(" "),a("hr",{staticClass:"research-line",staticStyle:{margin:"15px 0"}}),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8770249"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[1]  Unsupervised Feature Learning With Graph Embedding for View-Based 3D Model Retrieval.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Yuting Su, Wenhui Li, Weizhi Nie, Dan Song, An-An Liu.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Access. 2019.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8636159"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[2]  Spatiotemporal Symmetric Convolutional Neural Network for Video Bit-Depth Enhancement.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jing Liu, Pingping Liu, Yuting Su, Peiguang Jing, Xiaokang Yang.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Multimedia. 2019.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8447210/"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[3]   Dual-Stream Recurrent Neural Network for Video Captioning.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Ning Xu, An-An Liu, Yongkang Wong, Yongdong Zhang, Weizhi Nie, Yuting Su, Mohan S.Kankanhalli.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Circuits and Systems for Video Technology. 2019.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8359393"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[4]  High-Order Temporal Correlation Model Learning for Time-Series Prediction.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Peiguang Jing, Yuting Su, Xiao Jin, Chengqian Zhang.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Cybernetics. 2019.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8353302"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[5]   A Framework of Joint Low-Rank and Sparse Regression for Image Memorability Prediction.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Peiguang Jing, Yuting Su, Liqiang Nie, Huimin Gu, Jing Liu, Meng Wang.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Circuits and Systems for Video Technology, 2019.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8523661/"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[6]   A Fine-Grained Spatial-Temporal Attention Model for Video Captioning.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Yurui Qiu, Yongkang Wong, Yuting Su, Mohan Kankanhalli.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Access. 2018.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8233154/"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[7]   Low-Rank Multi-View Embedding Learning for Micro-Video Popularity Prediction.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Peiguang Jing, Yuting Su, Liqiang Nie, Xu Bai, Jing Liu, Meng Wang.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Knowledge and Data Engineering. 2018.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8141866"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[8]   Attention-in-Attention Networks for Surveillance Video Understanding in Internet of Things.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Ning Xu, Weizhi Nie, Yuting Su, Yongkang Wong, Mohan S. Kankanhalli.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Internet of Things Journal.2018.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8025385"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[9]    Low-Rank Regularized Heterogeneous Tensor Decomposition for Subspace Clustering.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jing Zhang, Xinhui Li, Peiguang Jing, Jing Liu, Yuting Su.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Signal Processing Letters. 2018.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7857115"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[10]   View-Based 3-D Model Retrieval: A Benchmark.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Wei-Zhi Nie, Yue Gao, Yu-Ting Su.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Cybernetics. 2018.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7984862"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[11]   Modeling Temporal Information of Mitotic for Mitotic Event Detection.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Weizhi Nie, Huiyun Cheng, Yuting Su.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Big Data. 2018.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7962189"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[12]   Mitosis Detection in Phase Contrast Microscopy Image Sequences of Stem Cell Populations: A Critical Review.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Yao Lu, Mei Chen, Yu-Ting Su.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Big Data. 2017.")])])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("div",{staticClass:"publication"},[e("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7486042"}},[e("p",{staticClass:"p title"},[e("strong",[this._v("[13]   A Tensor-Driven Temporal Correlation Model for Video Sequence Classification.")])]),this._v(" "),e("p",{staticClass:"p author"},[e("i",[this._v("Jing Zhang, Chuanzhong Xu, Peiguang Jing, Chengqian Zhang, Yuting Su.")])]),this._v(" "),e("p",{staticClass:"p time"},[this._v("IEEE Transactions on Big Data. 2016.")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("div",{staticClass:"publication"},[e("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7430305"}},[e("p",{staticClass:"p title"},[e("strong",[this._v("[14]  A Tensor-Driven Temporal Correlation Model for Video Sequence Classification.")])]),this._v(" "),e("p",{staticClass:"p author"},[e("i",[this._v("An-An Liu, Wei-Zhi Nie, Yue Gao, Yu-Ting Su.")])]),this._v(" "),e("p",{staticClass:"p time"},[this._v("IEEE Transactions on Image Processing. 2016.")])])])}]};var s=a("VU/8")({name:"SuyutingContenten"},i,!1,function(t){a("so+g")},"data-v-5b26c102",null).exports,n=a("6BGy"),o={name:"suyutingEnglish",components:{HomeHeaderen:a("E7Bq").a,HomeFooter:n.a,SuyutingContenten:s},data:function(){return{activeIndex:"/people"}},methods:{myajaxs:function(){this.$axios({method:"post",url:"/people/suyutingEnglish"}).then(function(t){console.log(t)}).catch(function(t){console.log(t)})}}},r={render:function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("Layout",[e("Header",{staticStyle:{position:"fixed",right:"0",left:"0","z-index":"1030"}},[e("home-headeren",{attrs:{"active-name":this.activeIndex}})],1),this._v(" "),e("Content",[e("suyuting-contenten")],1),this._v(" "),e("Footer",[e("home-footer")],1)],1)],1)},staticRenderFns:[]};var l=a("VU/8")(o,r,!1,function(t){a("dQDw")},"data-v-53331acd",null);e.default=l.exports},"L08/":function(t,e,a){t.exports=a.p+"static/img/research1-6.eafdb0a.png"},M04r:function(t,e){},M9sx:function(t,e){},Md5u:function(t,e){},MkWf:function(t,e){},MmyG:function(t,e,a){t.exports=a.p+"static/img/李文辉.ef98694.jpg"},MuXq:function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i=a("byf9"),s=a("6BGy"),n={render:function(){var t=this,e=t.$createElement,i=t._self._c||e;return i("div",[i("div",{staticClass:"breadcrumb"},[i("Breadcrumb",[i("BreadcrumbItem",{attrs:{to:"/"}},[t._v("主页")]),t._v(" "),i("BreadcrumbItem",{attrs:{to:"/people"}},[t._v("团队")]),t._v(" "),i("BreadcrumbItem",[t._v("徐宁")])],1)],1),t._v(" "),i("div",{staticClass:"content-box"},[i("div",[i("Row",[i("Col",{attrs:{span:"5"}},[i("div",{staticClass:"people-img"},[i("img",{attrs:{src:a("Cl+F"),width:"143px",height:"189px"}})])]),t._v(" "),i("Col",{attrs:{span:"19"}},[i("div",{staticClass:"people-intro"},[i("span",{staticStyle:{"font-size":"23px",color:"black","font-weight":"bold"}},[t._v("徐    宁")]),i("span",{staticStyle:{"padding-left":"20px"}},[t._v("助理教授")]),i("br"),i("br"),t._v(" "),i("span",[t._v("电气自动化与信息工程学院")]),i("br"),t._v(" "),i("span",[t._v("天津大学")]),i("br"),t._v(" "),i("span",[t._v("邮箱：ningxu@tju.edu.cn")]),i("br"),t._v(" "),i("span",[t._v("个人主页：ningxu1990.github.io")]),i("br")])])],1)],1),t._v(" "),t._m(0),t._v(" "),t._m(1)])])},staticRenderFns:[function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("h2",[this._v("简    介")]),this._v(" "),e("hr",{staticClass:"research-line",staticStyle:{margin:"15px 0"}}),this._v(" "),e("span",{staticClass:"content"},[this._v("徐宁，现任天津大学电气自动化与信息工程学院助理教授。2013年开始就读于天津大学电气自动化与信息工程学院，师从刘安安教授，并于2019年获天津大学工学博士学位。2016年至2017年期间，在Mohan Kankanhalli教授(IEEE Fellow)的指导下，以访问学者的身份在新加坡国立大学 SeSaMe 实验室交流学习。”2009年至2013年就读于海南大学信息科学技术学院（理科实验班），获海南大学工学学士学位。主要研究方向包括机器学习、计算机视觉、人体动作识别、视觉关系检测和视觉自然语言描述。")])])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",[a("h2",[t._v("论    文")]),t._v(" "),a("hr",{staticClass:"research-line",staticStyle:{margin:"15px 0"}}),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8476540"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[1]   Multi-Domain and Multi-Task Learning for Human Action Recognition. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Ning Xu, Weizhi Nie, Yuting Su, Yongdong Zhang.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Image Processing. 2019.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8447210/"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[2]   Dual-Stream Recurrent Neural Network for Video Captioning. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Ning Xu, An-An Liu, Yongkang Wong, Yongdong Zhang, Weizhi Nie, Yuting Su, Mohan S. Kankanhalli.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Circuits and Systems for Video Technology. 2019.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8141866"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[3]   Attention-in-Attention Networks for Surveillance Video Understanding in Internet of Things. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Ning Xu, Weizhi Nie, Yuting Su, Yongkang Wong, Mohan S. Kankanhalli.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Internet of Things Journal.2018.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7515012"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[4]    Benchmarking a Multimodal and Multiview and Interactive Dataset for Human Action Recognition.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Ning Xu, Weizhi Nie, Yuting Su, Yongkang Wong, Mohan S. Kankanhalli.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Cybernetics.2017.")])])])])}]};var o={name:"xuning",components:{XuningContent:a("VU/8")({name:"XuningContent"},n,!1,function(t){a("1uv5")},"data-v-c56d00de",null).exports,HomeFooter:s.a,HomeHeader:i.a},data:function(){return{activeIndex:"/people"}},methods:{myajaxs:function(){this.$axios({method:"post",url:"/people/xuning"}).then(function(t){console.log(t)}).catch(function(t){console.log(t)})}}},r={render:function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("Layout",[e("Header",{staticStyle:{position:"fixed",right:"0",left:"0","z-index":"1030"}},[e("home-header",{attrs:{"active-name":this.activeIndex}})],1),this._v(" "),e("Content",[e("xuning-content")],1),this._v(" "),e("Footer",[e("home-footer")],1)],1)],1)},staticRenderFns:[]};var l=a("VU/8")(o,r,!1,function(t){a("GWBv")},"data-v-52be644b",null);e.default=l.exports},NHnr:function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i=a("7+uW"),s={render:function(){var t=this.$createElement,e=this._self._c||t;return e("div",{attrs:{id:"app"}},[e("router-view")],1)},staticRenderFns:[]};var n=a("VU/8")({name:"app"},s,!1,function(t){a("JEUR")},null,null).exports,o=a("/ocq"),r=a("vkyI"),l=a("oQOq"),c=a("ZmSL"),p=a("5uEz"),v=a("xTw1"),u=a("gsQP"),_=a("06nC"),h=a("yuGA"),g=a("QOC1"),m=a("KmP5"),d=a("Nimd"),C=a("MuXq"),f=a("AVsf"),b=a("U9St"),E=a("3ZIU"),S=a("Peex"),x=a("Uylg"),I=a("m0m0"),y=a("KuYG"),w=a("7gKO"),M=a("usVh"),A=a("3Oue"),L=a("zeZq"),P=a("7Zyu"),T=a("jD5f"),R=a("ucMM"),D=a("jq8P"),N=a("Zofq"),Y=a("VixX"),H=a("1xpz"),k=a("ep9K"),J=a("ZaIm"),V=a("5S5f"),W=a("Y7m0"),B=a("nSAl"),j=a("YPsL"),F=a("553e");i.default.use(o.a);var z=new o.a({routes:[{path:"/home",name:r.default,component:function(t){return new Promise(function(t){t()}).then(function(){return t(a("vkyI"))}.bind(null,a)).catch(a.oe)}},{path:"/",name:l.default,component:function(t){return new Promise(function(t){t()}).then(function(){return t(a("oQOq"))}.bind(null,a)).catch(a.oe)}},{path:"/research",name:c.default,component:function(t){return new Promise(function(t){t()}).then(function(){return t(a("ZmSL"))}.bind(null,a)).catch(a.oe)}},{path:"/researchEnglish",name:p.default,component:function(t){return new Promise(function(t){t()}).then(function(){return t(a("5uEz"))}.bind(null,a)).catch(a.oe)}},{path:"/research/research1",name:v.default,component:function(t){return new Promise(function(t){t()}).then(function(){return t(a("xTw1"))}.bind(null,a)).catch(a.oe)}},{path:"/research/research2",name:u.default,component:function(t){return new Promise(function(t){t()}).then(function(){return t(a("gsQP"))}.bind(null,a)).catch(a.oe)}},{path:"/research/research3",name:_.default,component:function(t){return new Promise(function(t){t()}).then(function(){return t(a("06nC"))}.bind(null,a)).catch(a.oe)}},{path:"/research/research4",name:h.default,component:function(t){return new Promise(function(t){t()}).then(function(){return t(a("yuGA"))}.bind(null,a)).catch(a.oe)}},{path:"/research/research5",name:g.default,component:function(t){return new Promise(function(t){t()}).then(function(){return t(a("QOC1"))}.bind(null,a)).catch(a.oe)}},{path:"/people",name:m.default,component:function(t){return new Promise(function(t){t()}).then(function(){return t(a("KmP5"))}.bind(null,a)).catch(a.oe)}},{path:"/peopleEnglish",name:d.default,component:function(t){return new Promise(function(t){t()}).then(function(){return t(a("Nimd"))}.bind(null,a)).catch(a.oe)}},{path:"/people/xuning",name:C.default,component:function(t){return new Promise(function(t){t()}).then(function(){return t(a("MuXq"))}.bind(null,a)).catch(a.oe)}},{path:"/people/xuningEnglish",name:f.default,component:function(t){return new Promise(function(t){t()}).then(function(){return t(a("AVsf"))}.bind(null,a)).catch(a.oe)}},{path:"/people/songdan",name:b.default,component:function(t){return new Promise(function(t){t()}).then(function(){return t(a("U9St"))}.bind(null,a)).catch(a.oe)}},{path:"/people/SongdanEnglish",name:E.default,component:function(t){return new Promise(function(t){t()}).then(function(){return t(a("3ZIU"))}.bind(null,a)).catch(a.oe)}},{path:"/people/liujing",name:S.default,component:function(t){return new Promise(function(t){t()}).then(function(){return t(a("Peex"))}.bind(null,a)).catch(a.oe)}},{path:"/people/liujingEnglish",name:x.default,component:function(t){return new Promise(function(t){t()}).then(function(){return t(a("Uylg"))}.bind(null,a)).catch(a.oe)}},{path:"/people/nieweizhi",name:w.default,component:function(t){return new Promise(function(t){t()}).then(function(){return t(a("7gKO"))}.bind(null,a)).catch(a.oe)}},{path:"/people/nieweizhiEnglish",name:M.default,component:function(t){return new Promise(function(t){t()}).then(function(){return t(a("usVh"))}.bind(null,a)).catch(a.oe)}},{path:"/people/liuanan",name:A.default,component:function(t){return new Promise(function(t){t()}).then(function(){return t(a("3Oue"))}.bind(null,a)).catch(a.oe)}},{path:"/people/liuananEnglish",name:L.default,component:function(t){return new Promise(function(t){t()}).then(function(){return t(a("zeZq"))}.bind(null,a)).catch(a.oe)}},{path:"/people/suyuting",name:I.default,component:function(t){return new Promise(function(t){t()}).then(function(){return t(a("m0m0"))}.bind(null,a)).catch(a.oe)}},{path:"/people/suyutingEnglish",name:y.default,component:function(t){return new Promise(function(t){t()}).then(function(){return t(a("KuYG"))}.bind(null,a)).catch(a.oe)}},{path:"/people/jingpeiguang",name:P.default,component:function(t){return new Promise(function(t){t()}).then(function(){return t(a("7Zyu"))}.bind(null,a)).catch(a.oe)}},{path:"/people/JingpeiguangEnglish",name:T.default,component:function(t){return new Promise(function(t){t()}).then(function(){return t(a("jD5f"))}.bind(null,a)).catch(a.oe)}},{path:"/publication/publication2019",name:R.default,component:function(t){return new Promise(function(t){t()}).then(function(){return t(a("ucMM"))}.bind(null,a)).catch(a.oe)}},{path:"/publication/publication2018",name:D.default,component:function(t){return new Promise(function(t){t()}).then(function(){return t(a("jq8P"))}.bind(null,a)).catch(a.oe)}},{path:"/publication/publication2017",name:N.default,component:function(t){return new Promise(function(t){t()}).then(function(){return t(a("Zofq"))}.bind(null,a)).catch(a.oe)}},{path:"/publication/publication2016",name:Y.default,component:function(t){return new Promise(function(t){t()}).then(function(){return t(a("VixX"))}.bind(null,a)).catch(a.oe)}},{path:"/publication/publication2019English",name:H.default,component:function(t){return new Promise(function(t){t()}).then(function(){return t(a("1xpz"))}.bind(null,a)).catch(a.oe)}},{path:"/publication/publication2018English",name:k.default,component:function(t){return new Promise(function(t){t()}).then(function(){return t(a("ep9K"))}.bind(null,a)).catch(a.oe)}},{path:"/publication/publication2017English",name:J.default,component:function(t){return new Promise(function(t){t()}).then(function(){return t(a("ZaIm"))}.bind(null,a)).catch(a.oe)}},{path:"/publication/publication2016English",name:V.default,component:function(t){return new Promise(function(t){t()}).then(function(){return t(a("5S5f"))}.bind(null,a)).catch(a.oe)}},{path:"/contest/contest1",name:W.default,component:function(t){return new Promise(function(t){t()}).then(function(){return t(a("Y7m0"))}.bind(null,a)).catch(a.oe)}},{path:"/contest/contest2",name:j.default,component:function(t){return new Promise(function(t){t()}).then(function(){return t(a("YPsL"))}.bind(null,a)).catch(a.oe)}},{path:"/contest/contest1English",name:B.default,component:function(t){return new Promise(function(t){t()}).then(function(){return t(a("nSAl"))}.bind(null,a)).catch(a.oe)}},{path:"/contest/Contest2English",name:F.default,component:function(t){return new Promise(function(t){t()}).then(function(){return t(a("553e"))}.bind(null,a)).catch(a.oe)}}]}),Z=a("BTaQ"),G=a.n(Z),q=(a("+skl"),a("M9sx"),a("//Fk")),X=a.n(q),U=a("mtWM"),$=a.n(U),O=a("mw3O"),K=a.n(O),Q=$.a.create({baseURL:"",timeout:1e3,headers:{"Content-Type":"application/x-www-form-urlencoded;"}});Q.interceptors.request.use(function(t){return"post"===t.method&&(t.data=K.a.stringify(t.data)),t},function(t){return X.a.reject(t)}),Q.interceptors.response.use(function(t){return 200!==t.status?X.a.reject(t):t},function(t){return X.a.reject(t)});var tt=Q;i.default.config.productionTip=!1,i.default.use(G.a),i.default.prototype.$axios=tt,new i.default({el:"#app",router:z,template:"<App/>",render:function(t){return t(n)},components:{App:n}})},NQ74:function(t,e,a){t.exports=a.p+"static/img/research3-7.b4eb6a8.jpg"},Nimd:function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i={render:function(){var t=this,e=t.$createElement,i=t._self._c||e;return i("div",[i("div",{staticClass:"guwen"},[t._m(0),t._v(" "),i("hr",{staticClass:"people-line",staticStyle:{margin:"10px 0 40px 0"}}),t._v(" "),i("Row",[i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("tQnf"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("p",{staticStyle:{color:"rgb(100, 100, 100)","text-align":"center","font-size":"16px"}},[t._v("Chuntian Zhang "),i("br"),t._v("Professor"),i("br")])])]),t._v(" "),i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("U6CQ"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("p",{staticStyle:{color:"rgb(100, 100, 100)","text-align":"center","font-size":"16px"}},[t._v("Zhaoxuan Yang "),i("br"),t._v("Professor"),i("br")])])])],1)],1),t._v(" "),i("div",{staticClass:"teacher"},[t._m(1),t._v(" "),i("hr",{staticClass:"people-line",staticStyle:{margin:"10px 0 40px 0"}}),t._v(" "),i("Row",[i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("p4HD"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("a",{attrs:{href:"/#/people/suyutingEnglish"}},[t._v("Yuting Su "),i("br"),t._v("Professor")])])]),t._v(" "),i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("3gOL"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("a",{attrs:{href:"/#/people/liuananEnglish"}},[t._v("An-An Liu "),i("br"),t._v("Professor")])])])],1),t._v(" "),i("Row",[i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("+Dnu"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("a",{attrs:{href:"/#/people/nieweizhiEnglish"}},[t._v("Weizhi Nie "),i("br"),t._v("Associate Professor")])])]),t._v(" "),i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("2fq6"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("a",{attrs:{href:"/#/people/liujingEnglish"}},[t._v("Jing Liu"),i("br"),t._v(" Associate Professor")])])])],1),t._v(" "),i("Row",[i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("K2Da"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("a",{attrs:{href:"/#/people/jingpeiguangEnglish"}},[t._v("Peiguang Jing"),i("br"),t._v("Assistant Professor")])])]),t._v(" "),i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("Dk4P"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("a",{attrs:{href:"/#/people/songdanEnglish"}},[t._v("Dan Song"),i("br"),t._v(" Assistant Professor")])])]),t._v(" "),i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("Cl+F"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("a",{attrs:{href:"https://ningxu.iti-tju.org/"}},[t._v("Ning Xu"),i("br"),t._v(" Assistant Professor")])])])],1)],1),t._v(" "),i("div",{staticClass:"phd"},[t._m(2),t._v(" "),i("hr",{staticClass:"people-line",staticStyle:{margin:"10px 0 40px 0"}}),t._v(" "),i("Row",[i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("8YpW"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("p",{staticClass:"people-phd"},[t._v("Yao Lu "),i("br"),t._v("Since 2014 Fall")])])]),t._v(" "),i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("Yhjq"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("p",{staticClass:"people-phd"},[i("a",{attrs:{href:"https://iti-tju.org/~yyliu/"}},[t._v("Yaoyao Liu "),i("br"),t._v("Since 2015 Fall")])])])]),t._v(" "),i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("MmyG"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("p",{staticClass:"people-phd"},[t._v("Wenhui Li "),i("br"),t._v("Since 2016 Fall")])])]),t._v(" "),i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("5GpU"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("p",{staticClass:"people-phd"},[t._v("Yuqian Li "),i("br"),t._v("Since 2017 Fall")])])])],1),t._v(" "),i("Row",[i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("bLpp"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("p",{staticClass:"people-phd"},[t._v("Hongshuo Tian "),i("br"),t._v("Since 2018 Fall")])])]),t._v(" "),i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("2iX+"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("p",{staticClass:"people-phd"},[t._v("Jiayu Li "),i("br"),t._v("Since 2018 Fall")])])]),t._v(" "),i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("G+Se"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("p",{staticClass:"people-phd"},[t._v("Qi Liang "),i("br"),t._v("Since 2019 Fall")])])]),t._v(" "),i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("JjdV"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("p",{staticClass:"people-phd"},[t._v("Song Yang "),i("br"),t._v("Since 2019 Fall")])])])],1),t._v(" "),i("Row",[i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("E2+J"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("p",{staticClass:"people-phd"},[t._v("Yan Wang "),i("br"),t._v("Since 2019 Fall")])])]),t._v(" "),i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("UEL+"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("p",{staticClass:"people-phd"},[t._v("Heyu Zhou "),i("br"),t._v("Since 2019 Fall")])])]),t._v(" "),i("Col",{attrs:{span:"6"}},[i("div",{staticClass:"people-list"},[i("img",{attrs:{src:a("D6O0"),width:"143px",height:"189px"}}),i("br"),t._v(" "),i("p",{staticClass:"people-phd"},[t._v("Yaqian Zhou "),i("br"),t._v("Since 2019 Fall")])])])],1)],1),t._v(" "),i("hr",{staticClass:"people-line",staticStyle:{margin:"10px 0 40px 0"}}),t._v(" "),i("div",{staticClass:"master"},[t._m(3),t._v(" "),i("hr",{staticClass:"people-line",staticStyle:{margin:"10px 0 40px 0"}}),t._v(" "),i("div",[t._m(4),t._v(" "),i("Row",[i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Yan Yan")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Shu Xiang")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Chuang Chen")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Kun Wang")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Hai Ding")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Pingping Liu")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Wanning Sun")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Mengmeng Xiao")])],1),t._v(" "),i("Row",[i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Jingting Wang")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Xingjian Long")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Haonan Wang")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Chunting Wang")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Jincheng Lv")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Jinghui Liu")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Yuechen Shang")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Mingxing Wang")])],1),t._v(" "),i("Row",[i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Weijie Wang")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Pengjiao Feng")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Peng Ye")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Yang Li")])],1),i("br"),t._v(" "),t._m(5),t._v(" "),i("Row",[i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Ya Wang")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Yue Zhao")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Ping Zhu")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Nian Hu")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Wenwu Jia")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Zhenlan Zhao")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Fubin Guo")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Qianyi Zhang")])],1),t._v(" "),i("Row",[i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Lu Qu")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Mengmeng Wang")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Tianshu Cui")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Daozheng Hong")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Qi Chen")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Meiqi Zhang")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Haizhao Li")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Huihui Fan")])],1),t._v(" "),i("Row",[i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Bowen Zheng")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Shida An")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Zhihui Hao")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Yuting Wu")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Yanhui Wang")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Cahngfei Yan")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Junjie Zhou")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Desheng Li")])],1),t._v(" "),i("Row",[i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Chunping Zhang")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Yangyang Xu")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Minjie Ren")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Yixin Wang")])],1),t._v(" "),i("br"),t._v(" "),t._m(6),t._v(" "),i("Row",[i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Han Wang")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Min Yuan")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Weikang Wang")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Xin Wen")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Jiaqi Zhang")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Ziwen Yang")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Qianqian Dou")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Xuqing Ye")])],1),t._v(" "),i("Row",[i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Yaxin Li")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Rongxuan Lu")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Jing Zhang")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Lijuan Zhang")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Wei Zhao")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Wenjie Tian")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Dangdang Zhou")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Huawei Xia")])],1),t._v(" "),i("Row",[i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Qiankun Han")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Tengfei Fan")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Yunxin Yuan")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Xiaoqi Shi")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Sijie Gao")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Tong Liu")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Ting Zhang")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Yingchen Zhai")])],1),t._v(" "),i("Row",[i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Zimu Lu")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Tianbao Li")])],1)],1)]),t._v(" "),i("div",{staticClass:"master"},[t._m(7),t._v(" "),i("hr",{staticClass:"people-line",staticStyle:{margin:"10px 0 40px 0"}}),t._v(" "),i("div",[i("Row",[i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Bingyang Huang")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Wenqing Gao")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Peipei Li")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Haiyi Wang")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Zhongyang Wang")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Yong Xu")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Meili Zhi")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Yazhou Zhao")])],1),t._v(" "),i("Row",[i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Tingting Pu")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Xiaorong Zhu")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Qun Cao")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Yawei Chen")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Jiaxing Du")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Fuwu Li")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Xiaoxue Li")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Qianxi Li")])],1),t._v(" "),i("Row",[i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Huijing Wang")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Ping Wang")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Chuanzhong Xu")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Zhengyu Zhao")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Yang Li")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Fan Yu")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Yang An")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Huiyun Cheng")])],1),t._v(" "),i("Row",[i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Jiangpeng Fu")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Huimin Gu")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Yahui Hao")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Nannan Liu")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Hongbin Guo")]),t._v(" "),i("Col",{staticClass:"people-master",attrs:{span:"3"}},[t._v("Zhengnan Li")])],1)],1)])])},staticRenderFns:[function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("p",{staticClass:"people-title"},[this._v("Consultant")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("p",{staticClass:"people-title"},[this._v("Faculty")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("p",{staticClass:"people-title"},[this._v("Ph.D. Students")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("p",{staticClass:"people-title"},[this._v("Master Students")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("span",{staticClass:"people-master"},[this._v("Since 2017 Fall"),e("br")])},function(){var t=this.$createElement,e=this._self._c||t;return e("span",{staticClass:"people-master"},[this._v("Since 2018 Fall"),e("br")])},function(){var t=this.$createElement,e=this._self._c||t;return e("span",{staticClass:"people-master"},[this._v("Since 2019 Fall"),e("br")])},function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("p",{staticClass:"people-title"},[this._v("Alumi")])])}]};var s=a("VU/8")({name:"PeopleMenuen"},i,!1,function(t){a("AApq")},"data-v-fe317b8c",null).exports,n=a("6BGy"),o={name:"people-mainEnglish",components:{HomeHeaderen:a("E7Bq").a,HomeFooter:n.a,PeopleMenuen:s},data:function(){return{activeIndex:"/people"}},methods:{myajaxs:function(){this.$axios({method:"post",url:"/peopleEnglish"}).then(function(t){console.log(t)}).catch(function(t){console.log(t)})}}},r={render:function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("Layout",[e("Header",{staticStyle:{position:"fixed",right:"0",left:"0","z-index":"1030"}},[e("home-headeren",{attrs:{"active-name":this.activeIndex}})],1),this._v(" "),e("Content",[e("people-menuen")],1),this._v(" "),e("Footer",[e("home-footer")],1)],1)],1)},staticRenderFns:[]};var l=a("VU/8")(o,r,!1,function(t){a("0nMg")},"data-v-1f8959d2",null);e.default=l.exports},PYLQ:function(t,e,a){t.exports=a.p+"static/img/research2-2.8467014.jpg"},Peex:function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i=a("byf9"),s={render:function(){var t=this,e=t.$createElement,i=t._self._c||e;return i("div",[i("div",{staticClass:"breadcrumb"},[i("Breadcrumb",[i("BreadcrumbItem",{attrs:{to:"/"}},[t._v("主页")]),t._v(" "),i("BreadcrumbItem",{attrs:{to:"/people"}},[t._v("团队")]),t._v(" "),i("BreadcrumbItem",[t._v("刘婧")])],1)],1),t._v(" "),i("div",{staticClass:"content-box"},[i("div",[i("Row",[i("Col",{attrs:{span:"5"}},[i("div",{staticClass:"people-img"},[i("img",{attrs:{src:a("2fq6"),width:"143px",height:"189px"}})])]),t._v(" "),i("Col",{attrs:{span:"19"}},[i("div",{staticClass:"people-intro"},[i("span",{staticStyle:{"font-size":"23px",color:"black","font-weight":"bold"}},[t._v("刘    婧")]),i("span",{staticStyle:{"padding-left":"20px"}},[t._v("助理教授/硕导")]),i("br"),i("br"),t._v(" "),i("span",[t._v("电气自动化与信息工程学院")]),i("br"),t._v(" "),i("span",[t._v("天津大学")]),i("br"),t._v(" "),i("span",[t._v("邮箱：jliu_tju@tju.edu.cn")]),i("br")])])],1)],1),t._v(" "),t._m(0),t._v(" "),t._m(1)])])},staticRenderFns:[function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("h2",[this._v("简    介")]),this._v(" "),e("hr",{staticClass:"research-line",staticStyle:{margin:"15px 0"}}),this._v(" "),e("span",{staticClass:"content"},[this._v("2017年,刘婧获得上海交通大学电子信息与电气工程学院信息与通信工程专业博士学位。现任天津大学电气自动化与信息工程学院助理教授（讲师）。她的研究方向包括数字图像处理、视频图像编码、计算机视觉。 ")])])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",[a("h2",[t._v("论    文")]),t._v(" "),a("hr",{staticClass:"research-line",staticStyle:{margin:"15px 0"}}),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8713480"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[1]    BE-CALF: Bit-Depth Enhancement by Concatenating All Level Features of DNN.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jing Liu, Wanning Sun, Yuting Su, Peiguang Jing, Xiaokang Yang.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Image Processing. 2019.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8703748"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[2]    Fast Context-Adaptive Bit-Depth Enhancement via Linear Interpolation.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jing Liu, Bing Yang, Yuting Su, Pingping Liu.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access. 2019.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8656492"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[3]     Multi-Channel Decomposition in Tandem With Free-Energy Principle for Reduced-Reference Image Quality Assessment.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Wenhan Zhu, Guangtao Zhai, Xiongkuo Min, Menghan Hu, Jing Liu, Guodong Guo, Xiaokang Yang.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Multimedia. 2019.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8636159"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[4]     Spatiotemporal Symmetric Convolutional Neural Network for Video Bit-Depth Enhancement.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jing Liu, Pingping Liu, Yuting Su, Peiguang Jing, Xiaokang Yang. ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Multimedia. 2019.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8585006"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[5]     Recurrent Conditional Generative Adversarial Network for Image Deblurring.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jing Liu, Wanning Sun, Mengjie Li. ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access. 2018.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8353302"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[6]    A Framework of Joint Low-Rank and Sparse Regression for Image Memorability Prediction.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Peiguang Jing, Yuting Su, Liqiang Nie, Huiming Gu, Jing Liu, Meng Wang. ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Circuits and Systems for Video Technology. 2018.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8421587"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[7]   Improving Bit-Depth Expansion via Context-Aware MMSE Optimization (CAMO).")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jing Liu, Wanning Sun, Peiguang Jing, Jiexiao Yu, Yuting Su. ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access. 2018.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8283657"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[8]   IPAD: Intensity Potential for Adaptive De-Quantization.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jing Liu, Guangtao Zhai, Anan Liu, Xiaokang Yang, Xibin Zhao, Chang Wen Chen. ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Image Processing. 2018.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8241862"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[9]    Blind Quality Assessment Based on Pseudo-Reference Image. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Xiongkuo Min, Ke Gu, Guangtao Zhai, Xiaokang Yang, Chang Wen Chen. ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Multimedia. 2017.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8233154"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[10]    Low-Rank Multi-View Embedding Learning for Micro-Video Popularity Prediction. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Peiguang Jing, Yuting Su, Liqiang Nie, Xu Bai, Jing Liu, Meng Wang. ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Knowledge and Data Engineering. 2017.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8099567"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[11]   A-Lamp: Adaptive Layout-Aware Multi-patch Deep Convolutional Neural Network for Photo Aesthetic Assessment. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Shuang Ma, Jing Liu, Chang Wen Chen. ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Honolulu, HI, USA. 2017.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8019511"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[12]    Dynamic backlight scaling considering ambient luminance for mobile energy saving. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Wei Sun, Guangtao Zhai, Xiongkuo Min, Yutao Liu, Siwei Ma, Jing Liu, Jiantao Zhou, Xianming Liu.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE International Conference on Multimedia and Expo (ICME). Hongkong, China. 2017.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8019328"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[13]    IPAD: Intensity potential for adaptive de-quantization. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jing Liu, Guangtao Zhai, Xiaokang Yang, Menghan Hu, Chang Wen Chen.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE International Conference on Multimedia and Expo (ICME). Hongkong, China. 2017..")])])])])}]};var n=a("VU/8")({name:"LiujingContent"},s,!1,function(t){a("pPG9")},"data-v-0e65b402",null).exports,o={name:"liujing",components:{HomeFooter:a("6BGy").a,LiujingContent:n,HomeHeader:i.a},data:function(){return{activeIndex:"/people"}},methods:{myajaxs:function(){this.$axios({method:"post",url:"/people/liujing"}).then(function(t){console.log(t)}).catch(function(t){console.log(t)})}}},r={render:function(){var t=this.$createElement,e=this._self._c||t;return e("Layout",[e("Header",{staticStyle:{position:"fixed",right:"0",left:"0","z-index":"1030"}},[e("home-header",{attrs:{"active-name":this.activeIndex}})],1),this._v(" "),e("Content",[e("liujing-content")],1),this._v(" "),e("Footer",[e("home-footer")],1)],1)},staticRenderFns:[]};var l=a("VU/8")(o,r,!1,function(t){a("ePIu")},"data-v-3a7e6e8e",null);e.default=l.exports},"Q5C+":function(t,e){},Q7kd:function(t,e){},QLm7:function(t,e){},QOC1:function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i=a("byf9"),s={render:function(){var t=this,e=t.$createElement,i=t._self._c||e;return i("div",{staticClass:"content-box"},[i("div",{staticClass:"breadcrumb"},[i("Breadcrumb",[i("BreadcrumbItem",{attrs:{to:"/home"}},[t._v("主页")]),t._v(" "),i("BreadcrumbItem",{attrs:{to:"/research"}},[t._v("研究方向")]),t._v(" "),i("BreadcrumbItem",[t._v("多媒体计算")])],1)],1),t._v(" "),i("div",[i("h1",[t._v("    "),i("Icon",{attrs:{type:"ios-fastforward"}}),t._v("  多媒体计算")],1),t._v(" "),t._m(0)]),t._v(" "),i("Collapse",{staticClass:"collapse",staticStyle:{"font-size":"13px"},model:{value:t.value1,callback:function(e){t.value1=e},expression:"value1"}},[i("Panel",{attrs:{name:"1"}},[t._v("\n        1.简介\n        "),i("p",{staticClass:"me-collapse-content",attrs:{slot:"content"},slot:"content"},[t._v("\n                  随着信息时代的发展和时代需求的不断更新，多媒体视觉信息爆炸性增长，对于视觉语义的分析和理解逐渐走进人们的视野。对视觉语义的分析和理解主要应用于现如今多媒体环境下视频分类，视频推荐，情感分析，视觉记忆度分析等等具有实际应用价值的环境之中。其利用张量分解等工具对视觉信息进行相应分析处理。在张量分解领域，本实验室主要关注时间序列分析，视频序列分类等。在视觉语义理解领域，本实验室主要关注于视频的事件检测，视觉信息的情感分析，视觉信息的记忆度等等。\n        ")])]),t._v(" "),i("Panel",{attrs:{name:"2"}},[t._v("\n        2. 张量分解\n        "),i("p",{staticClass:"me-collapse-content",attrs:{slot:"content"},slot:"content"},[i("span",[t._v("\n              2.1高阶时间序列分析"),i("br"),t._v("\n        时间序列分析通过历史观测值去预测系统或现象的演变，其核心过程是通过一系列的观测值确定现象的内在本质。从基于时间序列预测的模型角度分析，当前的预测模型可以大致分为参数化的预测模型与非参数化的预测模型。在参数化的预测模型中，时间序列的潜在结构可以由带有未知参数的预定义函数决定。\n            ")]),i("br"),t._v(" "),i("img",{staticClass:"me-img",attrs:{src:a("HVvy"),width:"800px"}}),i("br"),i("br"),t._v(" "),i("span",[t._v("\n             2.2高阶数据表示学习"),i("br"),t._v("\n         通过网络媒体平台及各种传感器设备所收集到的信息天然呈现高阶多维特性，为更好的利用数据原始内嵌的关联性结构信息解决多媒体数据的表示问题， 课题组利用张量对数据进行建模，并通过张量分解及张量学习的方式，获取更本质的特征表示，以更好地解决语义鸿沟问题。\n            ")]),i("br"),t._v(" "),i("br"),t._v(" "),i("img",{staticClass:"me-img",attrs:{src:a("BU5W"),width:"800px"}}),i("br"),i("br")])]),t._v(" "),i("Panel",{attrs:{name:"3"}},[t._v("\n        3. 视觉语义理解\n        "),i("p",{staticClass:"me-collapse-content",attrs:{slot:"content"},slot:"content"},[i("span",[t._v("\n              3.1 情感分析"),i("br"),t._v("\n        视觉情感分析的目的是使用带有主观感情色彩的方式表述图像和视频，并使计算机能够检测和表达这些信息。伴随着社会化媒体的兴盛和充沛训练数据的出现，深度学习之类的技术革命给该领域带来新的机遇和挑战。从视觉情感语义提取框架出发，对传统视觉情感分析中视觉特征提取、情感空间建立和特征与情感的映射等关键技术进行综述；并对基于中间表达层、目标对象检测的视觉情感分析以及大数据背景下深度学习技术在该领域的应用进行论述。\n\n            ")]),i("br"),t._v(" "),i("img",{staticClass:"me-img",attrs:{src:a("xt5J"),width:"800px"}}),i("br"),i("br"),t._v(" "),i("span",[t._v("\n              3.2 时尚分析"),i("br"),t._v("\n        互联网的快速普及和在线购物平台的蓬勃发展使得网购服饰成为了一种潮流。随着人工智能技术的发展，时尚智能分析不仅可以给消费者提供个性化服务，预测时尚的流行趋势，还可以推荐搭配的单品以及对时尚搭配的兼容度进行预测。在此背景下，聚焦于时尚搭配，兼容度评分预测等一系列问题的研究。\n\n            ")]),i("br"),i("br"),t._v(" "),i("img",{staticClass:"me-img",attrs:{src:a("iovA"),width:"800px"}}),i("br"),i("br"),t._v(" "),i("span",[t._v("\n              3.3 图像记忆度"),i("br"),t._v("\n        目前，相机技术和设备的日益普及正在引发数字图像的指数爆炸式增长。虽然人类有在记忆各种类型的图像方面具有天生的能力，然而并不是所有的图像都以等同的方式驻留在我们的脑海中。一些图像虽然只是惊鸿一瞥，但是却让人记忆深刻，而其他的则会从我们的记忆中消失。图像可记忆度是用于测量用户在特定一段时间内对图像可记忆程度。近年来，由于图像可记忆度在教育、多媒体、交互设计和广告设计等领域的潜在的商业和应用价值，吸引了越来越多的研究者进行研究。例如，在图像/视频摘要应用中，图像可记忆度用来从用户图像集中挑选最难忘的图像组成图像/视频摘要集。在商业广告应用中，图像可记忆度还可以用于增强用户对目标品牌的印象度。\n            ")]),i("br"),i("br"),t._v(" "),i("img",{staticClass:"me-img",attrs:{src:a("hA1W"),width:"800px"}}),i("br"),i("br"),t._v(" "),i("span",[t._v("\n              3.4 短视频语义分析"),i("br"),t._v("\n        短视频作为用户生成内容的新趋势，在各种社交平台上广泛传播。 短视频的流行是因为它更好地适应了现代社会快节奏的特性，以社交传播为导向。区别于传统的视频，短视频是由个人用户创建的并且包含一些独特特性的短视频。短视频倾向于向观众概述一个相对简单但完整的故事，即在有限的时间段内，试图尽可能地凝练和最大化想要表达的内容，从而创造更有吸引力的故事。课题组在本方向上重点解决短视频流行度预测，短视频事件检测，短视频多标签分类等问题。\n            ")]),i("br"),i("br"),t._v(" "),i("img",{staticClass:"me-img",attrs:{src:a("jdyf"),width:"800px"}}),i("br"),i("br")])]),t._v(" "),i("Panel",{attrs:{name:"4"}},[t._v("\n        4. 论文\n        "),i("p",{staticClass:"me-collapse-content",attrs:{slot:"content"},slot:"content"},[i("span",[t._v("\n               [1] Jing P, Su Y, Li Z, et al. Low-rank regularized tensor discriminant representation for image set classification[J]. Signal Processing, 2019, 156: 62-70.\n[2] Su Y, Bai X, Jian P, et al. Low-rank approximation-based tensor decomposition model for subspace clustering[J]. Electronics Letters, 2019, 55(7): 406-408.\n[3] Zhang J, Li Z, Jing P, et al. Tensor-driven low-rank discriminant analysis for image set classification[J]. Multimedia Tools and Applications, 2019, 78(4): 4001-4020.\n[4] Jing P, Su Y, Nie L, et al. A framework of joint low-rank and sparse regression for image memorability prediction[J]. IEEE Transactions on Circuits and Systems for Video Technology, 2018, 29(5): 1296-1309."),i("br"),t._v("\n[5] Jing P, Su Y, Jin X, et al. High-order temporal correlation model learning for time-series prediction[J]. IEEE transactions on cybernetics, 2018, 49(6): 2385-2397."),i("br"),t._v("\n[6] Jing P, Su Y, Xu C, et al. HyperSSR: A hypergraph based semi-supervised ranking method for visual search reranking[J]. Neurocomputing, 2018, 274: 50-57."),i("br"),t._v("\n[7] Zhang J, Li X, Jing P, et al. Low-rank regularized heterogeneous tensor decomposition for subspace clustering[J]. IEEE Signal Processing Letters, 2017, 25(3): 333-337."),i("br"),t._v("\n[8] Jing P, Su Y, Nie L, et al. Low-rank multi-view embedding learning for micro-video popularity prediction[J]. IEEE Transactions on Knowledge and Data Engineering, 2017, 30(8): 1519-1532."),i("br"),t._v("\n[9] Jing P, Su Y, Nie L, et al. Predicting image memorability through adaptive transfer learning from external sources[J]. IEEE Transactions on Multimedia, 2016, 19(5): 1050-1062."),i("br"),t._v("\n[10] Zhang L, Jing P, Su Y, et al. SnapVideo: personalized video generation for a sightseeing trip[J]. IEEE transactions on cybernetics, 2016, 47(11): 3866-3878."),i("br"),t._v("\n[11] Jing P, Su Y, Nie L, et al. Predicting image memorability through adaptive transfer learning from external sources[J]. IEEE Transactions on Multimedia, 2016, 19(5): 1050-1062."),i("br"),t._v(" "),i("br")]),i("br")])])],1)],1)},staticRenderFns:[function(){var t=this.$createElement,e=this._self._c||t;return e("p",{staticClass:"research-people"},[e("span",[this._v("团队成员")]),e("br"),this._v(" "),e("span",[e("a",{attrs:{href:"/#/people/suyuting"}},[this._v("苏育挺（教授）")]),this._v("    "),e("a",{attrs:{href:"/#/people/jingpeiguang"}},[this._v("井佩光（助理教授)")]),e("br"),this._v("\n               张美琪（硕士生）  武宇廷（硕士生） 李德盛（硕士生）"),e("br"),this._v("\n          洪道政（硕士生）  陈    琦（硕士生） 崔天舒（硕士生）"),e("br")])])}]};var n=a("VU/8")({name:"ResearchFiveContent"},s,!1,function(t){a("ny3f")},"data-v-325b888a",null).exports,o={name:"research5",components:{HomeFooter:a("6BGy").a,ResearchFiveContent:n,HomeHeader:i.a},data:function(){return{activeIndex:"/research"}},methods:{myajaxs:function(){this.$axios({method:"post",url:"/research/research5"}).then(function(t){console.log(t)}).catch(function(t){console.log(t)})}}},r={render:function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("Layout",[e("Header",{staticStyle:{position:"fixed",right:"0",left:"0","z-index":"1030"}},[e("home-header",{attrs:{"active-name":this.activeIndex}})],1),this._v(" "),e("Content",[e("research-five-content")],1),this._v(" "),e("Footer",[e("home-footer")],1)],1)],1)},staticRenderFns:[]};var l=a("VU/8")(o,r,!1,function(t){a("oBQg")},"data-v-68c37cce",null);e.default=l.exports},RWbm:function(t,e){},S0BT:function(t,e,a){t.exports=a.p+"static/img/research3-1.868681c.jpg"},S0lg:function(t,e){},SdAV:function(t,e){},T63n:function(t,e){},TLpD:function(t,e,a){t.exports=a.p+"static/img/research1-8.506f702.jpg"},U6CQ:function(t,e,a){t.exports=a.p+"static/img/yangzhaoxuan.4db12e5.jpg"},U9St:function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i=a("byf9"),s=a("6BGy"),n={render:function(){var t=this,e=t.$createElement,i=t._self._c||e;return i("div",[i("div",{staticClass:"breadcrumb"},[i("Breadcrumb",[i("BreadcrumbItem",{attrs:{to:"/"}},[t._v("主页")]),t._v(" "),i("BreadcrumbItem",{attrs:{to:"/people"}},[t._v("团队")]),t._v(" "),i("BreadcrumbItem",[t._v("宋丹")])],1)],1),t._v(" "),i("div",{staticClass:"content-box"},[i("div",[i("Row",[i("Col",{attrs:{span:"5"}},[i("div",{staticClass:"people-img"},[i("img",{attrs:{src:a("Dk4P"),width:"143px",height:"189px"}})])]),t._v(" "),i("Col",{attrs:{span:"19"}},[i("div",{staticClass:"people-intro"},[i("span",{staticStyle:{"font-size":"23px",color:"black","font-weight":"bold"}},[t._v("宋    丹")]),i("span",{staticStyle:{"padding-left":"20px"}},[t._v("助理教授")]),i("br"),i("br"),t._v(" "),i("span",[t._v("电气自动化与信息工程学院")]),i("br"),t._v(" "),i("span",[t._v("天津大学")]),i("br"),t._v(" "),i("span",[t._v("邮箱：dan.song@tju.edu.cn")]),i("br"),t._v(" "),i("span",[i("router-link",{attrs:{to:"https://github.com/dan-song"}},[t._v("[GitHub]")]),t._v(" "),i("router-link",{attrs:{to:"https://scholar.google.com.hk/citations?hl=zh-CN&user=G-mHRrEAAAAJ"}},[t._v("[Google Scholar]")])],1),i("br")])])],1)],1),t._v(" "),t._m(0),t._v(" "),t._m(1)])])},staticRenderFns:[function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("h2",[this._v("简    介")]),this._v(" "),e("hr",{staticClass:"research-line",staticStyle:{margin:"15px 0"}}),this._v(" "),e("span",{staticClass:"content"},[this._v("宋丹现任天津大学电气与信息工程学院讲师。她是"),e("a",{attrs:{href:"https://www.iti-tju.org/"}},[this._v("天津大学多媒体实验室")]),this._v("的一名成员。2018年，她在中国浙江大学获得了博士学位。她曾是英国国家计算机动画中心(NCCA)的学术访问学者。她的研究方向包括计算机图形学、计算机视觉、机器学习和虚拟装配。曾在TCSVT、PR、CGF、CAD等高质量期刊和会议上发表论文。曾担任ACM MM、CVM、MTAP、NEPL等一系列论坛的审稿人。")])])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",[a("h2",[t._v("论    文")]),t._v(" "),a("hr",{staticClass:"research-line",staticStyle:{margin:"15px 0"}}),t._v(" "),a("div",[a("span",{staticStyle:{"font-size":"15px",color:"#4590a3"}},[a("strong",[t._v("2019")])])]),a("br"),t._v(" "),a("div",{staticClass:"publication"},[a("p",{staticClass:"p title"},[a("strong",[t._v("[1]   Joint Heterogeneous Feature Learning and Distribution Alignment for 2D Image-Based 3D Object Retrieval. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Su, Y. T., Li, Y. Q., Nie, W. Z., "),a("strong",[t._v("Song, D.")]),t._v(", & Liu, A. A.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Circuits and Systems for Video Technology, 2019. ")])]),t._v(" "),a("div",{staticClass:"publication"},[a("p",{staticClass:"p title"},[a("strong",[t._v("[2]   Illumination-aware Faster R-CNN for Robust Multispectral Pedestrian Detection. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Li, C., "),a("strong",[t._v("Song, D.")]),t._v(", Tong, R., & Tang, M. ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("Pattern Recognition, 85, 161-171, 2019 ")])]),t._v(" "),a("div",{staticClass:"publication"},[a("p",{staticClass:"p title"},[a("strong",[t._v("[3]   A Shell Space Constrained Approach for Curve Design on Surface Meshes. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jin, Y., "),a("strong",[t._v("Song, D.")]),t._v(", Wang, T., Huang, J., Song, Y., & He, L.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("Computer-Aided Design, 113, 24-34, 2019 ")])]),t._v(" "),a("div",{staticClass:"publication"},[a("p",{staticClass:"p title"},[a("strong",[t._v("[4]   Unsupervised Feature Learning With Graph Embedding for View-Based 3D Model Retrieval. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Su, Y., Li, W., Nie, W., "),a("strong",[t._v("Song, D.")]),t._v(", & Liu, A. A.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access, 7, 95285-95296, 2019 ")])]),t._v(" "),a("div",{staticClass:"publication"},[a("p",{staticClass:"p title"},[a("strong",[t._v("[5]   Multi-View Hierarchical Fusion Network for 3D Object Retrieval and Classification. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Liu, A. A., Hu, N., "),a("strong",[t._v("Song, D.")]),t._v(", Guo, F. B., Zhou, H. Y., & Hao, T.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access, 7, 153021-153030, 2019 ")])]),t._v(" "),a("div",{staticClass:"publication"},[a("p",{staticClass:"p title"},[a("strong",[t._v("[6]   Monocular image based 3d model retrieval.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Li, W. H., Liu, A. A., Nie, W. Z., "),a("strong",[t._v("Song, D.")]),t._v(" et al.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("SHREC 2019' MI3DOR ")])]),t._v(" "),a("div",{staticClass:"publication"},[a("p",{staticClass:"p title"},[a("strong",[t._v("[7]   End-to-End Visual Domain Adaptation Network for Cross-Domain 3D CPS Data Retrieval.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Liu, A. A., Xiang, S., Nie W. Z., & "),a("strong",[t._v("Song, D.")]),t._v(".")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access, 7, 118630-118638, 2019 ")])]),t._v(" "),a("div",{staticClass:"publication"},[a("p",{staticClass:"p title"},[a("strong",[t._v("[8]   SP-VITON: shape-preserving image-based virtual try-on network.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[a("strong",[t._v("Song, D.")]),t._v(", Li, T., Mao, Z., & Liu, A. A.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" Multimedia Tools and Applications, 2019 ")])]),t._v(" "),a("div",{staticClass:"publication"},[a("p",{staticClass:"p title"},[a("strong",[t._v("[9]   Location Emotion Recognition for Travel Recommendation based on Social Network.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Nie, W., Ding, H., "),a("strong",[t._v("Song, D.")]),t._v(", & Long, X. ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" Signal, Image and Video Processing, 13(7): 1259-1266, 2019 ")])]),t._v(" "),a("div",[a("span",{staticStyle:{"font-size":"15px",color:"#4590a3"}},[a("strong",[t._v("2018")])])]),a("br"),t._v(" "),a("div",{staticClass:"publication"},[a("p",{staticClass:"p title"},[a("strong",[t._v("[1]   Data-Driven 3-D Human Body Customization With a Mobile Device.  ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[a("strong",[t._v("Song, D.")]),t._v(", Tong, R., Du, J., Zhang, Y., & Jin, Y.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access, 6, 27939-27948, 2018 ")])]),t._v(" "),a("div",{staticClass:"publication"},[a("p",{staticClass:"p title"},[a("strong",[t._v("[2]   Multispectral Pedestrian Detection via Simultaneous Detection and Segmentation.  ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Li, C., "),a("strong",[t._v("Song, D.")]),t._v(", Tong, R., & Tang, M.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("British Machine Vision Conference, 2018 ")])]),t._v(" "),a("div",{staticClass:"publication"},[a("p",{staticClass:"p title"},[a("strong",[t._v("[3]   “Edutainment 2017” a visual and semantic representation of 3D face model for reshaping face in images. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Du J., "),a("strong",[t._v("Song, D.")]),t._v(", Tang Y., Tong, R., & Tang, M.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("British Machine Vision Conference, 2018 ")])]),t._v(" "),a("div",[a("span",{staticStyle:{"font-size":"15px",color:"#4590a3"}},[a("strong",[t._v("2017")])])]),a("br"),t._v(" "),a("div",{staticClass:"publication"},[a("p",{staticClass:"p title"},[a("strong",[t._v("[1]   Clothes size prediction from dressed-human silhouettes.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[a("strong",[t._v("Song, D.")]),t._v(", Tong, R., Chang, J., Wang, T., Du J., Tang, M., & Zhang, J. J.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("Computer Graphics Forum, 35, 7, 147-156, 2016 ")])]),t._v(" "),a("div",[a("span",{staticStyle:{"font-size":"15px",color:"#4590a3"}},[a("strong",[t._v("2016")])])]),a("br"),t._v(" "),a("div",{staticClass:"publication"},[a("p",{staticClass:"p title"},[a("strong",[t._v("[1]   3D Body Shapes Estimation from Dressed-Human Silhouettes.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[a("strong",[t._v("Song, D.")]),t._v(", Tong, R., Chang, J., Yang, X., Tang, M., & Zhang, J. J. ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("Computer Graphics Forum, 35, 7, 147-156, 2016 ")])])])}]};var o={name:"songdan",components:{SongdanContent:a("VU/8")({name:"SongdanContent"},n,!1,function(t){a("wLWH")},"data-v-777c9433",null).exports,HomeFooter:s.a,HomeHeader:i.a},data:function(){return{activeIndex:"/people"}},methods:{myajaxs:function(){this.$axios({method:"post",url:"/people/songdan"}).then(function(t){console.log(t)}).catch(function(t){console.log(t)})}}},r={render:function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("Layout",[e("Header",{staticStyle:{position:"fixed",right:"0",left:"0","z-index":"1030"}},[e("home-header",{attrs:{"active-name":this.activeIndex}})],1),this._v(" "),e("Content",[e("songdan-content")],1),this._v(" "),e("Footer",[e("home-footer")],1)],1)],1)},staticRenderFns:[]};var l=a("VU/8")(o,r,!1,function(t){a("ACsK")},"data-v-6361b35f",null);e.default=l.exports},"UEL+":function(t,e,a){t.exports=a.p+"static/img/周河宇.4da430d.jpg"},Uylg:function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i=a("E7Bq"),s={render:function(){var t=this,e=t.$createElement,i=t._self._c||e;return i("div",[i("div",{staticClass:"breadcrumb"},[i("Breadcrumb",[i("BreadcrumbItem",{attrs:{to:"/"}},[t._v("HOME")]),t._v(" "),i("BreadcrumbItem",{attrs:{to:"/peopleEnglish"}},[t._v("PEOPLE")]),t._v(" "),i("BreadcrumbItem",[t._v("Jing Liu")])],1)],1),t._v(" "),i("div",{staticClass:"content-box"},[i("div",[i("Row",[i("Col",{attrs:{span:"5"}},[i("div",{staticClass:"people-img"},[i("img",{attrs:{src:a("2fq6"),width:"143px",height:"189px"}})])]),t._v(" "),i("Col",{attrs:{span:"19"}},[i("div",{staticClass:"people-intro"},[i("span",{staticStyle:{"font-size":"23px",color:"black","font-weight":"bold"}},[t._v("Jing Liu")]),i("span",{staticStyle:{"padding-left":"20px"}},[t._v("Assistant Professor")]),i("br"),i("br"),t._v(" "),i("span",[t._v("School of Electrical and Information Engineering")]),i("br"),t._v(" "),i("span",[t._v("Tianjin University, China")]),i("br"),t._v(" "),i("span",[t._v("Email：jliu_tju@tju.edu.cn")]),i("br")])])],1)],1),t._v(" "),t._m(0),t._v(" "),t._m(1)])])},staticRenderFns:[function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("h2",[this._v("Introduction")]),this._v(" "),e("hr",{staticClass:"research-line",staticStyle:{margin:"15px 0"}}),this._v(" "),e("span",{staticClass:"content"},[this._v("In 2017, Jing Liu received her PhD in information and communication engineering from the school of electronic information and electrical engineering, Shanghai Jiaotong University. She is now an assistant professor (lecturer) in school of electrical automation and information engineering, tianjin university. Her research interests include digital image processing, video image coding, and computer vision.")])])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",[a("h2",[t._v("Publication")]),t._v(" "),a("hr",{staticClass:"research-line",staticStyle:{margin:"15px 0"}}),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8713480"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[1]    BE-CALF: Bit-Depth Enhancement by Concatenating All Level Features of DNN.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jing Liu, Wanning Sun, Yuting Su, Peiguang Jing, Xiaokang Yang.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Image Processing. 2019.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8703748"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[2]    Fast Context-Adaptive Bit-Depth Enhancement via Linear Interpolation.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jing Liu, Bing Yang, Yuting Su, Pingping Liu.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access. 2019.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8656492"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[3]     Multi-Channel Decomposition in Tandem With Free-Energy Principle for Reduced-Reference Image Quality Assessment.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Wenhan Zhu, Guangtao Zhai, Xiongkuo Min, Menghan Hu, Jing Liu, Guodong Guo, Xiaokang Yang.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Multimedia. 2019.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8636159"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[4]     Spatiotemporal Symmetric Convolutional Neural Network for Video Bit-Depth Enhancement.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jing Liu, Pingping Liu, Yuting Su, Peiguang Jing, Xiaokang Yang. ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Multimedia. 2019.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8585006"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[5]     Recurrent Conditional Generative Adversarial Network for Image Deblurring.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jing Liu, Wanning Sun, Mengjie Li. ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access. 2018.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8353302"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[6]    A Framework of Joint Low-Rank and Sparse Regression for Image Memorability Prediction.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Peiguang Jing, Yuting Su, Liqiang Nie, Huiming Gu, Jing Liu, Meng Wang. ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Circuits and Systems for Video Technology. 2018.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8421587"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[7]   Improving Bit-Depth Expansion via Context-Aware MMSE Optimization (CAMO).")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jing Liu, Wanning Sun, Peiguang Jing, Jiexiao Yu, Yuting Su. ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access. 2018.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8283657"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[8]   IPAD: Intensity Potential for Adaptive De-Quantization.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jing Liu, Guangtao Zhai, Anan Liu, Xiaokang Yang, Xibin Zhao, Chang Wen Chen. ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Image Processing. 2018.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8241862"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[9]    Blind Quality Assessment Based on Pseudo-Reference Image. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Xiongkuo Min, Ke Gu, Guangtao Zhai, Xiaokang Yang, Chang Wen Chen. ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Multimedia. 2017.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8233154"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[10]    Low-Rank Multi-View Embedding Learning for Micro-Video Popularity Prediction. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Peiguang Jing, Yuting Su, Liqiang Nie, Xu Bai, Jing Liu, Meng Wang. ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Knowledge and Data Engineering. 2017.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8099567"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[11]   A-Lamp: Adaptive Layout-Aware Multi-patch Deep Convolutional Neural Network for Photo Aesthetic Assessment. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Shuang Ma, Jing Liu, Chang Wen Chen. ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Honolulu, HI, USA. 2017.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8019511"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[12]    Dynamic backlight scaling considering ambient luminance for mobile energy saving. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Wei Sun, Guangtao Zhai, Xiongkuo Min, Yutao Liu, Siwei Ma, Jing Liu, Jiantao Zhou, Xianming Liu.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE International Conference on Multimedia and Expo (ICME). Hongkong, China. 2017.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8019328"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[13]    IPAD: Intensity potential for adaptive de-quantization. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jing Liu, Guangtao Zhai, Xiaokang Yang, Menghan Hu, Chang Wen Chen.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE International Conference on Multimedia and Expo (ICME). Hongkong, China. 2017..")])])])])}]};var n=a("VU/8")({name:"LiujingContenten"},s,!1,function(t){a("dnio")},"data-v-3d260120",null).exports,o={name:"liujingEnglish",components:{HomeFooter:a("6BGy").a,LiujingContenten:n,HomeHeaderen:i.a},data:function(){return{activeIndex:"/people"}},methods:{myajaxs:function(){this.$axios({method:"post",url:"/people/liujingEnglish"}).then(function(t){console.log(t)}).catch(function(t){console.log(t)})}}},r={render:function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("Layout",[e("Header",{staticStyle:{position:"fixed",right:"0",left:"0","z-index":"1030"}},[e("home-headeren",{attrs:{"active-name":this.activeIndex}})],1),this._v(" "),e("Content",[e("liujing-contenten")],1),this._v(" "),e("Footer",[e("home-footer")],1)],1)],1)},staticRenderFns:[]};var l=a("VU/8")(o,r,!1,function(t){a("ZgOq")},"data-v-35281916",null);e.default=l.exports},"UzE/":function(t,e){},VFjw:function(t,e){},Vavi:function(t,e,a){t.exports=a.p+"static/img/research1-7.0d9d651.png"},VixX:function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i=a("byf9"),s={render:function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"content-box"},[a("Row",[a("Col",{attrs:{span:"6"}},[a("Menu",{staticClass:"menu",staticStyle:{width:"200px","background-color":"rgb(245, 247, 249)","margin-top":"50px"},attrs:{theme:"light","active-name":"4"}},[a("MenuItem",{attrs:{name:"1",to:"/publication/publication2019"}},[a("Icon",{attrs:{type:"md-document"}}),t._v("\n          2019\n        ")],1),t._v(" "),a("MenuItem",{attrs:{name:"2",to:"/publication/publication2018"}},[a("Icon",{attrs:{type:"md-document"}}),t._v("\n          2018\n        ")],1),t._v(" "),a("MenuItem",{attrs:{name:"3",to:"/publication/publication2017"}},[a("Icon",{attrs:{type:"md-document"}}),t._v("\n          2017\n        ")],1),t._v(" "),a("MenuItem",{attrs:{name:"4",to:"/publication/publication2016"}},[a("Icon",{attrs:{type:"md-document"}}),t._v("\n          2016\n        ")],1)],1)],1),t._v(" "),a("Col",{attrs:{span:"18"}},[a("div",{staticClass:"education"},[a("div",{staticClass:"education-block"},[a("h3"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Multi-Modal Clique-Graph Matching for View-Based 3D Model Retrieval")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Weizhi Nie, Yue Gao, Yuting Su ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Image Processing, TIP 2016.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7430305"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("3D Convolutional Networks-Based Mitotic Event Detection in Time-Lapse Phase Contrast Microscopy Image Sequences of Stem Cell Populations")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Yuting Su, Weizhi Nie, Mohan Kankanhalli")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Conference on Computer Vision and Pattern Recognition Workshops, CVPRW 2016.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7789661"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Predicting Image Memorability Through Adaptive Transfer Learning From External Sources")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Peiguang Jing, Yuting Su, Liqiang Nie, Huimin Gu")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Multimedia, TMM 2016.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7797211"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("SnapVideo: Personalized Video Generation for a Sightseeing Trip")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Luming Zhang, Peiguang Jing, Yuting Su, Chao Zhang, Ling Shaoz")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Cybernetics, TCYB 2016.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7516655"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("HEp-2 Cells Classification via Clustered Multi-task Learning")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Yao Lu, Weizhi Nie, Yuting Su, Zhaoxuan Yang")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("Neurocomputing, 2016.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://www.sciencedirect.com/science/article/pii/S0925231216001235"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("A Tensor-Driven Temporal Correlation Model for Video Sequence Classification")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jing Zhang, Chuanzhong Xu, Peiguang Jing, Chengqian Zhang, Yuting Su  ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Signal Processing Letters, 2016.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7486042"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br")])])])],1)],1)},staticRenderFns:[]};var n=a("VU/8")({name:"Publication2016Content"},s,!1,function(t){a("6IBH")},"data-v-4b6f71c9",null).exports,o={name:"publication2016",components:{HomeFooter:a("6BGy").a,Publication2016Content:n,HomeHeader:i.a},methods:{myajaxs:function(){this.$axios({method:"post",url:"/publication/publication2016"}).then(function(t){console.log(t)}).catch(function(t){console.log(t)})}}},r={render:function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("Layout",[e("Header",{staticStyle:{position:"fixed",right:"0",left:"0","z-index":"1030"}},[e("home-header",{attrs:{"active-name":this.activeIndex}})],1),this._v(" "),e("Content",[e("publication2016-content")],1),this._v(" "),e("Footer",[e("home-footer")],1)],1)],1)},staticRenderFns:[]};var l=a("VU/8")(o,r,!1,function(t){a("cncX")},"data-v-12a875a2",null);e.default=l.exports},"Wo+Z":function(t,e,a){t.exports=a.p+"static/img/research2.5a5a0bc.jpg"},X4yP:function(t,e){},XJiA:function(t,e){},XKGJ:function(t,e){},Y7m0:function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i=a("byf9"),s={render:function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"content-box"},[a("div",{staticClass:"content"},[a("Menu",{staticStyle:{"background-color":"rgb(245, 247, 249)"},attrs:{mode:"horizontal",theme:t.theme1,"active-name":"1"}},[a("MenuItem",{staticStyle:{width:"50%",overflow:"hidden","text-overflow":"ellipsis","white-space":"nowrap"},attrs:{name:"1",to:"/contest/contest1"}},[a("Icon",{attrs:{type:"ios-paper"}}),t._v("\n        SHREC 2015-2020\n      ")],1),t._v(" "),a("MenuItem",{staticStyle:{width:"50%",overflow:"hidden","text-overflow":"ellipsis","white-space":"nowrap"},attrs:{name:"2",to:"/contest/contest2"}},[a("Icon",{attrs:{type:"ios-ribbon"}}),t._v("\n        相差显微镜图像序列细胞有丝分裂事件检测比赛\n      ")],1)],1),t._v(" "),a("div",{staticClass:"contest-content"},[a("Card",{staticStyle:{"min-width":"700px","background-color":"rgb(245, 247, 249)"}},[a("a",{attrs:{href:"https://iti-tju.org/MI3DOR20"}},[a("h2",{staticStyle:{margin:"10px 0",color:"rgb(0,82,140)","text-align":"left"}},[t._v("SHREC 2020 - Extended Monocular Image Based 3D Model Retrieval")])]),a("br"),t._v(" "),a("p",[t._v("According to our SHREC 2019 - Monocular Image Based 3D Object Retrieval track, we have extended the number of the categories from the initial 21 classes to 40 classes, resulting in a new dataset which has 40,000 images and 12,732 models. We seek for more evaluations on the performance of existing and new 3D retrieval methods using the SHREC'20 benchmark, which is more comprehensive. Especially, we would like to bring unsupervised learning to 3D retrieval based on 2D images for its significance in reality.\n          "),a("br"),a("br"),a("span",{staticStyle:{color:"rgb(0,82,140)"}},[t._v("This contest is undergoing")])])]),a("br"),a("br"),t._v(" "),a("Card",{staticStyle:{"min-width":"700px","background-color":"rgb(245, 247, 249)"}},[a("a",{attrs:{href:"https://iti-tju.org/MI3DOR19"}},[a("h2",{staticStyle:{margin:"10px 0",color:"rgb(0,82,140)","text-align":"left"}},[t._v("SHREC 2019 - Monocular Image-based 3D Model Retrieval")])]),a("br"),t._v(" "),a("p",[t._v("Monocular image based 3D object retrieval is a novel and challenging research topic in the field of 3D object retrieval. Given a RGB image captured in real world, it aims to search for relevant 3D objects from a dataset. To advance this promising research, we organize this SHREC track and build the first monocular image based 3D object retrieval benchmark by collecting 2D images from ImageNet and 3D objects from popular 3D datasets such as NTU, PSB, ModelNet40 and ShapeNet. The benchmark contains classified 21,000 2D images and 7,690 3D objects of 21 categories. This track attracted 9 groups from 4 countries and the submission of 20 runs. The evaluation results show that the supervised cross domain learning get the superior retrieval performance (Best NN is 97.4 %) by bridging the domain gap with label information. However, there is still a big challenge for unsupervised cross domain learning (Best NN is 61.2%), which is more practical for the real application.\n          "),a("br"),a("br"),a("a",{staticStyle:{color:"rgb(0,82,140)","text-decoration":"underline"},attrs:{href:"../../../static/SHREC19.pdf",download:"SHREC19.pdf"}},[t._v("[Paper Download]")])])]),a("br"),a("br"),t._v(" "),a("Card",{staticStyle:{"min-width":"700px","background-color":"rgb(245, 247, 249)"}},[a("a",{attrs:{href:"https://iti-tju.org/SHREC2016"}},[a("h2",{staticStyle:{margin:"10px 0",color:"rgb(0,82,140)","text-align":"left"}},[t._v("SHREC’16 Track: 3D Object Retrieval with Multimodal Views")])]),a("br"),t._v(" "),a("p",[t._v("In the SHREC’16 track of 3D Object Retrieval with Multimodal Views, we aim to concentrate focused research efforts on how to represent the 3D object by using multimodal views. The objective of this track is to retrieve 3D printing objects and 3D real objects by using multimodal views, which are color images and depth images for each 3D object. Different to our SHREC’15 track, our collection is composed of 605 objects, in which 200 objects including 100 3D printing objects and 100 3D real objects are selected as the queries while the others are selected as the tests. Seven groups were participated in this track and 9 runs were submitted. The evaluation results show a promising scenario about multimodal view-based 3D retrieval methods.\n          "),a("br"),a("br"),a("a",{staticStyle:{color:"rgb(0,82,140)","text-decoration":"underline"},attrs:{href:"../../../static/SHREC16.pdf",download:"SHREC16.pdf"}},[t._v("[Paper Download]")])])]),a("br"),a("br"),t._v(" "),a("Card",{staticStyle:{"min-width":"700px","background-color":"rgb(245, 247, 249)"}},[a("a",{attrs:{href:"https://iti-tju.org/SHREC2015"}},[a("h2",{staticStyle:{margin:"10px 0",color:"rgb(0,82,140)","text-align":"left"}},[t._v("SHREC’15 Track: 3D Object Retrieval with Multimodal Views")])]),a("br"),t._v(" "),a("p",[t._v("In the SHREC’15 track of 3D Object Retrieval with Multimodal Views, we aim to concentrate focused research efforts on how to represent the 3D object by using multimodal views. The objective of this track is to retrieve 3D objects by using multimodal views, which are color images and depth images for each 3D object. Our collection is composed of 505 objects, in which 311 objects are selected as the queries. Six groups were participated in this track and 26 runs were submitted for two tasks. The evaluation results show a promising scenario about multimodal view-based 3D retrieval methods, and reveal interesting insights in dealing with multimodal data.\n          "),a("br"),a("br"),a("a",{staticStyle:{color:"rgb(0,82,140)","text-decoration":"underline"},attrs:{href:"../../../static/SHREC15.pdf",download:"SHREC15.pdf"}},[t._v("[Paper Download]")])])]),a("br"),a("br")],1)],1)])},staticRenderFns:[]};var n=a("VU/8")({name:"ContestContent1"},s,!1,function(t){a("XKGJ")},"data-v-58cfc432",null).exports,o={name:"contest1",components:{HomeFooter:a("6BGy").a,ContestContent1:n,HomeHeader:i.a},data:function(){return{activeIndex:"/research"}},methods:{myajaxs:function(){this.$axios({method:"post",url:"/contest/contest1"}).then(function(t){console.log(t)}).catch(function(t){console.log(t)})}}},r={render:function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("Layout",[e("Header",{staticStyle:{position:"fixed",right:"0",left:"0","z-index":"1030"}},[e("home-header",{attrs:{"active-name":this.activeIndex}})],1),this._v(" "),e("Content",[e("contest-content1")],1),this._v(" "),e("Footer",[e("home-footer")],1)],1)],1)},staticRenderFns:[]};var l=a("VU/8")(o,r,!1,function(t){a("VFjw")},"data-v-f166a6a0",null);e.default=l.exports},YPsL:function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i=a("byf9"),s={render:function(){var t=this.$createElement,e=this._self._c||t;return e("div",{staticClass:"content-box"},[e("div",{staticClass:"content"},[e("Menu",{staticStyle:{"background-color":"rgb(245, 247, 249)"},attrs:{mode:"horizontal",theme:this.theme1,"active-name":"2"}},[e("MenuItem",{staticStyle:{width:"50%",overflow:"hidden","text-overflow":"ellipsis","white-space":"nowrap"},attrs:{name:"1",to:"/contest/contest1"}},[e("Icon",{attrs:{type:"ios-paper"}}),this._v("\n        SHREC'19--基于单视图的三维模型检索\n      ")],1),this._v(" "),e("MenuItem",{staticStyle:{width:"50%",overflow:"hidden","text-overflow":"ellipsis","white-space":"nowrap"},attrs:{name:"2",to:"/contest/contest2"}},[e("Icon",{attrs:{type:"ios-ribbon"}}),this._v("\n        相差显微镜图像序列细胞有丝分裂事件检测比赛\n      ")],1)],1),this._v(" "),this._m(0)],1)])},staticRenderFns:[function(){var t=this,e=t.$createElement,i=t._self._c||e;return i("div",{staticClass:"contest-content"},[i("h2",{staticStyle:{margin:"10px 0"}},[t._v("相差显微镜图像序列细胞有丝分裂事件检测比赛")]),t._v(" "),i("p",[t._v("        有丝分裂检测旨在确定显微镜图像中细胞有丝分裂事件的存在，并且在整个显微镜图像序列中定位有丝分裂细胞的空间和时间位置。 与静态显微镜图像中的有丝分裂检测不同，相差显微镜图像数据集中的有丝分裂检测需要同时考虑细胞图像的空间和时序动态信息，并且精确描述这些事件的发生和持续时间。"),i("br"),i("br")]),t._v(" "),i("p",[t._v("        本次比赛的目的是为低倍率相差显微镜图像数据集下的细胞有丝分裂检测算法评估提供一个通用的基准。由于每个细胞仅能提供较低的可用像素信息，低倍率显微镜图像下的有丝分裂检测尤其具有挑战性。 低倍率显微成像是确保监视足够数量的细胞的有丝分裂行为所必需的。 只有这样才能将获得的足够的数据来对细胞群体进行分析。"),i("br"),i("br"),t._v(" "),i("a",{staticStyle:{"font-size":"15px"},attrs:{href:"http://media.m2i.ac.cn/mitosisdetection"}},[t._v("http://media.m2i.ac.cn/mitosisdetection")]),i("br"),i("br")]),t._v(" "),i("img",{staticStyle:{width:"80%","margin-left":"10%"},attrs:{src:a("bqn7")}}),i("br"),i("br")])}]};var n=a("VU/8")({name:"ContestContent2"},s,!1,function(t){a("270D")},"data-v-60ee244a",null).exports,o={name:"contest2",components:{HomeFooter:a("6BGy").a,ContestContent2:n,HomeHeader:i.a},data:function(){return{activeIndex:"/research"}},methods:{myajaxs:function(){this.$axios({method:"post",url:"/contest/contest2"}).then(function(t){console.log(t)}).catch(function(t){console.log(t)})}}},r={render:function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("Layout",[e("Header",{staticStyle:{position:"fixed",right:"0",left:"0","z-index":"1030"}},[e("home-header",{attrs:{"active-name":"activeIndex"}})],1),this._v(" "),e("Content",[e("contest-content2")],1),this._v(" "),e("Footer",[e("home-footer")],1)],1)],1)},staticRenderFns:[]};var l=a("VU/8")(o,r,!1,function(t){a("Q5C+")},"data-v-6be9ec18",null);e.default=l.exports},Yhjq:function(t,e,a){t.exports=a.p+"static/img/刘瑶瑶.47e5258.jpg"},ZLST:function(t,e){},ZaIm:function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i=a("E7Bq"),s=a("6BGy"),n={render:function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"content-box"},[a("Row",[a("Col",{attrs:{span:"6"}},[a("Menu",{staticClass:"menu",staticStyle:{width:"200px","background-color":"rgb(245, 247, 249)","margin-top":"50px"},attrs:{theme:"light","active-name":"3"}},[a("MenuItem",{attrs:{name:"1",to:"/publication/publication2019English"}},[a("Icon",{attrs:{type:"md-document"}}),t._v("\n          2019\n        ")],1),t._v(" "),a("MenuItem",{attrs:{name:"2",to:"/publication/publication2018English"}},[a("Icon",{attrs:{type:"md-document"}}),t._v("\n          2018\n        ")],1),t._v(" "),a("MenuItem",{attrs:{name:"3",to:"/publication/publication2017English"}},[a("Icon",{attrs:{type:"md-document"}}),t._v("\n          2017\n        ")],1),t._v(" "),a("MenuItem",{attrs:{name:"4",to:"/publication/publication2016English"}},[a("Icon",{attrs:{type:"md-document"}}),t._v("\n          2016\n        ")],1)],1)],1),t._v(" "),a("Col",{attrs:{span:"18"}},[a("div",{staticClass:"education"},[a("div",{staticClass:"education-block"},[a("h3"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Hierarchical Clustering Multi-Task Learning for Joint Human Action Grouping and Recognition.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Yuting Su, Weizhi Nie, Mohan Kankanhalli")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Pattern Analysis and Machine Intelligence, TPAMI 2017.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7423818"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("A-Lamp: Adaptive Layout-Aware Multi-patch Deep Convolutional Neural Network for Photo Aesthetic Assessment.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Shuang Ma, Jing Liu, Chang Wen Chen")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8099567"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Multi-Camera Action Dataset for Cross-Camera Action Recognition Benchmarking")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Wenhui Li, Yongkang Wong, An-An Liu, Yang Li, Yuting Su, Mohan Kankanhalli")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Winter Conference on Applications of Computer Vision, WACV 2017.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://arxiv.org/pdf/1607.06408.pdf"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Mitosis Detection in Phase Contrast Microscopy Image Sequences of Stem Cell Populations: A Critical Review")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Yao Lu, Mei Chen, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Big Data, TBD 2017.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7962189"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Special Issue on Biomedical Big Data: Understanding, Learning and Applications")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jun Zhu, An-An Liu, Mei Chen, Tolga Tasdizen, Hang Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Big Data, TBD 2017.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/abstract/document/7962189"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Attention-in-Attention Networks for Surveillance Video Understanding in Internet of Things")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Ning Xu, An-An Liu, Weizhi Nie, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Internet of Things Journal, 2017.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8141866"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Benchmarking a Multimodal and Multiview and Interactive Dataset for Human Action Recognition")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Ning Xu, Weizhi Nie, Yuting Su, Yongkang Wong, Mohan Kankanhalli")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Cybernetics, TCYB 2017.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7515012"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Multi-Grained Random Fields for Mitosis Identification in Time-Lapse Phase Contrast Microscopy Image Sequences.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Jinhui Tang, Weizhi Nie, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Medical Imaging, TMI 2017.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7885509"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Modeling Temporal Information of Mitotic for Mitotic Event Detection")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Weizhi Nie, Huiyun Cheng, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Big Data, TBD 2017.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7984862"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Predicting Image Memorability Through Adaptive Transfer Learning From External Sources")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Peiguang Jing, Yuting Su, Liqiang Nie, Huimin Gu")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Multimedia, TMM 2017.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7797211"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("SnapVideo: Personalized Video Generation for a Sightseeing Trip.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Luming Zhang, Peiguang Jing, Yuting Su, Chao Zhang, Ling Shaoz")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("  IEEE Transactions on Cybernetics, TCYB 2017.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7516655"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Spatiotemporal Joint Mitosis Detection Using CNN-LSTM Network in Time-Lapse Phase Contrast Microscopy Images")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Luming Zhang, Peiguang Jing, Yuting Su, Chao Zhang, Ling Shaoz")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access, 2017.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/abstract/document/8019789"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br")])])])],1)],1)},staticRenderFns:[]};var o={name:"publication2017English",components:{Publication2017Contenten:a("VU/8")({name:"Publication2017Contenten"},n,!1,function(t){a("lxx0")},"data-v-45fec5bf",null).exports,HomeFooter:s.a,HomeHeaderen:i.a},methods:{myajaxs:function(){this.$axios({method:"post",url:"/publication/publication2017English"}).then(function(t){console.log(t)}).catch(function(t){console.log(t)})}}},r={render:function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("Layout",[e("Header",{staticStyle:{position:"fixed",right:"0",left:"0","z-index":"1030"}},[e("home-headeren",{attrs:{"active-name":this.activeIndex}})],1),this._v(" "),e("Content",[e("publication2017-contenten")],1),this._v(" "),e("Footer",[e("home-footer")],1)],1)],1)},staticRenderFns:[]};var l=a("VU/8")(o,r,!1,function(t){a("CQF5")},"data-v-a881ce22",null);e.default=l.exports},ZgOq:function(t,e){},ZmSL:function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i=a("byf9"),s=a("6BGy"),n={name:"research",components:{ResearchMenu:a("biSA").a,HomeFooter:s.a,HomeHeader:i.a},data:function(){return{activeIndex:"/research"}},methods:{myajaxs:function(){this.$axios({method:"post",url:"/research"}).then(function(t){console.log(t)}).catch(function(t){console.log(t)})}}},o={render:function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("Layout",[e("Header",{staticStyle:{position:"fixed",right:"0",left:"0","z-index":"1030"}},[e("home-header",{attrs:{"active-name":this.activeIndex}})],1),this._v(" "),e("Content",[e("research-menu")],1),this._v(" "),e("Footer",[e("home-footer")],1)],1)],1)},staticRenderFns:[]};var r=a("VU/8")(n,o,!1,function(t){a("Md5u")},"data-v-18a07822",null);e.default=r.exports},Zofq:function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i=a("6BGy"),s=a("byf9"),n={render:function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"content-box"},[a("Row",[a("Col",{attrs:{span:"6"}},[a("Menu",{staticClass:"menu",staticStyle:{width:"200px","background-color":"rgb(245, 247, 249)","margin-top":"50px"},attrs:{theme:"light","active-name":"3"}},[a("MenuItem",{attrs:{name:"1",to:"/publication/publication2019"}},[a("Icon",{attrs:{type:"md-document"}}),t._v("\n          2019\n        ")],1),t._v(" "),a("MenuItem",{attrs:{name:"2",to:"/publication/publication2018"}},[a("Icon",{attrs:{type:"md-document"}}),t._v("\n          2018\n        ")],1),t._v(" "),a("MenuItem",{attrs:{name:"3",to:"/publication/publication2017"}},[a("Icon",{attrs:{type:"md-document"}}),t._v("\n          2017\n        ")],1),t._v(" "),a("MenuItem",{attrs:{name:"4",to:"/publication/publication2016"}},[a("Icon",{attrs:{type:"md-document"}}),t._v("\n          2016\n        ")],1)],1)],1),t._v(" "),a("Col",{attrs:{span:"18"}},[a("div",{staticClass:"education"},[a("div",{staticClass:"education-block"},[a("h3"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Hierarchical Clustering Multi-Task Learning for Joint Human Action Grouping and Recognition.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Yuting Su, Weizhi Nie, Mohan Kankanhalli")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Pattern Analysis and Machine Intelligence, TPAMI 2017.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7423818"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("A-Lamp: Adaptive Layout-Aware Multi-patch Deep Convolutional Neural Network for Photo Aesthetic Assessment.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Shuang Ma, Jing Liu, Chang Wen Chen")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8099567"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Multi-Camera Action Dataset for Cross-Camera Action Recognition Benchmarking")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Wenhui Li, Yongkang Wong, An-An Liu, Yang Li, Yuting Su, Mohan Kankanhalli")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Winter Conference on Applications of Computer Vision, WACV 2017.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://arxiv.org/pdf/1607.06408.pdf"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Mitosis Detection in Phase Contrast Microscopy Image Sequences of Stem Cell Populations: A Critical Review")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Yao Lu, Mei Chen, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Big Data, TBD 2017.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7962189"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Special Issue on Biomedical Big Data: Understanding, Learning and Applications")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jun Zhu, An-An Liu, Mei Chen, Tolga Tasdizen, Hang Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Big Data, TBD 2017.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/abstract/document/7962189"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Attention-in-Attention Networks for Surveillance Video Understanding in Internet of Things")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Ning Xu, An-An Liu, Weizhi Nie, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Internet of Things Journal, 2017.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8141866"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Benchmarking a Multimodal and Multiview and Interactive Dataset for Human Action Recognition")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Ning Xu, Weizhi Nie, Yuting Su, Yongkang Wong, Mohan Kankanhalli")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Cybernetics, TCYB 2017.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7515012"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Multi-Grained Random Fields for Mitosis Identification in Time-Lapse Phase Contrast Microscopy Image Sequences.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Jinhui Tang, Weizhi Nie, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Medical Imaging, TMI 2017.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7885509"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Modeling Temporal Information of Mitotic for Mitotic Event Detection")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Weizhi Nie, Huiyun Cheng, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Big Data, TBD 2017.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7984862"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Predicting Image Memorability Through Adaptive Transfer Learning From External Sources")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Peiguang Jing, Yuting Su, Liqiang Nie, Huimin Gu")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Multimedia, TMM 2017.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7797211"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("SnapVideo: Personalized Video Generation for a Sightseeing Trip.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Luming Zhang, Peiguang Jing, Yuting Su, Chao Zhang, Ling Shaoz")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("  IEEE Transactions on Cybernetics, TCYB 2017.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7516655"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Spatiotemporal Joint Mitosis Detection Using CNN-LSTM Network in Time-Lapse Phase Contrast Microscopy Images")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Luming Zhang, Peiguang Jing, Yuting Su, Chao Zhang, Ling Shaoz")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access, 2017.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/abstract/document/8019789"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br")])])])],1)],1)},staticRenderFns:[]};var o={name:"publication2017",components:{Publication2017Content:a("VU/8")({name:"Publication2017Content"},n,!1,function(t){a("wZmW")},"data-v-411e5de2",null).exports,HomeHeader:s.a,HomeFooter:i.a},methods:{myajaxs:function(){this.$axios({method:"post",url:"/publication/publication2017"}).then(function(t){console.log(t)}).catch(function(t){console.log(t)})}}},r={render:function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("Layout",[e("Header",{staticStyle:{position:"fixed",right:"0",left:"0","z-index":"1030"}},[e("home-header",{attrs:{"active-name":this.activeIndex}})],1),this._v(" "),e("Content",[e("publication2017-content")],1),this._v(" "),e("Footer",[e("home-footer")],1)],1)],1)},staticRenderFns:[]};var l=a("VU/8")(o,r,!1,function(t){a("uZ9r")},"data-v-0961b066",null);e.default=l.exports},afHC:function(t,e,a){t.exports=a.p+"static/img/research3-6.5753d9e.jpg"},bLpp:function(t,e,a){t.exports=a.p+"static/img/田宏硕.94c9fa9.jpg"},"bUi/":function(t,e){},biSA:function(t,e,a){"use strict";var i={render:function(){var t=this,e=t.$createElement,i=t._self._c||e;return i("div",[i("Row",{staticClass:"row1"},[i("Col",{staticClass:"col-left",attrs:{span:"14"}},[i("div",[i("a",{attrs:{href:"/#/research/research1"}},[i("h2",[t._v("跨媒体内容理解")])])]),t._v(" "),i("div",[i("p",{staticClass:"lead",staticStyle:{"margin-top":"30px"}},[i("Icon",{attrs:{type:"ios-square"}}),i("i"),t._v("  视觉语义概念建模视觉语义概念建模"),i("br"),t._v(" "),i("Icon",{attrs:{type:"ios-square"}}),i("i"),t._v("  视觉关系检测与识别"),i("br"),t._v(" "),i("Icon",{attrs:{type:"ios-square"}}),i("i"),t._v("  视觉类人描述"),i("br")],1)]),t._v(" "),i("div",[i("p",{staticClass:"introduction"},[t._v("\n          近年来，随着网络技术飞速发展，特别是公共安全监控系统和网络视频分享平台的普及，视觉数据呈现出爆炸性增长。在大数据时代，如何对视觉信息中包含的复杂语义进行自动解析，实现从独立的语义概念识别到类人的自然语言描述生成，是当前计算机视觉和人工智能领域的研究热点，对于公共安全风险防范、网络文化市场监管等多个领域具有重要的应用价值。\n        ")])])]),t._v(" "),i("Col",{attrs:{span:"10"}},[i("div",[i("a",{attrs:{href:"/#/research/research1"}},[i("img",{staticStyle:{height:"304px",width:"457px"},attrs:{src:a("zBUN")}})])])])],1),t._v(" "),i("hr",{staticClass:"research-line",staticStyle:{margin:"70px"}}),t._v(" "),i("Row",{staticClass:"row2"},[i("Col",{staticClass:"col-left",attrs:{span:"14"}},[i("div",[i("a",{attrs:{href:"/#/research/research2"}},[i("h2",[t._v("三维模型检索")])])]),t._v(" "),i("div",[i("p",{staticClass:"lead",staticStyle:{"margin-top":"30px"}},[i("Icon",{attrs:{type:"ios-square"}}),i("i"),t._v("  三维模型多视角视觉特征的高分辨力表征"),i("br"),t._v(" "),i("Icon",{attrs:{type:"ios-square"}}),i("i"),t._v("  三维模型间相似性度量"),i("br")],1)]),t._v(" "),i("div",[i("p",{staticClass:"introduction"},[t._v("\n          近年来，随着多媒体采集设备和三维建模技术的快速发展，三维模型数量呈现爆炸性增长。据统计，当前全球制造业三维模型数量过亿。特别是随着3D打印技术的普及，用户对三维模型需求强烈，迫切需要便捷的三维模型获取途径。因此，在新数据的驱动下，学术界与工业界急需基于人工智能的三维模型检索新理论，实现便捷的三维模型大数据管理。\n        ")])])]),t._v(" "),i("Col",{attrs:{span:"10"}},[i("div",[i("a",{attrs:{href:"/#/research/research2"}},[i("img",{staticStyle:{width:"457px"},attrs:{src:a("Wo+Z")}})])])])],1),t._v(" "),i("hr",{staticClass:"research-line",staticStyle:{margin:"70px"}}),t._v(" "),i("Row",{staticClass:"row3"},[i("Col",{staticClass:"col-left",attrs:{span:"14"}},[i("div",[i("a",{attrs:{href:"/#/research/research3"}},[i("h2",[t._v("细胞图像分析")])])]),t._v(" "),i("div",[i("p",{staticClass:"lead",staticStyle:{"margin-top":"30px"}},[i("Icon",{attrs:{type:"ios-square"}}),i("i"),t._v("  细胞有丝分裂事件的识别"),i("br"),t._v(" "),i("Icon",{attrs:{type:"ios-square"}}),i("i"),t._v("  细胞有丝分裂事件的定位"),i("br"),t._v(" "),i("Icon",{attrs:{type:"ios-square"}}),i("i"),t._v("  细胞有丝分裂过程分割"),i("br")],1)]),t._v(" "),i("div",[i("p",{staticClass:"introduction"},[t._v("\n          近年来，随着医学信息采集技术的发展，在医疗诊断和生物研究的过程当中往往需要处理大量的医学图像数据。在医疗大数据的时代，利用机器学习方法和人工智能技术对海量的医学图像数据进行充分的分析和挖掘，将会对医学诊断和生物研究的发展带来新的促进。M2I实验室细胞图像分析组主要关注利用计算机视觉和机器学习方法对细胞显微镜图像下细胞有丝分裂事件进行识别、定位与分割。\n        ")])])]),t._v(" "),i("Col",{attrs:{span:"10"}},[i("div",[i("a",{attrs:{href:"/#/research/research3"}},[i("img",{staticStyle:{width:"457px"},attrs:{src:a("bqn7"),height:"304px"}})])])])],1),t._v(" "),i("hr",{staticClass:"research-line",staticStyle:{margin:"70px"}}),t._v(" "),i("Row",{staticClass:"row4"},[i("Col",{staticClass:"col-left",attrs:{span:"14"}},[i("div",[i("a",{attrs:{href:"/#/research/research4"}},[i("h2",[t._v("面向普通用户的三维人体重建")])])]),t._v(" "),i("div",[i("p",{staticClass:"lead",staticStyle:{"margin-top":"30px"}},[i("Icon",{attrs:{type:"ios-square"}}),i("i"),t._v("  针对着装图像的衣服尺码估计"),i("br"),t._v(" "),i("Icon",{attrs:{type:"ios-square"}}),i("i"),t._v("  针对着装图像的三维人体重建"),i("br"),t._v(" "),i("Icon",{attrs:{type:"ios-square"}}),i("i"),t._v("  面向普通用户的便捷三维人体重建"),i("br")],1)]),t._v(" "),i("div",[i("p",{staticClass:"introduction"},[t._v("\n          随着信息时代的发展和时代需求的不断更新，多媒体视觉信息爆炸性增长，对于视觉语义的分析和理解逐渐走进人们的视野。对视觉语义的分析和理解主要应用于现如今多媒体环境下视频分类，视频推荐，情感分析，视觉记忆度分析等等具有实际应用价值的环境之中。其利用张量分解等工具对视觉信息进行相应分析处理。在张量分解领域，本实验室主要关注时间序列分析，视频序列分类等。在视觉语义理解领域，本实验室主要关注于视频的事件检测，视觉信息的情感分析，视觉信息的记忆度等等。\n        ")])])]),t._v(" "),i("Col",{attrs:{span:"10"}},[i("div",[i("a",{attrs:{href:"/#/research/research4"}},[i("img",{staticStyle:{width:"457px"},attrs:{src:a("cram"),height:"300px"}})])])])],1),t._v(" "),i("hr",{staticClass:"research-line",staticStyle:{margin:"70px"}}),t._v(" "),i("Row",{staticClass:"row5"},[i("Col",{staticClass:"col-left",attrs:{span:"14"}},[i("div",[i("a",{attrs:{href:"/#/research/research5"}},[i("h2",[t._v("社交媒体分析")])])]),t._v(" "),i("div",[i("p",{staticClass:"lead",staticStyle:{"margin-top":"30px"}},[i("Icon",{attrs:{type:"ios-square"}}),i("i"),t._v("  张量分解"),i("br"),t._v(" "),i("Icon",{attrs:{type:"ios-square"}}),i("i"),t._v("  视觉语义理解"),i("br")],1)]),t._v(" "),i("div",[i("p",{staticClass:"introduction"},[t._v("\n          随着信息时代的发展和时代需求的不断更新，多媒体视觉信息爆炸性增长，对于视觉语义的分析和理解逐渐走进人们的视野。对视觉语义的分析和理解主要应用于现如今多媒体环境下视频分类，视频推荐，情感分析，视觉记忆度分析等等具有实际应用价值的环境之中。其利用张量分解等工具对视觉信息进行相应分析处理。在张量分解领域，本实验室主要关注时间序列分析，视频序列分类等。在视觉语义理解领域，本实验室主要关注于视频的事件检测，视觉信息的情感分析，视觉信息的记忆度等等。\n        ")])])]),t._v(" "),i("Col",{attrs:{span:"10"}},[i("div",[i("a",{attrs:{href:"/#/research/research5"}},[i("img",{staticStyle:{width:"457px"},attrs:{src:a("mG6J")}})])])])],1)],1)},staticRenderFns:[]};var s=a("VU/8")({name:"ResearchMenu"},i,!1,function(t){a("MkWf")},"data-v-14bc450f",null);e.a=s.exports},bqn7:function(t,e,a){t.exports=a.p+"static/img/research3.08908fa.png"},byf9:function(t,e,a){"use strict";var i={name:"HomeHeader",props:{activeIndex:String},data:function(){return{}}},s={render:function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"home-header",staticStyle:{display:"flex",width:"1536px","min-width":"1280px","box-sizing":"border-box"}},[t._m(0),t._v(" "),a("div",{staticClass:"header-menu"},[a("Menu",{staticStyle:{background:"rgb(0,82,140)",width:"410px"},attrs:{mode:"horizontal","active-name":"activeIndex"}},[a("MenuItem",{staticStyle:{color:"white"},attrs:{to:"/",name:"1"}},[t._v("\n        主页\n      ")]),t._v(" "),a("MenuItem",{staticStyle:{color:"white"},attrs:{to:"/people",name:"2"}},[t._v("\n        团队\n      ")]),t._v(" "),a("MenuItem",{staticStyle:{color:"white"},attrs:{to:"/research",name:"3"}},[t._v("\n        研究方向\n      ")]),t._v(" "),a("MenuItem",{staticStyle:{color:"white"},attrs:{to:"/publication/publication2019",name:"5"}},[t._v("\n        学术成果\n      ")]),t._v(" "),a("MenuItem",{staticStyle:{color:"white"},attrs:{to:"/contest/contest1",name:"6"}},[t._v("\n        比赛\n      ")])],1)],1),t._v(" "),a("div",{staticClass:"header-button"},[a("Button",{attrs:{type:"primary ",to:"/"}},[t._v("中/En")])],1)])},staticRenderFns:[function(){var t=this.$createElement,e=this._self._c||t;return e("div",{staticClass:"header-logo"},[e("img",{staticClass:"logo",attrs:{src:a("uzhG")}})])}]};var n=a("VU/8")(i,s,!1,function(t){a("rNb9")},"data-v-990d720c",null);e.a=n.exports},cihS:function(t,e){},cncX:function(t,e){},cram:function(t,e,a){t.exports=a.p+"static/img/research4.ea32263.jpg"},dQDw:function(t,e){},dnio:function(t,e){},dr0C:function(t,e,a){t.exports=a.p+"static/img/research1-2.e7a19d9.png"},ePIu:function(t,e){},eWhT:function(t,e){},ep9K:function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i=a("E7Bq"),s=a("6BGy"),n={render:function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"content-box"},[a("Row",[a("Col",{attrs:{span:"6"}},[a("Menu",{staticClass:"menu",staticStyle:{width:"200px","background-color":"rgb(245, 247, 249)","margin-top":"50px"},attrs:{theme:"light","active-name":"2"}},[a("MenuItem",{attrs:{name:"1",to:"/publication/publication2019English"}},[a("Icon",{attrs:{type:"md-document"}}),t._v("\n          2019\n        ")],1),t._v(" "),a("MenuItem",{attrs:{name:"2",to:"/publication/publication2018English"}},[a("Icon",{attrs:{type:"md-document"}}),t._v("\n          2018\n        ")],1),t._v(" "),a("MenuItem",{attrs:{name:"3",to:"/publication/publication2017English"}},[a("Icon",{attrs:{type:"md-document"}}),t._v("\n          2017\n        ")],1),t._v(" "),a("MenuItem",{attrs:{name:"4",to:"/publication/publication2016English"}},[a("Icon",{attrs:{type:"md-document"}}),t._v("\n          2016\n        ")],1)],1)],1),t._v(" "),a("Col",{attrs:{span:"18"}},[a("div",{staticClass:"education"},[a("div",{staticClass:"education-block"},[a("h3"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Hierarchical Graph Structure Learning for Multi-View 3D Model Retrieval")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Yuting Su, Wenhui Li, An-An Liu, Weizhi Nie")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("The 27th International Joint Conference on Artificial Intelligence, IJCAI 2018.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://www.ijcai.org/proceedings/2018/0127.pdf"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Cross-Domain 3D Model Retrieval via Visual Domain Adaptation")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Shu Xiang, Wenhui Li, Weizhi Nie, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("The 27th International Joint Conference on Artificial Intelligence, IJCAI 2018.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://www.ijcai.org/proceedings/2018/0115.pdf"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Multi-Level Policy and Reward Reinforcement Learning for Image Captioning")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Ning Xu, Hanwang Zhang, Weizhi Nie, Yuting Su, Yongdong Zhang")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("The 27th International Joint Conference on Artificial Intelligence, IJCAI 2018.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://www.ijcai.org/proceedings/2018/114"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("View-Based 3-D Model Retrieval: A Benchmark")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Weizhi Nie, Yue Gao, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Cybernetics, TCYB 2018.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7857115"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("PANORAMA-Based Multi-Scale and Multi-Channel CNN for 3D Model Retrieval")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Weizhi Nie, Kun Wang, Yao Lu, Anan Liu, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Visual Communications and Image Processing, VCIP 2018.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8698722"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("A Review of Breast Cancer Detection in Medical Images")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Yao Lu, Jiayu Li, Yuting Su, An-An Liu")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Visual Communications and Image Processing, VCIP 2018.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/abstract/document/8698732/"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Attention-in-Attention Networks for Surveillance Video Understanding in Internet of Things")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Ning Xu, An-An Liu, Weizhi Nie, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Internet of Things Journal, 2018.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8141866"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v(" IPAD: Intensity Potential for Adaptive De-Quantization.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jing Liu, Guangtao Zhai, Anan Liu, Xiaokang Yang, Xibin Zhao, Chang Wen Chen")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Image Processing, TIP 2018.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8421587"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v(" Blind Quality Assessment Based on Pseudo-Reference Image")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Xiongkuo Min, Ke Gu, Guangtao Zhai, Xiaokang Yang, Chang Wen Chen")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Multimedia, TMM 2018.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8421587"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Low-Rank Multi-View Embedding Learning for Micro-Video Popularity Prediction")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Peiguang Jing, Yuting Su, Liqiang Nie, Xu Bai, Jing Liu, Meng Wang ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Knowledge and Data Engineering, TKDE 2018.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8233154"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Low-Rank Regularized Heterogeneous Tensor Decomposition for Subspace Clustering")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jing Zhang, Xinhui Li, Peiguang Jing, Jing Liu, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Signal Processing Letters, 2018.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8025385"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("A Fine-Grained Spatial-Temporal Attention Model for Video Captioning")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Yurui Qiu, Yongkang Wong, Yuting Su, Mohan Kankanhalli")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access, 2018")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8523661"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("AMFNet: An Adversarial Network for Median Filtering Detection")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Xiao Jin, Peiguang Jing, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Access, 2018.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8447546"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Sparsity-Based Image Inpainting Detection via Canonical Correlation Analysis With Low-Rank Constraints")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Xiao Jin, Yuting Su, Liang Zou, Yongwei Wang, Peiguang Jing, Z. Jane Wang")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Access, 2018.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8439932"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v(" Human Action Recognition Based on Selected Spatio-Temporal Features via Bidirectional LSTM")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Wenhui Li, Weizhi Nie, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access, 2018.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8434092"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v(" Recurrent Conditional Generative Adversarial Network for Image Deblurring")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jing Liu, Wanning Sun, Mengjie Li")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access, 2018.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8585006"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v(" Improving Bit-Depth Expansion via Context-Aware MMSE Optimization (CAMO)")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jing Liu, Wanning Sun, Peiguang Jing, Jiexiao Yu, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access, 2018.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8421587"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br")])])])],1)],1)},staticRenderFns:[]};var o={name:"publication2018English",components:{Publication2018Contenten:a("VU/8")({name:"Publication2018Contenten"},n,!1,function(t){a("2/Ij")},"data-v-24444d9a",null).exports,HomeFooter:s.a,HomeHeaderen:i.a},methods:{myajaxs:function(){this.$axios({method:"post",url:"/publication/publication2018English"}).then(function(t){console.log(t)}).catch(function(t){console.log(t)})}}},r={render:function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("Layout",[e("Header",{staticStyle:{position:"fixed",right:"0",left:"0","z-index":"1030"}},[e("home-headeren",{attrs:{"active-name":this.activeIndex}})],1),this._v(" "),e("Content",[e("publication2018-contenten")],1),this._v(" "),e("Footer",[e("home-footer")],1)],1)],1)},staticRenderFns:[]};var l=a("VU/8")(o,r,!1,function(t){a("Q7kd")},"data-v-5098b50d",null);e.default=l.exports},fo5S:function(t,e){},gsQP:function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i=a("byf9"),s=a("6BGy"),n={render:function(){var t=this,e=t.$createElement,i=t._self._c||e;return i("div",{staticClass:"content-box"},[i("div",{staticClass:"breadcrumb"},[i("Breadcrumb",[i("BreadcrumbItem",{attrs:{to:"/home"}},[t._v("主页")]),t._v(" "),i("BreadcrumbItem",{attrs:{to:"/research"}},[t._v("研究方向")]),t._v(" "),i("BreadcrumbItem",[t._v("三维模型检索")])],1)],1),t._v(" "),i("div",[i("h1",[t._v("    "),i("Icon",{attrs:{type:"ios-fastforward"}}),t._v("  三维模型检索")],1),t._v(" "),t._m(0)]),t._v(" "),i("Collapse",{staticClass:"collapse",staticStyle:{"font-size":"13px"},model:{value:t.value1,callback:function(e){t.value1=e},expression:"value1"}},[i("Panel",{attrs:{name:"1"}},[t._v("\n      1.简介\n      "),i("p",{staticClass:"me-collapse-content",attrs:{slot:"content"},slot:"content"},[t._v("\n                 近年来，随着多媒体采集设备和三维建模技术的快速发展，三维模型数量呈现爆炸性增长。据统计，当前全球制造业三维模型数量过亿。特别是随着3D打印技术的普及，用户对三维模型需求强烈，迫切需要便捷的三维模型获取途径。因此，在新数据的驱动下，学术界与工业界急需基于人工智能的三维模型检索新理论，实现便捷的三维模型大数据管理。\n      ")])]),t._v(" "),i("Panel",{attrs:{name:"2"}},[t._v("\n      2.三维模型多视角视觉特征的高分辨力表征\n      "),i("p",{staticClass:"me-collapse-content",attrs:{slot:"content"},slot:"content"},[i("span",[t._v("2.1基于域自适应的跨域三维模型多视角特征学习方法\n        ")]),i("br"),i("br"),t._v(" "),i("span",[t._v("        与拥有亿级数量的二维图像数据库相比，现有的三维模型数据库所包含模型数量相当有限。最新的三维模型数据库，如ModelNet40和ShapeNet55也分别只有12311和51300个模型。尽管当前已提出多种流行的三维模型多视图特征提取方法，但是这些方法仅适用于单一数据域任务，无法适用于目标域和源域来自不同领域的真实应用场景。理论上讲，深度学习方法高度依赖于大规模训练数据，因此现有的深度学习方法对于常见的小规模三维模型数据库来说往往形成过拟合，泛化能力受到严重制约。因此，需要探索鲁棒的三维模型多视角特征跨域学习方法来提高模型泛化能力。"),i("br"),t._v("\n              该方法的创新点主要包括以下两个方面："),i("br"),t._v("\n              1）针对三维模型多视角视图集提出多视角深度卷积网络模型，实现端到端模式下数据驱动的多视角特征提取和融合；"),i("br"),t._v("\n              2）提出跨域数据分布对齐理论，实现不同分布下同类数据共嵌空间投影，从而实现高分辨力的多视角特征学习。"),i("br")]),i("br"),i("br"),t._v(" "),i("img",{staticClass:"me-img",attrs:{src:a("24ZX"),width:"800px"}}),i("br"),i("br"),t._v(" "),i("span",[t._v("2.2基于多视角隐性变量模型的三维模型特征提取方法\n        ")]),i("br"),i("br"),t._v(" "),i("span",[t._v("\n                  基于视图的三维模型检索的目的是识别三维模型数据库中与给定查询模型相似的模型，该模型通常由一组多视角视图集表示。要创建多视图集表示，需要为每个三维模型定义特定的相机阵列配置（如图2（a）所示）。然后，每个三维模型可以由对应于预定义相机阵列各空间位置的一组连续视图图像来表示。由此可知，相机阵列的定义对于多视角特征学习非常关键，其难点在于：1）难以启发式地定义多个相机的空间位置以捕获三维模型的显着特征；2）难以启发式的确定使用多少必要的相机数目。领域急需一种不受限于相机阵列设定约束的三维模型特征提取方法。因此，我们提出了一种多视角隐变量模型（MVLVM）来解决该问题。"),i("br"),t._v("\n          该方法的创新点主要包括以下两个方面："),i("br"),t._v("\n          1）通过模型类别、代表性视图选择和多视角视图潜在关联的联合学习实现多视角特征学习。"),i("br"),t._v("\n          2）突破了传统方法对视图采集角度与数目的约束，显著提升视觉特征的高分辨力。"),i("br")]),t._v(" "),i("img",{staticClass:"me-img",attrs:{src:a("PYLQ"),width:"800px"}}),i("br"),i("br")])]),t._v(" "),i("Panel",{attrs:{name:"3"}},[t._v("\n      3.三维模型间相似性度量\n      "),i("p",{staticClass:"me-collapse-content",attrs:{slot:"content"},slot:"content"},[i("span",[t._v("\n            3.1基于多模态团图匹配的三维模型相似性度量方法\n          ")]),i("br"),i("br"),t._v(" "),i("span",[t._v("\n                  给定由一组多视角2D图像表示的三维模型，设计特定图结构以表示三维模型的视觉特性和空间相关性，然后利用图匹配来计算成对模型之间的相似性。当前基于图匹配的度量方法有经典图和超图，但存在两个严重的问题：1）经典图和超图的构造严重依赖于特征视图提取。但是，从多个相似视图中选择特征视图非常具有挑战性；2）对于超图构造，定义高阶属性是非常复杂的，解决与映射约束的超图匹配极具挑战性。为了解决这些问题，我们提出构建多模态团图（Multi-modal Clique Graph, MCG）。"),i("br"),t._v("\n          该方法的创新点主要包括以下两个方面："),i("br"),t._v("\n          1）将超图中复杂高阶节点的关联信息用简单的团图结构替换，有效降低图结构的复杂性；"),i("br"),t._v("\n          2）将经典超图匹配中超边的匹配问题转换成了两个团图结构的匹配，有效降低超图匹配的算法复杂度。"),i("br")]),i("br"),i("br"),t._v(" "),i("img",{staticClass:"me-img",attrs:{src:a("6jn2"),width:"800px"}}),i("br"),i("br"),t._v(" "),i("span",[t._v("\n            3.2基于超集团图的相似性度量方法\n          ")]),i("br"),i("br"),t._v(" "),i("span",[t._v("\n                  为了探索团图的高阶计算理论，我们提出了超集团图（Hyper-Clique Graph, HCG）的构建，如图4所示，将各团结构作为一个超节点，并使用超边来进行连接。由于图结构的变化导致了超集团图匹配的目标函数发生了根本性变化，因此我们针对潜在的变量重新设置目标函数并进行优化，克服一对一约束下的高阶匹配的困难，从而解决超集团图之间的相似度计算问题。"),i("br"),t._v("\n          该方法的创新点主要包括以下两个方面："),i("br"),t._v("\n          1）提出创新的超集团图构建方法，针对多视角图集构建超节点和超边，显著增强图结构对多视角潜在关联性的表征能力；"),i("br"),t._v("\n          2）针对超节点间关联性表征提出了高阶张量计算理论，并提出基于加权随机游走策略的HCG匹配方法。"),i("br")]),i("br"),i("br"),t._v(" "),i("img",{staticClass:"me-img",attrs:{src:a("7D6F"),width:"800px"}}),i("br"),i("br")])]),t._v(" "),i("Panel",{attrs:{name:"4"}},[t._v("\n      4.论文\n      "),i("p",{staticClass:"me-collapse-content",attrs:{slot:"content"},slot:"content"})])],1)],1)},staticRenderFns:[function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("p",{staticClass:"research-people"},[a("span",[t._v("团队成员")]),a("br"),t._v(" "),a("span",[a("a",{attrs:{href:"/#/people/liuanan"}},[t._v("刘安安（教授）")]),t._v("    "),a("a",{attrs:{href:"/#/people/nieweizhi"}},[t._v("聂为之（副教授)")]),a("br"),t._v(" "),a("a",{attrs:{href:"/#/people/songdan"}},[t._v("宋丹（助理教授)")]),a("br"),t._v("\n             李文辉（博士生）  李余钱（博士生）  李佳玉（博士生）"),a("br"),t._v("\n        周河宇（博士生）  向    姝（硕士生）  赵镇澜（硕士生）"),a("br"),t._v("\n             郭富斌（硕士生）  胡    念（硕士生）\n           ")])])}]};var o={name:"research2",components:{ResearchTwoContent:a("VU/8")({name:"ResearchTwoContent"},n,!1,function(t){a("AeLw")},"data-v-48d965ea",null).exports,HomeFooter:s.a,HomeHeader:i.a},data:function(){return{activeIndex:"/research"}},methods:{myajaxs:function(){this.$axios({method:"post",url:"/research/research2"}).then(function(t){console.log(t)}).catch(function(t){console.log(t)})}}},r={render:function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("Layout",[e("Header",{staticStyle:{position:"fixed",right:"0",left:"0","z-index":"1030"}},[e("home-header",{attrs:{"active-name":this.activeIndex}})],1),this._v(" "),e("Content",[e("research-two-content")],1),this._v(" "),e("Footer",[e("home-footer")],1)],1)],1)},staticRenderFns:[]};var l=a("VU/8")(o,r,!1,function(t){a("8WJj")},"data-v-a66a8a96",null);e.default=l.exports},hA1W:function(t,e,a){t.exports=a.p+"static/img/research5-5.29f1d5d.png"},hYxp:function(t,e,a){t.exports=a.p+"static/img/research4-2.04e5af1.jpg"},habg:function(t,e,a){t.exports=a.p+"static/img/banner1.27dc71e.jpg"},i7es:function(t,e){},ieDd:function(t,e){},iovA:function(t,e,a){t.exports=a.p+"static/img/research5-4.0d6e16a.png"},jD5f:function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i=a("E7Bq"),s={render:function(){var t=this,e=t.$createElement,i=t._self._c||e;return i("div",[i("div",{staticClass:"breadcrumb"},[i("Breadcrumb",[i("BreadcrumbItem",{attrs:{to:"/"}},[t._v("HOME")]),t._v(" "),i("BreadcrumbItem",{attrs:{to:"/peopleEnglish"}},[t._v("PEOPLE")]),t._v(" "),i("BreadcrumbItem",[t._v("Peiguang Jing")])],1)],1),t._v(" "),i("div",{staticClass:"content-box"},[i("div",[i("Row",[i("Col",{attrs:{span:"5"}},[i("div",{staticClass:"people-img"},[i("img",{attrs:{src:a("K2Da"),width:"143px",height:"189px"}})])]),t._v(" "),i("Col",{attrs:{span:"19"}},[i("div",{staticClass:"people-intro"},[i("span",{staticStyle:{"font-size":"23px",color:"black","font-weight":"bold"}},[t._v("Peiguang Jing")]),i("span",{staticStyle:{"padding-left":"20px"}},[t._v("Assistant Professor")]),i("br"),i("br"),t._v(" "),i("span",[t._v("School of Electrical and Information Engineering")]),i("br"),t._v(" "),i("span",[t._v("Tianjin University, China")]),i("br"),t._v(" "),i("span",[t._v("Email：pgjing@tju.edu.cn")]),i("br")])])],1)],1),t._v(" "),t._m(0),t._v(" "),t._m(1)])])},staticRenderFns:[function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("h2",[this._v("Introduction")]),this._v(" "),e("hr",{staticClass:"research-line",staticStyle:{margin:"15px 0"}}),this._v(" "),e("span",{staticClass:"content"},[this._v("Peiguang Jing received his master's degree from Tianjin University in 2013 and his doctor's degree from Tianjin University in 2018. From 2014 to 2015, Peiguang Jing conducted joint doctoral training at the National University of Singapore. Now I am a lecturer and master tutor in school of electrical automation and information engineering, Tianjin University. Current research interests include tensor decomposition, multimedia computing, machine learning, etc.")])])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",[a("h2",[t._v("Publication")]),t._v(" "),a("hr",{staticClass:"research-line",staticStyle:{margin:"15px 0"}}),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8359393"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[1]   High-Order Temporal Correlation Model Learning for Time-Series Prediction. IEEE Transactions on Cybernetics ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Peiguang Jing, Yuting Su, Xiao Jin, Chengqian Zhang.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Cybernetics, 2019, 49(6):2385-2397. ")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8480641"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[2]   Wearable Computing for Internet of Things: A Discriminant Approach for Human Activity Recognition.  ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Wei Lu, Fugui Fan, Jinghui Chu, Peiguang Jing, Yuting Su.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Internet of Things Journal, 2019, 6(2): 2749-2759.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8353302"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[3]   A Framework of Joint Low-Rank and Sparse Regression for Image Memorability Prediction. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" Peiguang Jing, Yuting Su, Liqiang Nie, Huimin Gu, Jing Liu , and Meng Wang.  ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Circuits and Systems for Video Technology, 2019,29(5):1296-1309. ")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8853293"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[4]   Low-rank Regularized Multi-representation Learning for Fashion Compatibility Prediction ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Peiguang Jing, Shu Ye, Liqiang Nie, Jing Liu, Yuting Su.  ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Multimedia, 2019, DOI: 10.1109/TMM.2019.2944749. ")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",[a("p",{staticClass:"p title"},[a("strong",[t._v("[5]   Low-rank regularized tensor discriminant representation for image set classification ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Peiguang Jing, Yuting Su, Zhengnan Li, Jing Liu, Liqiang Nie. ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" Signal Processing, 2019, 156:62-70. ")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",[a("p",{staticClass:"p title"},[a("strong",[t._v("[6]    Personalized Capsule Wardrobe Creation with Garment and User Modeling ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Xue Dong, Xuemeng Song, Fuli Feng, Peiguang Jing, Xin-Shun Xu, Liqiang Nie.   ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" In Proceedings of ACM International Conference on Multimedia, 2019: 302-310.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8233154"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[7]   Low-Rank Multi-View Embedding Learning for Micro-Video Popularity Prediction. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" Peiguang Jing, Yuting Su, Liqiang Nie, Xu Bai, Jing Liu, Meng Wang.  ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Knowledge and Data Engineering, 2018, 30(8): 1519-1532.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",[a("p",{staticClass:"p title"},[a("strong",[t._v("[8]   Structured Low-rank Inverse-covariance Estimation for Visual Sentiment Distribution Prediction. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" Anan Liu, Yingdi Shi, Peiguang Jing, Jing Liu, Yuting Su.  ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("Signal Processing, 2018, 152:206-216. ")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8025385"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[9]   Low-Rank Regularized Heterogeneous Tensor Decomposition for Subspace Clustering. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" Jing Zhang, Xinhui Li, Peiguang Jing, Jing Liu, Yuting Su.  ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Signal Processing Letters, 2018, 25 (3), 333-337.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7486042"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[10]   A Tensor-Driven Temporal Correlation Model for Video Sequence Classification. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" Jing Zhang, Chuanzhong Xu, Peiguang Jing, Chengqian Zhang, Yuting Su.  ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("  IEEE Signal Processing Letters, 2016, 23 (9), 1246 – 1249.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7797211"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[11]   Predicting Image Memorability Through Adaptive Transfer Learning From External Sources. ")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" Peiguang Jing, Yuting Su, Liqiang Nie, Huimin Gu.  ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("  IEEE Transactions on Multimedia, 2017, 19(5): 1050-1062.")])])])])}]};var n=a("VU/8")({name:"JingpeiguangContenten"},s,!1,function(t){a("X4yP")},"data-v-200f9c1e",null).exports,o={name:"JingpeiguangEnglish",components:{HomeFooter:a("6BGy").a,JingpeiguangContenten:n,HomeHeaderen:i.a},data:function(){return{activeIndex:"/people"}},methods:{myajaxs:function(){this.$axios({method:"post",url:"/people/jingpeiguangEnglish"}).then(function(t){console.log(t)}).catch(function(t){console.log(t)})}}},r={render:function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("Layout",[e("Header",{staticStyle:{position:"fixed",right:"0",left:"0","z-index":"1030"}},[e("home-headeren",{attrs:{"active-name":this.activeIndex}})],1),this._v(" "),e("Content",[e("jingpeiguang-contenten")],1),this._v(" "),e("Footer",[e("home-footer")],1)],1)],1)},staticRenderFns:[]};var l=a("VU/8")(o,r,!1,function(t){a("UzE/")},"data-v-50d8624d",null);e.default=l.exports},jOVy:function(t,e){},jTiP:function(t,e){},jdyf:function(t,e,a){t.exports=a.p+"static/img/research5-6.ff3c55d.png"},jq8P:function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i={render:function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"content-box"},[a("Row",[a("Col",{attrs:{span:"6"}},[a("Menu",{staticClass:"menu",staticStyle:{width:"200px","background-color":"rgb(245, 247, 249)","margin-top":"50px"},attrs:{theme:"light","active-name":"2"}},[a("MenuItem",{attrs:{name:"1",to:"/publication/publication2019"}},[a("Icon",{attrs:{type:"md-document"}}),t._v("\n          2019\n        ")],1),t._v(" "),a("MenuItem",{attrs:{name:"2",to:"/publication/publication2018"}},[a("Icon",{attrs:{type:"md-document"}}),t._v("\n          2018\n        ")],1),t._v(" "),a("MenuItem",{attrs:{name:"3",to:"/publication/publication2017"}},[a("Icon",{attrs:{type:"md-document"}}),t._v("\n          2017\n        ")],1),t._v(" "),a("MenuItem",{attrs:{name:"4",to:"/publication/publication2016"}},[a("Icon",{attrs:{type:"md-document"}}),t._v("\n          2016\n        ")],1)],1)],1),t._v(" "),a("Col",{attrs:{span:"18"}},[a("div",{staticClass:"education"},[a("div",{staticClass:"education-block"},[a("h3"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Hierarchical Graph Structure Learning for Multi-View 3D Model Retrieval")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Yuting Su, Wenhui Li, An-An Liu, Weizhi Nie")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("The 27th International Joint Conference on Artificial Intelligence, IJCAI 2018.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://www.ijcai.org/proceedings/2018/0127.pdf"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Cross-Domain 3D Model Retrieval via Visual Domain Adaptation")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Shu Xiang, Wenhui Li, Weizhi Nie, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("The 27th International Joint Conference on Artificial Intelligence, IJCAI 2018.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://www.ijcai.org/proceedings/2018/0115.pdf"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Multi-Level Policy and Reward Reinforcement Learning for Image Captioning")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Ning Xu, Hanwang Zhang, Weizhi Nie, Yuting Su, Yongdong Zhang")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("The 27th International Joint Conference on Artificial Intelligence, IJCAI 2018.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://www.ijcai.org/proceedings/2018/114"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("View-Based 3-D Model Retrieval: A Benchmark")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Weizhi Nie, Yue Gao, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Cybernetics, TCYB 2018.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7857115"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("PANORAMA-Based Multi-Scale and Multi-Channel CNN for 3D Model Retrieval")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Weizhi Nie, Kun Wang, Yao Lu, Anan Liu, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Visual Communications and Image Processing, VCIP 2018.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8698722"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("A Review of Breast Cancer Detection in Medical Images")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Yao Lu, Jiayu Li, Yuting Su, An-An Liu")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Visual Communications and Image Processing, VCIP 2018.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/abstract/document/8698732/"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Attention-in-Attention Networks for Surveillance Video Understanding in Internet of Things")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Ning Xu, An-An Liu, Weizhi Nie, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Internet of Things Journal, 2018.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8141866"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v(" IPAD: Intensity Potential for Adaptive De-Quantization.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jing Liu, Guangtao Zhai, Anan Liu, Xiaokang Yang, Xibin Zhao, Chang Wen Chen")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Image Processing, TIP 2018.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8421587"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v(" Blind Quality Assessment Based on Pseudo-Reference Image")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Xiongkuo Min, Ke Gu, Guangtao Zhai, Xiaokang Yang, Chang Wen Chen")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Multimedia, TMM 2018.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8421587"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Low-Rank Multi-View Embedding Learning for Micro-Video Popularity Prediction")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Peiguang Jing, Yuting Su, Liqiang Nie, Xu Bai, Jing Liu, Meng Wang ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Knowledge and Data Engineering, TKDE 2018.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8233154"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Low-Rank Regularized Heterogeneous Tensor Decomposition for Subspace Clustering")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jing Zhang, Xinhui Li, Peiguang Jing, Jing Liu, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Signal Processing Letters, 2018.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8025385"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("A Fine-Grained Spatial-Temporal Attention Model for Video Captioning")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Yurui Qiu, Yongkang Wong, Yuting Su, Mohan Kankanhalli")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access, 2018")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8523661"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("AMFNet: An Adversarial Network for Median Filtering Detection")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Xiao Jin, Peiguang Jing, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Access, 2018.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8447546"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Sparsity-Based Image Inpainting Detection via Canonical Correlation Analysis With Low-Rank Constraints")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Xiao Jin, Yuting Su, Liang Zou, Yongwei Wang, Peiguang Jing, Z. Jane Wang")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Access, 2018.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8439932"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v(" Human Action Recognition Based on Selected Spatio-Temporal Features via Bidirectional LSTM")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Wenhui Li, Weizhi Nie, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access, 2018.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8434092"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v(" Recurrent Conditional Generative Adversarial Network for Image Deblurring")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jing Liu, Wanning Sun, Mengjie Li")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access, 2018.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8585006"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v(" Improving Bit-Depth Expansion via Context-Aware MMSE Optimization (CAMO)")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jing Liu, Wanning Sun, Peiguang Jing, Jiexiao Yu, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access, 2018.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8421587"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br")])])])],1)],1)},staticRenderFns:[]};var s=a("VU/8")({name:"Publication2018Content"},i,!1,function(t){a("62qv")},"data-v-4131ac82",null).exports,n=a("6BGy"),o={name:"publication2018",components:{HomeHeader:a("byf9").a,HomeFooter:n.a,Publication2018Content:s},methods:{myajaxs:function(){this.$axios({method:"post",url:"/publication/publication2018"}).then(function(t){console.log(t)}).catch(function(t){console.log(t)})}}},r={render:function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("Layout",[e("Header",{staticStyle:{position:"fixed",right:"0",left:"0","z-index":"1030"}},[e("home-header",{attrs:{"active-name":this.activeIndex}})],1),this._v(" "),e("Content",[e("publication2018-content")],1),this._v(" "),e("Footer",[e("home-footer")],1)],1)],1)},staticRenderFns:[]};var l=a("VU/8")(o,r,!1,function(t){a("QLm7")},"data-v-1452c0d5",null);e.default=l.exports},lxx0:function(t,e){},m0m0:function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i=a("byf9"),s={render:function(){var t=this,e=t.$createElement,i=t._self._c||e;return i("div",[i("div",{staticClass:"breadcrumb"},[i("Breadcrumb",[i("BreadcrumbItem",{attrs:{to:"/"}},[t._v("主页")]),t._v(" "),i("BreadcrumbItem",{attrs:{to:"/people"}},[t._v("团队")]),t._v(" "),i("BreadcrumbItem",[t._v("苏育挺")])],1)],1),t._v(" "),i("div",{staticClass:"content-box"},[i("div",[i("Row",[i("Col",{attrs:{span:"5"}},[i("div",{staticClass:"people-img"},[i("img",{attrs:{src:a("p4HD"),width:"143px",height:"189px"}})])]),t._v(" "),i("Col",{attrs:{span:"19"}},[i("div",{staticClass:"people-intro"},[i("span",{staticStyle:{"font-size":"23px",color:"black","font-weight":"bold"}},[t._v("苏育挺")]),i("span",{staticStyle:{"padding-left":"20px"}},[t._v("教授/博导")]),i("br"),i("br"),t._v(" "),i("span",[t._v("电气自动化与信息工程学院")]),i("br"),t._v(" "),i("span",[t._v("天津大学")]),i("br"),t._v(" "),i("span",[t._v("邮箱：ytsu@tju.edu.cn")]),i("br")])])],1)],1),t._v(" "),t._m(0),t._v(" "),t._m(1),t._v(" "),t._m(2),t._v(" "),t._m(3)])])},staticRenderFns:[function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("h2",[this._v("简    介")]),this._v(" "),e("hr",{staticClass:"research-line",staticStyle:{margin:"15px 0"}}),this._v(" "),e("span",{staticClass:"content"},[this._v("自2001年起，苏育挺任教于天津大学。现任天津大学电气自动化与信息工程学院教授。他的研究方向包括多媒体信息处理、多媒体信息安全、图像/视频压缩编码、物联网技术。")])])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",[a("h2",[t._v("论    文")]),t._v(" "),a("hr",{staticClass:"research-line",staticStyle:{margin:"15px 0"}}),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8770249"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[1]  Unsupervised Feature Learning With Graph Embedding for View-Based 3D Model Retrieval.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Yuting Su, Wenhui Li, Weizhi Nie, Dan Song, An-An Liu.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Access. 2019.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8636159"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[2]  Spatiotemporal Symmetric Convolutional Neural Network for Video Bit-Depth Enhancement.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jing Liu, Pingping Liu, Yuting Su, Peiguang Jing, Xiaokang Yang.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Multimedia. 2019.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8447210/"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[3]   Dual-Stream Recurrent Neural Network for Video Captioning.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Ning Xu, An-An Liu, Yongkang Wong, Yongdong Zhang, Weizhi Nie, Yuting Su, Mohan S.Kankanhalli.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Circuits and Systems for Video Technology. 2019.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8359393"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[4]  High-Order Temporal Correlation Model Learning for Time-Series Prediction.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Peiguang Jing, Yuting Su, Xiao Jin, Chengqian Zhang.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Cybernetics. 2019.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8353302"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[5]   A Framework of Joint Low-Rank and Sparse Regression for Image Memorability Prediction.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Peiguang Jing, Yuting Su, Liqiang Nie, Huimin Gu, Jing Liu, Meng Wang.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Circuits and Systems for Video Technology, 2019.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8523661/"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[6]   A Fine-Grained Spatial-Temporal Attention Model for Video Captioning.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Yurui Qiu, Yongkang Wong, Yuting Su, Mohan Kankanhalli.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Access. 2018.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8233154/"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[7]   Low-Rank Multi-View Embedding Learning for Micro-Video Popularity Prediction.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Peiguang Jing, Yuting Su, Liqiang Nie, Xu Bai, Jing Liu, Meng Wang.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Knowledge and Data Engineering. 2018.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8141866"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[8]   Attention-in-Attention Networks for Surveillance Video Understanding in Internet of Things.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Ning Xu, Weizhi Nie, Yuting Su, Yongkang Wong, Mohan S. Kankanhalli.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Internet of Things Journal.2018.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8025385"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[9]    Low-Rank Regularized Heterogeneous Tensor Decomposition for Subspace Clustering.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jing Zhang, Xinhui Li, Peiguang Jing, Jing Liu, Yuting Su.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Signal Processing Letters. 2018.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7857115"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[10]   View-Based 3-D Model Retrieval: A Benchmark.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Wei-Zhi Nie, Yue Gao, Yu-Ting Su.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Cybernetics. 2018.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7984862"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[11]   Modeling Temporal Information of Mitotic for Mitotic Event Detection.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Weizhi Nie, Huiyun Cheng, Yuting Su.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Big Data. 2018.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7962189"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[12]   Mitosis Detection in Phase Contrast Microscopy Image Sequences of Stem Cell Populations: A Critical Review.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Yao Lu, Mei Chen, Yu-Ting Su.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Big Data. 2017.")])])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("div",{staticClass:"publication"},[e("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7486042"}},[e("p",{staticClass:"p title"},[e("strong",[this._v("[13]   A Tensor-Driven Temporal Correlation Model for Video Sequence Classification.")])]),this._v(" "),e("p",{staticClass:"p author"},[e("i",[this._v("Jing Zhang, Chuanzhong Xu, Peiguang Jing, Chengqian Zhang, Yuting Su.")])]),this._v(" "),e("p",{staticClass:"p time"},[this._v("IEEE Transactions on Big Data. 2016.")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("div",{staticClass:"publication"},[e("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7430305"}},[e("p",{staticClass:"p title"},[e("strong",[this._v("[14]  A Tensor-Driven Temporal Correlation Model for Video Sequence Classification.")])]),this._v(" "),e("p",{staticClass:"p author"},[e("i",[this._v("An-An Liu, Wei-Zhi Nie, Yue Gao, Yu-Ting Su.")])]),this._v(" "),e("p",{staticClass:"p time"},[this._v("IEEE Transactions on Image Processing. 2016.")])])])}]};var n=a("VU/8")({name:"SuyutingContent"},s,!1,function(t){a("8Il4")},"data-v-2cc4a92e",null).exports,o={name:"suyuting",components:{HomeFooter:a("6BGy").a,SuyutingContent:n,HomeHeader:i.a},data:function(){return{activeIndex:"/people"}},methods:{myajaxs:function(){this.$axios({method:"post",url:"/people/suyuting"}).then(function(t){console.log(t)}).catch(function(t){console.log(t)})}}},r={render:function(){var t=this.$createElement,e=this._self._c||t;return e("Layout",[e("Header",{staticStyle:{position:"fixed",right:"0",left:"0","z-index":"1030"}},[e("home-header",{attrs:{"active-name":this.activeIndex}})],1),this._v(" "),e("Content",[e("suyuting-content")],1),this._v(" "),e("Footer",[e("home-footer")],1)],1)},staticRenderFns:[]};var l=a("VU/8")(o,r,!1,function(t){a("ZLST")},"data-v-1ae6a3b0",null);e.default=l.exports},mG6J:function(t,e,a){t.exports=a.p+"static/img/research5.3892067.png"},mOiL:function(t,e){},"mt/z":function(t,e){},nSAl:function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i=a("E7Bq"),s={render:function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"content-box"},[a("div",{staticClass:"content"},[a("Menu",{staticStyle:{"min-width":"600px","background-color":"rgb(245, 247, 249)"},attrs:{mode:"horizontal",theme:t.theme1,"active-name":"1"}},[a("MenuItem",{staticStyle:{width:"50%",overflow:"hidden","text-overflow":"ellipsis","white-space":"nowrap"},attrs:{name:"1",to:"/contest/contest1English"}},[a("Icon",{attrs:{type:"ios-paper"}}),t._v("\n        SHREC 2015-2020\n      ")],1),t._v(" "),a("MenuItem",{staticStyle:{width:"50%",overflow:"hidden","text-overflow":"ellipsis","white-space":"nowrap"},attrs:{name:"2",to:"/contest/contest2English"}},[a("Icon",{attrs:{type:"ios-ribbon"}}),t._v("\n        CVPR 2019 Contest on Mitosis Detection in Phase Contrast Microscopy Image Sequences\n      ")],1)],1),t._v(" "),a("div",{staticClass:"contest-content"},[a("Card",{staticStyle:{"min-width":"700px","background-color":"rgb(245, 247, 249)"}},[a("a",{attrs:{href:"https://iti-tju.org/MI3DOR20"}},[a("h2",{staticStyle:{margin:"10px 0",color:"rgb(0,82,140)","text-align":"left"}},[t._v("SHREC 2020 - Extended Monocular Image Based 3D Model Retrieval")])]),a("br"),t._v(" "),a("p",[t._v("According to our SHREC 2019 - Monocular Image Based 3D Object Retrieval track, we have extended the number of the categories from the initial 21 classes to 40 classes, resulting in a new dataset which has 40,000 images and 12,732 models. We seek for more evaluations on the performance of existing and new 3D retrieval methods using the SHREC'20 benchmark, which is more comprehensive. Especially, we would like to bring unsupervised learning to 3D retrieval based on 2D images for its significance in reality.\n          "),a("br"),a("br"),a("span",{staticStyle:{color:"rgb(0,82,140)"}},[t._v("This contest is undergoing")])])]),a("br"),a("br"),t._v(" "),a("Card",{staticStyle:{"min-width":"700px","background-color":"rgb(245, 247, 249)"}},[a("a",{attrs:{href:"https://iti-tju.org/MI3DOR19"}},[a("h2",{staticStyle:{margin:"10px 0",color:"rgb(0,82,140)","text-align":"left"}},[t._v("SHREC 2019 - Monocular Image-based 3D Model Retrieval")])]),a("br"),t._v(" "),a("p",[t._v("Monocular image based 3D object retrieval is a novel and challenging research topic in the field of 3D object retrieval. Given a RGB image captured in real world, it aims to search for relevant 3D objects from a dataset. To advance this promising research, we organize this SHREC track and build the first monocular image based 3D object retrieval benchmark by collecting 2D images from ImageNet and 3D objects from popular 3D datasets such as NTU, PSB, ModelNet40 and ShapeNet. The benchmark contains classified 21,000 2D images and 7,690 3D objects of 21 categories. This track attracted 9 groups from 4 countries and the submission of 20 runs. The evaluation results show that the supervised cross domain learning get the superior retrieval performance (Best NN is 97.4 %) by bridging the domain gap with label information. However, there is still a big challenge for unsupervised cross domain learning (Best NN is 61.2%), which is more practical for the real application.\n          "),a("br"),a("br"),a("a",{staticStyle:{color:"rgb(0,82,140)","text-decoration":"underline"},attrs:{href:"../../../static/SHREC19.pdf",download:"SHREC19.pdf"}},[t._v("[Paper Download]")])])]),a("br"),a("br"),t._v(" "),a("Card",{staticStyle:{"min-width":"700px","background-color":"rgb(245, 247, 249)"}},[a("a",{attrs:{href:"https://iti-tju.org/SHREC2016"}},[a("h2",{staticStyle:{margin:"10px 0",color:"rgb(0,82,140)","text-align":"left"}},[t._v("SHREC’16 Track: 3D Object Retrieval with Multimodal Views")])]),a("br"),t._v(" "),a("p",[t._v("In the SHREC’16 track of 3D Object Retrieval with Multimodal Views, we aim to concentrate focused research efforts on how to represent the 3D object by using multimodal views. The objective of this track is to retrieve 3D printing objects and 3D real objects by using multimodal views, which are color images and depth images for each 3D object. Different to our SHREC’15 track, our collection is composed of 605 objects, in which 200 objects including 100 3D printing objects and 100 3D real objects are selected as the queries while the others are selected as the tests. Seven groups were participated in this track and 9 runs were submitted. The evaluation results show a promising scenario about multimodal view-based 3D retrieval methods.\n          "),a("br"),a("br"),a("a",{staticStyle:{color:"rgb(0,82,140)","text-decoration":"underline"},attrs:{href:"../../../static/SHREC16.pdf",download:"SHREC16.pdf"}},[t._v("[Paper Download]")])])]),a("br"),a("br"),t._v(" "),a("Card",{staticStyle:{"min-width":"700px","background-color":"rgb(245, 247, 249)"}},[a("a",{attrs:{href:"https://iti-tju.org/SHREC2015"}},[a("h2",{staticStyle:{margin:"10px 0",color:"rgb(0,82,140)","text-align":"left"}},[t._v("SHREC’15 Track: 3D Object Retrieval with Multimodal Views")])]),a("br"),t._v(" "),a("p",[t._v("In the SHREC’15 track of 3D Object Retrieval with Multimodal Views, we aim to concentrate focused research efforts on how to represent the 3D object by using multimodal views. The objective of this track is to retrieve 3D objects by using multimodal views, which are color images and depth images for each 3D object. Our collection is composed of 505 objects, in which 311 objects are selected as the queries. Six groups were participated in this track and 26 runs were submitted for two tasks. The evaluation results show a promising scenario about multimodal view-based 3D retrieval methods, and reveal interesting insights in dealing with multimodal data.\n          "),a("br"),a("br"),a("a",{staticStyle:{color:"rgb(0,82,140)","text-decoration":"underline"},attrs:{href:"../../../static/SHREC15.pdf",download:"SHREC15.pdf"}},[t._v("[Paper Download]")])])]),a("br"),a("br")],1)],1)])},staticRenderFns:[]};var n=a("VU/8")({name:"ContestContent1en"},s,!1,function(t){a("5gt0")},"data-v-21e0597d",null).exports,o={name:"contest1English",components:{HomeFooter:a("6BGy").a,ContestContent1en:n,HomeHeaderen:i.a},data:function(){return{activeIndex:"/research"}},methods:{myajaxs:function(){this.$axios({method:"post",url:"/contest/contest1English"}).then(function(t){console.log(t)}).catch(function(t){console.log(t)})}}},r={render:function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("Layout",[e("Header",{staticStyle:{position:"fixed",right:"0",left:"0","z-index":"1030"}},[e("home-headeren",{attrs:{"active-name":"activeIndex"}})],1),this._v(" "),e("Content",[e("contest-content1en")],1),this._v(" "),e("Footer",[e("home-footer")],1)],1)],1)},staticRenderFns:[]};var l=a("VU/8")(o,r,!1,function(t){a("AflV")},"data-v-6b90a282",null);e.default=l.exports},nqWu:function(t,e){},ny3f:function(t,e){},oBQg:function(t,e){},oQOq:function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i=a("byf9"),s={render:function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"demo-split intro-new"},[a("Split",{model:{value:t.split1,callback:function(e){t.split1=e},expression:"split1"}},[a("div",{staticClass:"demo-split-pane",staticStyle:{"padding-right":"10%"},attrs:{slot:"left"},slot:"left"},[a("h2",{staticStyle:{"padding-bottom":"10px"}},[a("Icon",{attrs:{type:"ios-school"}}),t._v("  INTRODUCTION")],1),t._v(" "),a("hr",{staticClass:"research-line",staticStyle:{margin:"10px 0 15px 0"}}),t._v(" "),a("p",[t._v("Institute of Television and Image Information, Tianjin University is dedicated to multimedia content understanding, retrieval, security and communication research."),a("br"),t._v(" "),a("br"),t._v("\n        History:"),a("br"),t._v("\n        In early February 1970, Tianjin University Radio Department as the main part of the second group to undertake the development of color television system test broadcast vehicle task."),a("br"),t._v("\n        In 1979, with the approval of the Ministry of Education, Tianjin University established the Television Research Institute on the basis of the core members of the color TV research group."),a("br"),t._v("\n        In 1992, it was upgraded to Institute of Television and Image Information with the approval of the Ministry of Education.\n        "),a("br"),t._v(" "),a("br"),t._v("\n        Our research interests widely cover the related problems in computer vision, machine learning, signal processing and information retrieval and particularly focus in the following areas："),a("br"),t._v("\n        1. Computer Vision And Machine Learning"),a("br"),t._v("\n        2. Biomedical Image Analysis"),a("br"),t._v("\n        3. Multimedia Understanding And Retrieval"),a("br"),t._v("\n        4. Media Security And Forensics"),a("br")])]),t._v(" "),a("div",{staticClass:"demo-split-pane",staticStyle:{"padding-left":"10%"},attrs:{slot:"right"},slot:"right"},[a("h2",{staticStyle:{"padding-bottom":"10px"}},[a("Icon",{attrs:{type:"ios-list-box"}}),t._v("  NEWS")],1),t._v(" "),a("hr",{staticClass:"research-line",staticStyle:{margin:"10px 0 15px 0"}}),t._v(" "),a("p",[a("Icon",{attrs:{type:"md-arrow-forward"}}),t._v("Heyu Zhou  attended the 27th ACM International Conference on Multimedia in Nice, France on 20th October , 2019.")],1),a("br"),t._v(" "),a("p",[a("Icon",{attrs:{type:"md-arrow-forward"}}),t._v("Two papers are accepted by ACM Multimedia 2019 (Oral).")],1),a("br"),t._v(" "),a("p",[a("Icon",{attrs:{type:"md-arrow-forward"}}),t._v("One paper is accepted by NeurIPS 2019.")],1),a("br"),t._v(" "),a("p",[a("Icon",{attrs:{type:"md-arrow-forward"}}),t._v("One paper is accepted by IEEE Transactions on Circuits and Systems for Video Technology (TCSVT) 2019.")],1),a("br"),t._v(" "),a("p",[a("Icon",{attrs:{type:"md-arrow-forward"}}),t._v("One paper is accepted by IEEE Transactions on Multimedia (TMM).")],1),a("br"),t._v(" "),a("p",[a("Icon",{attrs:{type:"md-arrow-forward"}}),t._v("One paper is accepted by IEEE Journal of Biomedical and Health Informatics (JBHI) 2019.")],1)])])],1)},staticRenderFns:[]};var n=a("VU/8")({name:"IntroNewsen",data:function(){return{split1:.5}}},s,!1,function(t){a("eWhT")},"data-v-e4cd34aa",null).exports,o=a("00Uz"),r=a("6BGy"),l={name:"homeEnglish",components:{HomeHeaderen:a("E7Bq").a,HomeFooter:r.a,ResearchMenuen:o.a,IntroNewsen:n,HomeHeader:i.a},data:function(){return{activeIndex:"/"}},methods:{myajaxs:function(){this.$axios({method:"post",url:"/"}).then(function(t){console.log(t)}).catch(function(t){console.log(t)})}}},c={render:function(){var t=this,e=t.$createElement,i=t._self._c||e;return i("div",{staticClass:"layout"},[i("Layout",[i("Header",{staticStyle:{position:"fixed",left:"0",right:"0","z-index":"1030"}},[i("home-headeren")],1),t._v(" "),i("Content",[i("div",{staticClass:"blank"}),t._v(" "),i("div",{staticStyle:{"margin-top":"50px"}},[i("Carousel",{attrs:{autoplay:"",loop:"","autoplay-speed":"2500"},model:{value:t.value2,callback:function(e){t.value2=e},expression:"value2"}},[i("CarouselItem",[i("div",{staticClass:"demo-carousel"},[i("img",{attrs:{src:a("habg"),height:"756px",width:"100%"}})])]),t._v(" "),i("CarouselItem",[i("div",{staticClass:"demo-carousel"},[i("img",{attrs:{src:a("zH0C"),height:"756px",width:"100%"}})])])],1),t._v(" "),i("intro-newsen"),t._v(" "),i("research-menuen")],1)]),t._v(" "),i("Footer",[i("home-footer",{staticStyle:{"background-color":"rgb(23, 31, 36)"}})],1)],1)],1)},staticRenderFns:[]};var p=a("VU/8")(l,c,!1,function(t){a("fo5S")},"data-v-61e39fd0",null);e.default=p.exports},oiQJ:function(t,e){},osZ1:function(t,e){},p4HD:function(t,e,a){t.exports=a.p+"static/img/suyuting.864468a.jpg"},pPG9:function(t,e){},pdB7:function(t,e,a){t.exports=a.p+"static/img/research3-2.bee7b70.jpg"},pryb:function(t,e){},qWVv:function(t,e,a){t.exports=a.p+"static/img/research1-1.c8cd910.png"},qdnP:function(t,e){},rNb9:function(t,e){},"so+g":function(t,e){},szrY:function(t,e){},tQnf:function(t,e,a){t.exports=a.p+"static/img/zhangchuntian.86cf347.jpg"},tVeH:function(t,e){},uZ9r:function(t,e){},ucMM:function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i=a("byf9"),s={render:function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"content-box"},[a("Row",[a("Col",{attrs:{span:"6"}},[a("Menu",{staticClass:"menu",staticStyle:{width:"200px","background-color":"rgb(245, 247, 249)","margin-top":"50px"},attrs:{theme:"light","active-name":"1"}},[a("MenuItem",{attrs:{name:"1",to:"/publication/publication2019"}},[a("Icon",{attrs:{type:"md-document"}}),t._v("\n          2019\n        ")],1),t._v(" "),a("MenuItem",{attrs:{name:"2",to:"/publication/publication2018"}},[a("Icon",{attrs:{type:"md-document"}}),t._v("\n          2018\n        ")],1),t._v(" "),a("MenuItem",{attrs:{name:"3",to:"/publication/publication2017"}},[a("Icon",{attrs:{type:"md-document"}}),t._v("\n          2017\n        ")],1),t._v(" "),a("MenuItem",{attrs:{name:"4",to:"/publication/publication2016"}},[a("Icon",{attrs:{type:"md-document"}}),t._v("\n          2016\n        ")],1)],1)],1),t._v(" "),a("Col",{attrs:{span:"18"}},[a("div",{staticClass:"education"},[a("div",{staticClass:"education-block"},[a("h3"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Dual-Level Embedding Alignment Network for 2D Image-Based 3D Object Retrieval")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Heyu Zhou, An-An Liu, Weizhi Nie")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("ACM International Conference on Multimedia, MM 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://acmmm.org/accepted-papers/"}},[t._v("Link")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("MMJN: Multi-Modal Joint Networks for 3D Shape Recognition")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Weizhi Nie, Qi Liang, An-An Liu, Zhendong Mao, Yangyang Li")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("ACM International Conference on Multimedia, MM 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://acmmm.org/accepted-papers/"}},[t._v("Link")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Meta-Transfer Learning for Few-Shot Learning")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Qianru Sun, Yaoyao Liu, Tat-Seng Chua, Bernt Schiele")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE International Conference on Computer Vision and Pattern Recognition, CVPR 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"http://openaccess.thecvf.com/content_CVPR_2019/papers/Sun_Meta-Transfer_Learning_for_Few-Shot_Learning_CVPR_2019_paper.pdf"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Learning to Self-Train for Semi-Supervised Few-Shot Classification")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Xinzhe Li, Qianru Sun, Yaoyao Liu, Shibao Zheng, Qin Zhou, Tat-Seng Chua, Bernt Schiele")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("33rd Conference on Neural Information Processing Systems, NeurIPS 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://arxiv.org/pdf/1906.00562.pdf"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("SHREC 2019-Monocular Image Based 3D Model Retrieval")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Wenhui Li, Anan Liu, Weizhi Nie, Dan Song, Yuqian Li, Weijie Wang, Shu Xiang, Heyu Zhou, et al.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("3D Shape Retrieval Contest, Eurographics Workshop on 3D Object Retrieval, 2019")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://pdfs.semanticscholar.org/7a86/b957168093f1da829e252ba4a4a0faea24f8.pdf"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Hierarchical Deep Neural Network for Image Captioning")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Yuting Su, Yuqian Li, Ning Xu, An-An Liu")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("Neural Processing Letters, 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://link.springer.com/content/pdf/10.1007%2Fs11063-019-09997-5.pdf"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Multi-Guiding Long-Short Term Memory for Video Captioning")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Ning Xu, An-An Liu, Weizhi Nie, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("Multimedia Systems, 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://link.springer.com/article/10.1007%2Fs00530-018-0598-5"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Multi-Domain and Multi-Task Learning for Human Action Recognition")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Ning Xu, Weizhi Nie, Yuting Su, Yongdong Zhang")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Image Processing, TIP 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8476540"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Scene Graph Captioner: Image Captioning Based on Structural Visual Representation")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Ning Xu, An-An Liu, Jing Liu, Weizhi Nie, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("Journal of Visual Communication and Image Representation, 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://www.sciencedirect.com/science/article/pii/S1047320318303535"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Scene Graph Captioner: Image Captioning Based on Structural Visual Representation")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Ning Xu, An-An Liu, Jing Liu, Weizhi Nie, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("Journal of Visual Communication and Image Representation, 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://www.sciencedirect.com/science/article/pii/S1047320318303535"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Sequential Saliency Guided Deep Neural Network for Joint Mitosis Identification and Localization in Time-Lapse Phase Contrast Microscopy Images")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Yao Lu, An-An Liu, Mei Chen, Weizhi Nie, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Journal of Biomedical and Health Informatics, JBHI 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8846748/"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("3D Object Retrieval Based on Multi-View Latent Variable Model")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Weizhi Nie, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Circuits and Systems for Video Technology, TCSVT 2019")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8303699"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Hyper-Clique Graph Matching and Applications")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Weizhi Nie, An-An Liu, Yue Gao, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Circuits and Systems for Video Technology, TCSVT 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8401899"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("BE-CALF: Bit-Depth Enhancement by Concatenating All Level Features of DNN")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jing Liu, Wanning Sun, Yuting Su, Peiguang Jing, Xiaokang Yang")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Image Processing, TIP 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8713480"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Spatiotemporal Symmetric Convolutional Neural Network for Video Bit-Depth Enhancement.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jing Liu, Pingping Liu, Yuting Su, Peiguang Jing, Xiaokang Yang.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Multimedia, TMM 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8703748"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Wearable Computing for Internet of Things: A Discriminant Approach for Human Activity Recognition.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Wei Lu, Fugui Fan, Jinghui Chu, Peiguang Jing, Yuting Su.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Internet of Things Journal, 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8480641"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("High-Order Temporal Correlation Model Learning for Time-Series Prediction.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Peiguang Jing, Yuting Su, Xiao Jin, Chengqian Zhang")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Cybernetics, TCYB 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8359393"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("A Framework of Joint Low-Rank and Sparse Regression for Image Memorability Prediction.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Peiguang Jing, Yuting Su, Liqiang Nie, Huimin Gu, Jing Liu, Meng Wang ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Circuits and Systems for Video Technology, TCSVT 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8359393"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Dual-Stream Recurrent Neural Network for Video Captioning.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Ning Xu, An-An Liu, Yongkang Wong, Yongdong Zhang, Weizhi Nie, Yuting Su, Mohan S. Kankanhalli.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Circuits and Systems for Video Technology, TCSVT 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8359393"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("End-to-End Visual Domain Adaptation Network for Cross-Domain 3D CPS Data Retrieval.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Shu Xiang, Wei-Zhi Nie, Dan Song.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access, 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8812718"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Fast Context-Adaptive Bit-Depth Enhancement via Linear Interpolation")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Jing Liu, Bing Yang, Yuting Su, Pingping Liu")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access, 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8703748"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("Unsupervised Feature Learning With Graph Embedding for View-Based 3D Model Retrieval")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Yuting Su, Wenhui Li, Weizhi Nie, Dan Song, An-An Liu")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access, 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8770249"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br"),t._v(" "),a("p",{staticClass:"p title"},[a("strong",[t._v("SRNet: Structured Relevance Feature Learning Network From Skeleton Data for Human Action Recognition")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Weizhi Nie, Wei Wang, Xiangdong Huang")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access, 2019.")]),t._v(" "),a("p",{staticClass:"p materials"},[t._v("["),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8832127"}},[t._v("Paper")]),t._v("]")]),t._v(" "),a("br")])])])],1)],1)},staticRenderFns:[]};var n=a("VU/8")({name:"Publication2019Content"},s,!1,function(t){a("qdnP")},"data-v-1641e41c",null).exports,o={name:"publication2019",components:{HomeFooter:a("6BGy").a,Publication2019Content:n,HomeHeader:i.a},data:function(){return{activeIndex:"/publication"}},methods:{myajaxs:function(){this.$axios({method:"post",url:"/publication/publication2019"}).then(function(t){console.log(t)}).catch(function(t){console.log(t)})}}},r={render:function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("Layout",[e("Header",{staticStyle:{position:"fixed",right:"0",left:"0","z-index":"1030"}},[e("home-header",{attrs:{"active-name":this.activeIndex}})],1),this._v(" "),e("Content",[e("publication2019-content")],1),this._v(" "),e("Footer",[e("home-footer")],1)],1)],1)},staticRenderFns:[]};var l=a("VU/8")(o,r,!1,function(t){a("Ahpy")},"data-v-75c03ca6",null);e.default=l.exports},usVh:function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i=a("E7Bq"),s={render:function(){var t=this,e=t.$createElement,i=t._self._c||e;return i("div",[i("div",{staticClass:"breadcrumb"},[i("Breadcrumb",[i("BreadcrumbItem",{attrs:{to:"/"}},[t._v("HOME")]),t._v(" "),i("BreadcrumbItem",{attrs:{to:"/people"}},[t._v("PEOPLE")]),t._v(" "),i("BreadcrumbItem",[t._v("Weizhi Nie")])],1)],1),t._v(" "),i("div",{staticClass:"content-box"},[i("div",[i("Row",[i("Col",{attrs:{span:"5"}},[i("div",{staticClass:"people-img"},[i("img",{attrs:{src:a("+Dnu"),width:"143px",height:"189px"}})])]),t._v(" "),i("Col",{attrs:{span:"19"}},[i("div",{staticClass:"people-intro"},[i("span",{staticStyle:{"font-size":"23px",color:"black","font-weight":"bold"}},[t._v("Weizhi Nie")]),i("span",{staticStyle:{"padding-left":"20px"}},[t._v("Associate Professor")]),i("br"),i("br"),t._v(" "),i("span",[t._v("School of Electrical and Information Engineering")]),i("br"),t._v(" "),i("span",[t._v("Tianjin University, China")]),i("br"),t._v(" "),i("span",[t._v("Email：weizhinie@tju.edu.cn")]),i("br")])])],1)],1),t._v(" "),t._m(0),t._v(" "),t._m(1)])])},staticRenderFns:[function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("h2",[this._v("Introduction")]),this._v(" "),e("hr",{staticClass:"research-line",staticStyle:{margin:"15px 0"}}),this._v(" "),e("span",{staticClass:"content"},[this._v("Weizhi Nie has been teaching at tianjin university since 2014. He is an associate professor in the school of electrical automation and information engineering, Tianjin University. His research interests include 3d model retrieval, computer vision, machine learning, and multimedia information processing")])])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",[a("h2",[t._v("Publication")]),t._v(" "),a("hr",{staticClass:"research-line",staticStyle:{margin:"15px 0"}}),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8832127"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[1]   SRNet: Structured Relevance Feature Learning Network From Skeleton Data for Human Action Recognition.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Weizhi Nie, Wei Wang, Xiangdong Huang.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access. 2019.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8812718"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[2]   End-to-End Visual Domain Adaptation Network for Cross-Domain 3D CPS Data Retrieval.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Shu Xiang, Wei-Zhi Nie, Dan Song.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access. 2019.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8770249"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[3]   Unsupervised Feature Learning With Graph Embedding for View-Based 3D Model Retrieval.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Yuting Su, Wenhui Li, Weizhi Nie, Dan Song, An-An Liu.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access. 2019.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8447210"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[4]   Dual-Stream Recurrent Neural Network for Video Captioning.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Ning Xu, An-An Liu, Yongkang Wong, Yongdong Zhang, Weizhi Nie, Yuting Su, Mohan Kankanhalli.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Circuits and Systems for Video Technology. 2019.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8401899"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[5]  Hyper-Clique Graph Matching and Applications.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Wei-Zhi Nie, An-An Liu, Yue Gao, Yu-Ting Su.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Circuits and Systems for Video Technology. 2018.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8303699"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[6]  3D Object Retrieval Based on Multi-View Latent Variable Model.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Wei-Zhi Nie, Yu-Ting Su.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Circuits and Systems for Video Technology. 2018.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8698722"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[7]   PANORAMA-Based Multi-Scale and Multi-Channel CNN for 3D Model Retrieval.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Weizhi Nie, Kun Wang, Yao Lu, Anan Liu, Yuting Su.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Visual Communications and Image Processing (VCIP). Taichung, Taiwan, China. 2018.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8434092"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[8]  Human Action Recognition Based on Selected Spatio-Temporal Features via Bidirectional LSTM.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Wenhui Li, Weizhi Nie, Yuting Su.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Access. 2018.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8141866"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[9]  Attention-in-Attention Networks for Surveillance Video Understanding in Internet of Things.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Ning Xu, An-An Liu, Wei-Zhi Nie, Yu-Ting Su.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Internet of Things Journal. 2017.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7857115"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[10]  View-Based 3-D Model Retrieval: A Benchmark.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Wei-Zhi Nie, Yue Gao, Yu-Ting Su.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Cybernetics. 2017.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7984862"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[11]  Modeling Temporal Information of Mitotic for Mitotic Event Detection.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("Weizhi Nie, Huiyun Cheng, Yuting Su.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Big Data. 2017.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7885509"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[12]   Multi-Grained Random Fields for Mitosis Identification in Time-Lapse Phase Contrast Microscopy Image Sequences.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Jinhui Tang, Weizhi Nie, Yuting Su.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Medical Imaging. 2017.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7515012"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[13]   Benchmarking a Multimodal and Multiview and Interactive Dataset for Human Action Recognition.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Ning Xu, Wei-Zhi Nie, Yu-Ting Su, Yongkang Wong, Mohan Kankanhalli.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Cybernetics. 2016.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7423818"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[14]   Hierarchical Clustering Multi-Task Learning for Joint Human Action Grouping and Recognition.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Yu-Ting Su, Wei-Zhi Nie, Mohan Kankanhalli.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Pattern Analysis and Machine Intelligence. 2016.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7789661"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[15]   3D Convolutional Networks-Based Mitotic Event Detection in Time-Lapse Phase Contrast Microscopy Image Sequences of Stem Cell Populations.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Yu-Ting Su, Wei-Zhi Nie, Mohan Kankanhalli.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW). Las Vegas, NV, USA. 2016.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7430305"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[16]   Multi-Modal Clique-Graph Matching for View-Based 3D Model Retrieval.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Wei-Zhi Nie, Yue Gao, Yu-Ting Su.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("IEEE Transactions on Image Processing. 2016.")])])])])}]};var n=a("VU/8")({name:"NieweizhiContenten"},s,!1,function(t){a("XJiA")},"data-v-e021a98c",null).exports,o={name:"nieweizhiEnglish",components:{HomeFooter:a("6BGy").a,NieweizhiContenten:n,HomeHeaderen:i.a},data:function(){return{activeIndex:"/people"}},methods:{myajaxs:function(){this.$axios({method:"post",url:"/people/nieweizhiEnglish"}).then(function(t){console.log(t)}).catch(function(t){console.log(t)})}}},r={render:function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("Layout",[e("Header",{staticStyle:{position:"fixed",right:"0",left:"0","z-index":"1030"}},[e("home-headeren",{attrs:{"active-name":this.activeIndex}})],1),this._v(" "),e("Content",[e("nieweizhi-contenten")],1),this._v(" "),e("Footer",[e("home-footer")],1)],1)],1)},staticRenderFns:[]};var l=a("VU/8")(o,r,!1,function(t){a("Kqwg")},"data-v-42d80e4e",null);e.default=l.exports},uzhG:function(t,e,a){t.exports=a.p+"static/img/logo.afc8309.jpg"},v57D:function(t,e,a){t.exports=a.p+"static/img/research1-4.8dfe2a2.png"},vkyI:function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i=a("bOdI"),s=a.n(i),n=a("byf9"),o=a("6BGy"),r=a("biSA"),l={render:function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"demo-split intro-new"},[a("Split",{model:{value:t.split1,callback:function(e){t.split1=e},expression:"split1"}},[a("div",{staticClass:"demo-split-pane",staticStyle:{"padding-right":"10%"},attrs:{slot:"left"},slot:"left"},[a("h2",{staticStyle:{"padding-bottom":"10px"}},[a("Icon",{attrs:{type:"ios-school"}}),t._v("  实验室简介")],1),t._v(" "),a("hr",{staticClass:"research-line",staticStyle:{margin:"10px 0 15px 0"}}),t._v(" "),a("p",[t._v("天津大学电视与图像信息研究所，致力于多媒体内容理解、检索、安全与通信的研究。"),a("br"),t._v("\n        历史沿革："),a("br"),t._v("\n        1970年2月初，以天津大学无线电系为主体的会战二组承担了研制彩电制式试验转播车任务。"),a("br"),t._v("\n        1979年，经教育部批准，天津大学在彩电科研组核心人员的基础上成立了电视研究所。"),a("br"),t._v("\n        1992年，经教育部批准升格为电视与图像信息研究所（简称电视所）是中国高校中唯一经过国家教育部批准设立的从事电视技术研究的科研单位。"),a("br"),t._v(" "),a("br"),t._v("\n        我们的研究内容广泛，包括计算机视觉、机器学习、信号处理和信息检索等领域的相关问题，主要集中在以下几个方面:"),a("br"),t._v("\n        1. 计算机视觉和机器学习"),a("br"),t._v("\n        2. 生物医学图像分析"),a("br"),t._v("\n        3.多媒体理解与检索"),a("br"),t._v("\n        4. 媒体安全和取证"),a("br")])]),t._v(" "),a("div",{staticClass:"demo-split-pane",staticStyle:{"padding-left":"10%"},attrs:{slot:"right"},slot:"right"},[a("h2",{staticStyle:{"padding-bottom":"10px"}},[a("Icon",{attrs:{type:"ios-list-box"}}),t._v("  新闻")],1),t._v(" "),a("hr",{staticClass:"research-line",staticStyle:{margin:"10px 0 15px 0"}}),t._v(" "),a("p",[a("Icon",{attrs:{type:"md-arrow-forward"}}),t._v("Heyu Zhou  attended the 27th ACM International Conference on Multimedia in Nice, France on 20th October , 2019.")],1),a("br"),t._v(" "),a("p",[a("Icon",{attrs:{type:"md-arrow-forward"}}),t._v("Two papers are accepted by ACM Multimedia 2019 (Oral).")],1),a("br"),t._v(" "),a("p",[a("Icon",{attrs:{type:"md-arrow-forward"}}),t._v("One paper is accepted by NeurIPS 2019.")],1),a("br"),t._v(" "),a("p",[a("Icon",{attrs:{type:"md-arrow-forward"}}),t._v("One paper is accepted by IEEE Transactions on Circuits and Systems for Video Technology (TCSVT) 2019.")],1),a("br"),t._v(" "),a("p",[a("Icon",{attrs:{type:"md-arrow-forward"}}),t._v("One paper is accepted by IEEE Transactions on Multimedia (TMM).")],1),a("br"),t._v(" "),a("p",[a("Icon",{attrs:{type:"md-arrow-forward"}}),t._v("One paper is accepted by IEEE Journal of Biomedical and Health Informatics (JBHI) 2019.")],1)])])],1)},staticRenderFns:[]};var c,p=(c={name:"home",components:{IntroNews:a("VU/8")({name:"IntroNews",data:function(){return{split1:.5}}},l,!1,function(t){a("oiQJ")},"data-v-cb2e56e6",null).exports,ResearchMenu:r.a,HomeFooter:o.a,HomeHeader:n.a},data:function(){return{activeIndex:"/"}}},s()(c,"data",function(){return{value2:0}}),s()(c,"methods",{myajaxs:function(){this.$axios({method:"post",url:"/home"}).then(function(t){console.log(t)}).catch(function(t){console.log(t)})}}),c),v={render:function(){var t=this,e=t.$createElement,i=t._self._c||e;return i("div",{staticClass:"layout"},[i("Layout",[i("Header",{staticStyle:{position:"fixed","z-index":"1030",left:"0",right:"0"}},[i("home-header",{attrs:{"active-name":t.activeIndex}})],1),t._v(" "),i("Content",[i("div",{staticClass:"blank"}),t._v(" "),i("div",{staticStyle:{"margin-top":"50px"}},[i("Carousel",{attrs:{autoplay:"",loop:"","autoplay-speed":"2500"},model:{value:t.value2,callback:function(e){t.value2=e},expression:"value2"}},[i("CarouselItem",[i("div",{staticClass:"demo-carousel"},[i("img",{attrs:{src:a("habg"),height:"756x",width:"1740px"}})])]),t._v(" "),i("CarouselItem",[i("div",{staticClass:"demo-carousel"},[i("img",{attrs:{src:a("zH0C"),height:"756x",width:"1740px"}})])])],1),t._v(" "),i("intro-news"),t._v(" "),i("research-menu")],1)]),t._v(" "),i("Footer",[i("home-footer",{staticStyle:{"background-color":"rgb(23, 31, 36)"}})],1)],1)],1)},staticRenderFns:[]};var u=a("VU/8")(p,v,!1,function(t){a("bUi/")},"data-v-5cdcc490",null);e.default=u.exports},vwFX:function(t,e){},wLWH:function(t,e){},wZmW:function(t,e){},xAkj:function(t,e,a){t.exports=a.p+"static/img/research3-4.ee61656.jpg"},xTw1:function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i=a("byf9"),s={render:function(){var t=this,e=t.$createElement,i=t._self._c||e;return i("div",{staticClass:"content-box"},[i("div",{staticClass:"breadcrumb"},[i("Breadcrumb",[i("BreadcrumbItem",{attrs:{to:"/home"}},[t._v("主页")]),t._v(" "),i("BreadcrumbItem",{attrs:{to:"/research"}},[t._v("研究方向")]),t._v(" "),i("BreadcrumbItem",[t._v("跨媒体内容理解")])],1)],1),t._v(" "),i("div",[i("h1",[t._v("    "),i("Icon",{attrs:{type:"ios-fastforward"}}),t._v("  跨媒体内容理解")],1),t._v(" "),t._m(0)]),t._v(" "),i("Collapse",{staticClass:"collapse",staticStyle:{"font-size":"13px"},model:{value:t.value1,callback:function(e){t.value1=e},expression:"value1"}},[i("Panel",{attrs:{name:"1"}},[t._v("\n      1.简介\n      "),i("p",{staticClass:"me-collapse-content",attrs:{slot:"content"},slot:"content"},[t._v("\n                近年来，随着网络技术飞速发展，特别是公共安全监控系统和网络视频分享平台的普及，视觉数据呈现出爆炸性增长。在大数据时代，如何对视觉信息中包含的复杂语义进行自动解析，实现从独立的语义概念识别到类人的自然语言描述生成，是当前计算机视觉和人工智能领域的研究热点，对于公共安全风险防范、网络文化市场监管等多个领域具有重要的应用价值。M2I实验室-跨媒体内容理解组主要关注于视觉语义概念建模、视觉关系检测与识别、视觉类人描述等研究方向。\n      ")])]),t._v(" "),i("Panel",{attrs:{name:"2"}},[t._v("\n      2.视觉语义概念建模\n      "),i("p",{staticClass:"me-collapse-content",attrs:{slot:"content"},slot:"content"},[i("span",[t._v("\n                  视觉语义概念广泛涉及目标、属性、场景、人体动作等。相对于静态的目标检测和属性识别等，人体动作同时具有视觉表形和运动动态多样性，因此，我们着重研究了比较具有挑战性的人体动作识别任务。\n        ")]),i("br"),t._v(" "),i("br"),t._v(" "),i("img",{staticClass:"me-img",attrs:{src:a("qWVv"),width:"800px"}}),i("br"),i("br"),t._v(" "),i("span",[t._v("        近年来，随着拍摄角度与拍摄模态的变化，单视角或单模态提供的信息相对片面，因此如何将多视角多模态数据中互补的动作信息进行有效的融合，进一步提升动作识别准确率，依然是一个亟待解决的难题。同时，多任务学习通过融合各个任务之间的关联信息，可以共同提高识别的准确率以及模型整体的泛化能力，但是，由于多视角和多模态的数据都具有独特的特征分布，传统的多任务学习方法并不能直接处理多视角和多模态两类条件下的动作识别问题。\n         为了解决如上问题，我们面向多视角和多模态的多域信息，基于多任务学习理论进行多语义潜在关联挖掘，提出一种多域多任务动作识别算法（MDMTL），从语义概念关联性出发，引导并探索了多视角和多模态两类因素下的多语义概念联合建模问题。如图1-2所示，该算法通过学习得到一组嵌入式矩阵，将多域特征分别强制映射到公共的稀疏空间，该空间极大地削弱了类内差异，使得每个子集的动作样本都具有相似的嵌入表征。我们设计了整体学习策略，通过预评估每个样本得到具有差异性的权重，从而融合同一子集特征得到对应的多域不变性样本表征。我们使用多任务算法来探索“语义-语义”间关联性的挖掘，构建分类模型，同时使用 范数项和设计了稀疏约束项。最后，将特征提取与分类建模整合到统一的目标函数中，通过对目标方程的学习及参数优化，得到MDMTL算法模型。\n        ")]),i("br"),i("br"),t._v(" "),i("img",{staticClass:"me-img",attrs:{src:a("dr0C"),width:"800px"}}),i("br"),i("br")])]),t._v(" "),i("Panel",{attrs:{name:"3"}},[t._v("\n      3.视觉关系检测与识别\n      "),i("p",{staticClass:"me-collapse-content",attrs:{slot:"content"},slot:"content"},[i("span",[t._v("\n                  视觉关系识别任务不仅需要识别出图像中的目标物体及其位置（detection），还需要识别目标之间的关系（relationship）。一张图像中的关系通常表示为主谓宾三元组形式——<目标1-关系-目标2>，关系包含空间关系（clock-above-person），动词关系（person1-talk-person2）和比较级关系（person1-taller-person2）;等。如图所示，输入一张图片，输出为目标及其位置边框，以及目标之间的关系<person-on-motorcycle>。\n        ")]),i("br"),i("br"),t._v(" "),i("img",{staticClass:"me-img",attrs:{src:a("GIfL")}}),i("br"),i("br"),t._v(" "),i("span",[t._v("\n                  视觉关系通过将目标置于一个上下文语义环境中，提供了对图像场景的综合理解，在联系计算机视觉和自然语言方面展示出了巨大的作用。因此，视觉关系识别是图像理解的基础，能够推动很多研究课题的发展。例如，视觉描述任务中往往包含目标之间关系的描述；视觉问答任务的一些问题也包含目标之间的关系；图像检索任务也需要根据自然语言中描述的关系或者图像中蕴含的视觉关系来进行检索。\n              为了充分地挖掘图像/视频中的语义信息，大部分研究者将知识图谱（scene graph）作为视觉关系识别的主要表征形式。如图2-2所示，知识图谱由节点和边组成，其中，每个节点对应图像的目标物体，每个边对应图像中两两目标间的关系。\n        ")]),i("br"),i("br"),t._v(" "),i("img",{staticClass:"me-img",attrs:{src:a("v57D")}}),i("br"),i("br"),t._v(" "),i("span",[t._v("\n                  现有的视觉关系识别算法基于“目标对”所涉及的图像区域进行建模，从而实现目标和关系的识别。但是，视觉关系识别需要模型对整个图像的上下文信息进行全局的理解，而不应仅仅关注在局部“目标对”区域的建模。如图2-3所示，图像场景的上下文信息有助于局部目标和关系的识别。例如，识别<人>和&It摩托车>的关系&It骑>，“目标对”<人-摩托车>的周边上下文视觉信息<头盔>和<车辆>，可以为识别关系<骑>提供充分的依据。相似地，通过融合上下文信息<头盔>、<裤子>和<背包>，也能有效地提高目标<人>的识别准确率。因此，对图像场景的上下文信息进行深入的挖掘有利于视觉关系识别模型性能的提升。\n        ")]),i("br"),i("br"),t._v(" "),i("img",{staticClass:"me-img",attrs:{src:a("CFP7"),width:"800px"}}),i("br"),i("br"),t._v(" "),i("span",[t._v("\n                  因此，我们提出一个多层级上下文信息建模算法（Multi-Scale Context Modeling, MSCM），该方法通过联合挖掘与整合目标层级和区域层级的上下文信息，实现基于多层级上下文建模的知识图谱生成。如图2-4所示，首先，本课题针对目标级和区域级的上下文信息，分别设计一种基于RNN的编码模块，通过“目标到目标”，“区域到区域”、“目标到区域”以及“区域到目标”之间的信息交互式建模，灵活地探索与提取每个层级的上下文隐态信息。然后，通过融合目标/区域级的上下文隐态信息与目标/区域的视觉特征，实现知识图谱的生成。\n        ")]),i("br"),i("br"),t._v(" "),i("img",{staticClass:"me-img",attrs:{src:a("L08/"),width:"800px"}}),i("br"),i("br")])]),t._v(" "),i("Panel",{attrs:{name:"4"}},[t._v("\n      4.视觉类人描述\n      "),i("p",{staticClass:"me-collapse-content",attrs:{slot:"content"},slot:"content"},[i("span",[t._v("\n                    近年来，计算机视觉这一领域取得了长足的进展。为了让机器能够像人类一样“看”懂周围的世界，研究人员设计了大量的人工特征去描述一个物体或者事件，并且提出了各种模型去识别这些人为设计的特征。几年前，当我们谈论视觉理解时，我们能做的只是给一幅图像或一段视频自动打上一些相互独立的语义标签。而今天，我们已经可以借用深度学习的发展将这一基础任务再往前推进一步，即将单个的标签变成一段和当前视觉内容相关，并且通顺连贯的自然语言描述，即视觉类人描述任务。视觉类人描述是一个集计算机视觉和自然语言处理的交叉领域。不仅需要对视觉内容进行深入的建模，而且需要对自然语言（词汇、短语、句子）进行处理，使之与相应的视觉内容匹配。\n                但是，现有的基于多模态数据分析的视频类人描述模型只是在同一个模块中简单地探究了视觉特征和语义概念的隐态信息（hidden states）。但是，多模态数据之间的分布往往是异步的，如图3-1所示，视觉模态特征的改变常常比语义模态特征的改变更加敏感。因此，现有方法中，以帧为单位的模态特征拼接术（比如，串联和线性融合）将不足以充分挖掘每个模态中蕴含的视觉/语义信息。\n        ")]),i("br"),i("br"),t._v(" "),i("img",{staticClass:"me-img",attrs:{src:a("Vavi"),width:"800px"}}),i("br"),i("br"),t._v(" "),i("span",[t._v("\n                  因此，为了探索和融合异步多模态数据的隐态信息，我们提出基于多模异步状态融合的视频类人解析算法（Dual-Stream RNN，DS-RNN）。如图3-2所示，该方法可同时挖掘和整合视觉流（视觉特征）和语义流（图像语义）的隐态信息。首先，我们设计了一种基于LSTM的模态编码模块，即，注意力细粒度编码模块（Attentive Multi-Grained Encoder，AMGE），该模块借助视频（全局）语义概念来强化每个模态局部特征的学习，从而灵活地探索每个模态流的隐态信息。然后，我们设计了双流解码单元，通过融合上述两模块输出的异步且互补的序列隐态信息，将其解析为视频描述语句。直观来讲，当生成描述单词时，DS-RNN可通过互补的模态信息，灵活地侧重在视觉/语义模态的局部特征上。\n        ")]),i("br"),i("br"),t._v(" "),i("img",{staticClass:"me-img",attrs:{src:a("TLpD")}}),i("br"),i("br")])])],1)],1)},staticRenderFns:[function(){var t=this.$createElement,e=this._self._c||t;return e("p",{staticClass:"research-people"},[e("span",[this._v("团队成员")]),e("br"),this._v(" "),e("span",[e("a",{attrs:{href:"/#/people/liuanan"}},[this._v("刘安安（教授）")]),this._v("    "),e("a",{attrs:{href:"/#/people/xuning"}},[this._v("徐宁（预聘教师)")]),e("br"),this._v("\n           田宏硕（博士生） 王彦辉（博士生）"),e("br"),this._v("\n           逯子慕（硕士生）  李杰思（硕士生） 翟英晨（硕士生）\n         ")])])}]};var n=a("VU/8")({name:"ResearchOneContent"},s,!1,function(t){a("tVeH")},"data-v-10d0f726",null).exports,o={name:"research1",components:{HomeFooter:a("6BGy").a,ResearchOneContent:n,HomeHeader:i.a},data:function(){return{activeIndex:"/research"}},methods:{myajaxs:function(){this.$axios({method:"post",url:"/research/research1"}).then(function(t){console.log(t)}).catch(function(t){console.log(t)})}}},r={render:function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("Layout",[e("Header",{staticStyle:{position:"fixed",right:"0",left:"0","z-index":"1030"}},[e("home-header",{attrs:{"active-name":this.activeIndex}})],1),this._v(" "),e("Content",[e("research-one-content")],1),this._v(" "),e("Footer",[e("home-footer")],1)],1)],1)},staticRenderFns:[]};var l=a("VU/8")(o,r,!1,function(t){a("9JLm")},"data-v-e557ed74",null);e.default=l.exports},xVlF:function(t,e){},xt5J:function(t,e,a){t.exports=a.p+"static/img/research5-3.47766e1.png"},yuGA:function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i=a("byf9"),s={render:function(){var t=this,e=t.$createElement,i=t._self._c||e;return i("div",{staticClass:"content-box"},[i("div",{staticClass:"breadcrumb"},[i("Breadcrumb",[i("BreadcrumbItem",{attrs:{to:"/home"}},[t._v("主页")]),t._v(" "),i("BreadcrumbItem",{attrs:{to:"/research"}},[t._v("研究方向")]),t._v(" "),i("BreadcrumbItem",[t._v("面向普通用户的三维人体重建")])],1)],1),t._v(" "),i("div",[i("h1",[t._v("    "),i("Icon",{attrs:{type:"ios-fastforward"}}),t._v("  面向普通用户的三维人体重建")],1),t._v(" "),t._m(0)]),t._v(" "),i("Collapse",{staticClass:"collapse",staticStyle:{"font-size":"13px"},model:{value:t.value1,callback:function(e){t.value1=e},expression:"value1"}},[i("Panel",{attrs:{name:"1"}},[t._v("\n      1.简介\n      "),i("p",{staticClass:"me-collapse-content",attrs:{slot:"content"},slot:"content"},[t._v("\n                由于游戏、动画等应用的需求，三维人体重建一直是计算机图形学的重要研究课题。近几十年来，研究员们围绕这一课题提出了多种方法，取得了丰硕的成果。由于三维人体模型在游戏、动画中具有较高的应用价值，所以可以容忍这些方法在采集设备、方式和重建效率上付出较高的代价。然而对于虚拟试衣的个人用户来说，这些方法在方便性及快捷性方面存在很多不足：（1）采集设备诸如扫描仪、Kinect，并不是普通用户的常用设备；（2）采集方式要求用户穿紧身衣或穿着很少，给用户带来了不便与尴尬；及（3）迭代优化人体模型使之贴合输入数据的方法非常耗时。\n      ")])]),t._v(" "),i("Panel",{attrs:{name:"2"}},[t._v("\n      2. 针对着装图像的衣服尺码估计\n      "),i("p",{staticClass:"me-collapse-content",attrs:{slot:"content"},slot:"content"},[i("span",[t._v("\n                    合适的衣服尺寸对提高网络购衣的交易成功率至关重要。然而，用户通过网络买到合身的衣服并不容易。一方面，用户需要在私密空间用卷尺较专业地测量自己的身材尺寸（随着身材改变，用户需要测量多次）。另一方面，由于不同国家不同品牌的衣服尺码标准不一致，用户往往要手动查看商品网页上的尺码表，询问卖家或查看多条评论信息。因此，我们需要方便可靠的衣服尺码推荐方法。通过参考服装设计类文献及主流电商平台，我们采用了与衣服尺码密切相关的20个人体尺寸，包括三维人体的长度信息及围度信息。根据这20个常用的人体尺寸，通过程序自动查询商家尺码表便可得到衣服的尺码。\n          ")]),i("br"),t._v(" "),i("span",[t._v("\n                    进行网络购衣的人群大部分都是普通用户，为了给普通用户提供方便，我们以着装人体图像（即照片中的人穿着日常衣服）作为输入，既不需要诸如Kinect这样普通用户不常用的设备，又避免了用户穿着较少的不便与尴尬。然而，这也给估计身材尺寸引入了一些困难。如何去除衣服对身材的影响，如何有效且高效地从图像获取身材信息，都是我们要解决的难点。如图1所示，我们以人体标志点为桥梁连接输入图像与目标身材尺寸。基于构建的着装人体数据库，我们采用基于随机蕨的提升树回归方法根据着装人体剪影回归二维标志点运动。根据回归得到的二维标志点，我们计算与身材尺寸对应的标志点对之间的距离，并利用训练集学习二维标志点距离与对应身材尺寸之间的关系。\n          ")]),i("br"),t._v(" "),i("br"),t._v(" "),i("img",{staticClass:"me-img",attrs:{src:a("26uN"),width:"800px"}}),i("br"),i("br")])]),t._v(" "),i("Panel",{attrs:{name:"3"}},[t._v("\n      3. 针对着装图像的三维人体重建\n      "),i("p",{staticClass:"me-collapse-content",attrs:{slot:"content"},slot:"content"},[i("span",[t._v("\n                    虚拟试衣系统为用户省去了真实世界试衣的繁琐，提供了宝贵的视觉信息及衣服尺码建议，提升用户在购衣时的真实感和沉浸度。目前虚拟试衣系统面临三大难点：（1）高效的基于物理的布料仿真方法；（2）真实的布料物理属性；及（3）准确的用户三维人体模型。我们针对第三个难点，提出了一个快速高效的针对着装图像的三维人体重建方法。\n          ")]),i("br"),t._v(" "),i("span",[t._v("\n                    如图2所示，我们的方法经历了三维标志点回归及三维人体重建两个阶段。我们使用含有三维未着装及着装人体对的数据库制造训练样本（着装人体剪影，初始三维标志点及目标三维标志点）。目标三维标志点是预先定义好的，与人体身材密切相关的一组标志点，初始三维标志点为随机选取的其他人体的三维标志点。我们提出了一个有效的刻画三维人体标志点与着装人体剪影关系的特征描述，并训练一系列级联回归算子驱动三维标志点运动。在测试阶段，根据训练结果首先从着装人体剪影中回归三维标志点，然后这些三维标志点被用来作为约束求解SCAPE人体参数，进而重构出三维人体模型。\n          ")]),i("br"),i("br"),t._v(" "),i("img",{staticClass:"me-img",attrs:{src:a("hYxp")}}),i("br"),i("br")])]),t._v(" "),i("Panel",{attrs:{name:"4"}},[t._v("\n      4. 面向普通用户的便捷三维人体重建\n      "),i("p",{staticClass:"me-collapse-content",attrs:{slot:"content"},slot:"content"},[i("span",[t._v("\n                      我们面向普通用户开发了一个对用户友好的三维人体重建工具，使得普通用户可以更快更方便地获得他们的三维人体模型，以满足虚拟试衣的需求。我们使用Grabcut方法从照片中提取着装人体前景，我们允许用户放大缩小图像，且可以根据初步的分割结果增添新的暗示前景或背景的线条输入。接着分割出的人体轮廓被调整至虚拟相机配置下的应有的大小及位置，因此避免了相机标定操作，给用户带来更多的便利。我们训练了一系列的回归算子从着装人体剪影直接回归人体参数。既不需要耗时的匹配对应点过程，也不需要迭代优化求解人体参数。人体参数回归过程在一个普通的安卓手机上耗时仅1.26秒。虽然为了获得更高的重建效率，牺牲了一定的精度，但我们的结果依然满足普通用户试衣对尺寸的容忍程度。\n          ")]),i("br"),t._v(" "),i("span",[t._v("\n                      我们面向普通用户开发了一个对用户友好的三维人体重建工具，使得普通用户可以更快更方便地获得他们的三维人体模型，以满足虚拟试衣的需求。我们使用Grabcut方法从照片中提取着装人体前景，我们允许用户放大缩小图像，且可以根据初步的分割结果增添新的暗示前景或背景的线条输入。接着分割出的人体轮廓被调整至虚拟相机配置下的应有的大小及位置，因此避免了相机标定操作，给用户带来更多的便利。我们训练了一系列的回归算子从着装人体剪影直接回归人体参数。既不需要耗时的匹配对应点过程，也不需要迭代优化求解人体参数。人体参数回归过程在一个普通的安卓手机上耗时仅1.26秒。虽然为了获得更高的重建效率，牺牲了一定的精度，但我们的结果依然满足普通用户试衣对尺寸的容忍程度。\n          ")]),i("br"),i("br"),t._v(" "),i("img",{staticClass:"me-img",attrs:{src:a("Vavi"),width:"800px"}}),i("br"),i("br"),t._v(" "),i("span",[t._v("\n                    图3展示了普通用户如何使用本章的方法获得他们的定制化三维人体模型及未来针对虚拟试衣的应用。用户仅需要一个移动设备，首先用户被拍摄正面及侧面两张照片，其次他们输入身高及选择衣服类型，然后交互式地抠图，最后仅需1.26秒便可获得定制化的三维人体。随着布料仿真技术的发展及布料物理属性获取方法的成熟，我们重建的三维人体可用于虚拟试衣。在不久的将来，当我们网上购衣时，我们不但可以获得衣服尺码推荐，还可以看到自己的虚拟化身在虚拟试衣间的穿衣效果。如图3右方橙色区域所示，一方面我们可以看到自己的虚拟化身穿着不同衣服，摆出多样化姿势的视觉效果，有助于我们挑选心仪的衣服款式。另一方面，我们可以通过着装后的衣服松紧图（图中红色表示衣服紧致，绿色表示衣服宽松）来选择合适的衣服尺码。便捷的三维人体重建技术对虚拟试衣系统的普及具有重要意义。\n          ")]),i("br"),i("br"),t._v(" "),i("img",{staticClass:"me-img",attrs:{src:a("3ofm")}}),i("br"),i("br")])]),t._v(" "),i("Panel",{attrs:{name:"5"}},[t._v("\n      5. 论文\n      "),i("p",{staticClass:"me-collapse-content",attrs:{slot:"content"},slot:"content"},[i("span",[t._v("\n                      1. Song, D., Tong, R., Chang, J., Yang, X., Tang, M., & Zhang, J. J. 3D Body Shapes Estimation from Dressed-Human Silhouettes. Computer Graphics Forum,2016."),i("br"),t._v("\n                    2. Song, D., Tong, R., Du, J., Zhang, Y., & Jin, Y. Data-Driven 3-D Human Body Customization With a Mobile Device. IEEE Access,2018."),i("br"),t._v("\n                    3.\tSong, D., Tong, R., Chang, J., Wang, T., Du, J., Tang, M., & Zhang, J. J. Clothes Size Prediction from Dressed-Human Silhouettes. International Workshop on Next Generation Computer Animation Techniques,2017."),i("br"),t._v("\n                    4.\tSong, D., Jin, Y., Wang, T., Li, C., Tong, R., & Chang, J. A Semantic Parametric Model for 3D Human Body Reshaping. International Conference on E-Learning and Games,2018."),i("br")]),i("br")])])],1)],1)},staticRenderFns:[function(){var t=this.$createElement,e=this._self._c||t;return e("p",{staticClass:"research-people"},[e("span",[this._v("团队成员")]),e("br"),this._v(" "),e("span",[e("a",{attrs:{href:"/#/people/songdan"}},[this._v("宋丹（助理教授）")]),e("br"),this._v("\n             李天宝（硕士生）  张婷（硕士生） 赵小倩（硕士生）\n           ")])])}]};var n=a("VU/8")({name:"ResearchFourContent"},s,!1,function(t){a("2Da8")},"data-v-03090fc2",null).exports,o={name:"research4",components:{HomeFooter:a("6BGy").a,ResearchFourContent:n,HomeHeader:i.a},data:function(){return{activeIndex:"/research"}},methods:{myajaxs:function(){this.$axios({method:"post",url:"/research/research4"}).then(function(t){console.log(t)}).catch(function(t){console.log(t)})}}},r={render:function(){var t=this.$createElement,e=this._self._c||t;return e("div",[e("Layout",[e("Header",{staticStyle:{position:"fixed",right:"0",left:"0","z-index":"1030"}},[e("home-header",{attrs:{"active-name":this.activeIndex}})],1),this._v(" "),e("Content",[e("research-four-content")],1),this._v(" "),e("Footer",[e("home-footer")],1)],1)],1)},staticRenderFns:[]};var l=a("VU/8")(o,r,!1,function(t){a("E7wq")},"data-v-b80a3b3e",null);e.default=l.exports},zBUN:function(t,e,a){t.exports=a.p+"static/img/研究方向1头图.43888e0.jpg"},zH0C:function(t,e,a){t.exports=a.p+"static/img/zhouheyu.66dbff0.jpg"},zeZq:function(t,e,a){"use strict";Object.defineProperty(e,"__esModule",{value:!0});var i=a("E7Bq"),s={render:function(){var t=this,e=t.$createElement,i=t._self._c||e;return i("div",[i("div",{staticClass:"breadcrumb"},[i("Breadcrumb",[i("BreadcrumbItem",{attrs:{to:"/"}},[t._v("HOME")]),t._v(" "),i("BreadcrumbItem",{attrs:{to:"/peopleEnglish"}},[t._v("PEOPLE")]),t._v(" "),i("BreadcrumbItem",[t._v("An-an Liu")])],1)],1),t._v(" "),i("div",{staticClass:"content-box"},[i("div",[i("Row",[i("Col",{attrs:{span:"5"}},[i("div",{staticClass:"people-img"},[i("img",{attrs:{src:a("3gOL"),width:"143px",height:"189px"}})])]),t._v(" "),i("Col",{attrs:{span:"19"}},[i("div",{staticClass:"people-intro"},[i("span",{staticStyle:{"font-size":"23px",color:"black","font-weight":"bold"}},[t._v("An-An Liu")]),t._v(" "),i("span",{staticStyle:{"padding-left":"20px"}},[t._v("Professor")]),i("br"),i("br"),t._v(" "),i("span",[t._v("School of Electrical and Information Engineering")]),i("br"),t._v(" "),i("span",[t._v("Tianjin University, China")]),i("br"),t._v(" "),i("span",[t._v("Email：anan0422@gmail.com")]),i("br")])])],1)],1),t._v(" "),t._m(0),t._v(" "),t._m(1)])])},staticRenderFns:[function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",[a("h2",[t._v("Introduction")]),t._v(" "),a("hr",{staticClass:"research-line",staticStyle:{margin:"15px 0"}}),t._v(" "),a("span",{staticClass:"content"},[t._v("03/2010-present，School of Electrical Automation and Information Engineering, Department of Electronic Information Engineering, Tianjin University"),a("br"),t._v("\n      03/2016-03/2017  Visiting Scholar, National University of Singapore, School of Computer Science  Tutor:Mohan Kankanhalli (IEEE Fellow)"),a("br"),t._v("\n      09/2008-11/2009  Visiting Scholar,Carnegie Mellon University, Institute of Computer Science, Tutor: Takeo Kanade (IEEE/ACM/AAAI Fellow)"),a("br"),t._v("\n      05/2009-11/2009  Visiting Researcher, Intel Pittsburgh Research Center, Mentor:Dr. Mei Chen"),a("br"),t._v("\n      09/2001-03/2010  Ph.D candidate,School of Electronic Information Engineering, Tianjin University\n      ")])])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",[a("h2",[t._v("Publication")]),t._v(" "),a("hr",{staticClass:"research-line",staticStyle:{margin:"15px 0"}}),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7423818"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[1]  Hierarchical Clustering Multi-Task Learning for Joint Human Action Grouping and Recognition.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("  An-An Liu, Yu-Ting Su, Wei-Zhi Nie, Mohan Kankanhalli ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Pattern Analysis and Machine Intelligence., Vol. 39, No.1, pp:102-114, 2017. ")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7430305"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[2]   Multi-modal clique-graph matching for view-based 3D model retrieval")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" An-An Liu, Wei-Zhi Nie, Yue-Gao , Yu-Ting Su.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Image Processing, vol. 25, no. 5, pp. 2103–2116, 2016. ")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://www.ncbi.nlm.nih.gov/pubmed/27429453"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[3]  Benchmarking a Multimodal and Multiview and Interactive Dataset for Human Action Recognition.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" An-An Liu, Ning Xu, Wei-Zhi Nie, Yu-Ting Su, Yongkang Wong, Kankanhalli M.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Cybernetics, Vol. 47, No.7, pp:1781-1794,2017.")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://www.ncbi.nlm.nih.gov/pubmed/25167566"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[4]  Multipe/Single-View Human Action Recognition via Part-induced Multi-task Structural Learning.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" An-An Liu, Yu-Ting Su, Ping-Ping Jia, Zan Gao,Tong Hao, Zhao-Xuan Yang ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Cybernetics, Vol. 45, No. 6, pp. 1194-1208, 2015.  ")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7857115"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[5]  View-Based 3-D Model Retrieval: A Benchmark")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-An Liu, Wei-Zhi Nie, Yue Gao, Yu-Ting Su.")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Cybernetics, Vol. 48, No.3, pp:916-928,2018. ")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8476540"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[6]  Multi-Domain and Multi-Task Learning for Human Action Recognition")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" An-An Liu, Ning Xu,Wei-Zhi Nie, Yu-Ting Su, Yong-Dong Zhang ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Image Processing, Vol. 28, No. 2, pp. 853-867, 2019. ")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7885509"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[7]  Multi-Grained Random Fields for Mitosis Identification in Time-Lapse Phase Contrast Microscopy Image Sequences.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" An-An Liu, Jinhui Tang, Weizhi Nie, Yuting Su ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("  IEEE Transactions on Medical Imaging, Vol.36, No.8, pp:1699-1710, 2017. ")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/6026949"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[8]  A Semi-Markov Model for Mitosis Segmentation in Time-Lapse Phase Contrast Microscopy Image Sequences of Stem Cell Populations")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("  An-An Liu, Kang Li, Takeo Kanade ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Medical Imaging,  Vol. 31, No. 2, pp. 359-369, 2012. ")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8303699"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[9]  3D Object Retrieval Based on Multi-View Latent Variable Model")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("  An-An Liu, Wei-Zhi Nie, Yu-Ting Su ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("  IEEE Transactions on Circuits and Systems for Video Technology，2018  ")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8401899"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[10]  Hyper-Clique Graph Matching and Applications")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" Wei-Zhi Nie, An-An Liu, Yue Gao, Yu-Ting Su ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Circuits and Systems for Video Technology，2018  ")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8447210"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[11]   Dual-Stream Recurrent Neural Network for Video Captioning")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" Ning Xu, An-An Liu, Yongkang Wong, Yongdong Zhang, Weizhi Nie, Yuting Su,Mohan Kankanhalli")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Circuits and Systems for Video Technology，2018  ")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8141866"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[12]    Attention-In-Attention Networks for Surveillance Video Understanding in IoT")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" Ning Xu, An-An Liu, Wei-Zhi Nie, Yu-Ting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Internet of Thing Journal,Vol.5, No.5, pp.3419-3429, 2018 ")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7962189"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[13]   Mitosis Detection in Phase Contrast Microscopy Image Sequences of Stem Cell Populations: A Critical Review")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" An-An Liu, Yao Lu, Mei Chen, Yu-Ting Su ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" IEEE Transactions on Big Data, Vol. 3, No. 4, pp. 443-457,  2017 ")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://www.sciencedirect.com/science/article/pii/S1077314217300735"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[14]   Hierarchical & Multimodal Video Captioning: Discovering and Transferring Multimodal Knowledge for Vision to Language")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("An-AnLiu, Ning Xu, Yongkang Wong, Junnan Li, Yu-Ting Su, Mohan Kankanhalli")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" Computer Vision and Image Understanding, vol. 163, pp. 113-125, 2017")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/7299080"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[15]   Clique-graph Matching by Preserving Global & Local Structure")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" Wei-Zhi Nie, An-An Liu, Zan Gao, Yu-Ting Su ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("  IEEE Conference on Computer Vision and Pattern Recognition,4503-4510,2015. ")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://www.ijcai.org/proceedings/2018/115"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[16]   Cross-Domain 3D Model Retrieval via Visual Domain Adaption")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" Anan Liu, Shu Xiang, Wenhui Li, Weizhi Nie, Yuting Su")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v("  International Joint Conference on Artificial Intelligence, 2018 ")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8844130"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[17]    Multi-Level Policy and Reward Reinforcement Learning for Image Captioning")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v("  Ning Xu， Hanwang Zhang， An-An Liu， Weizhi Nie, Yuting Su, Jie Nie, Yongdong Zhang ")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" International Joint Conference on Artificial Intelligence, 2018 ")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://www.ijcai.org/proceedings/2018/127"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[18]   Hierarchical Graph Structure Learning for Multi-View 3D Model Retrieval")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" Yuting Su, Wenhui Li, Anan Liu, Weizhi Nie")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" International Joint Conference on Artificial Intelligence, 2018 ")])])]),t._v(" "),a("div",{staticClass:"publication"},[a("a",{attrs:{href:"https://www.intechopen.com/books/medical-imaging/a-hierarchical-framework-for-mitosis-detection-in-time-lapse-phase-contrast-microscopy-image-sequenc"}},[a("p",{staticClass:"p title"},[a("strong",[t._v("[19]   A Hierarchical Framework for Mitosis Detection in Time-Lapse Phase Contrast Microscopy Image Sequences of Stem Cell Populations.")])]),t._v(" "),a("p",{staticClass:"p author"},[a("i",[t._v(" Anan Liu, Kang Li")])]),t._v(" "),a("p",{staticClass:"p time"},[t._v(" Medical Imaging (Chapter 17)，Dec. 2011 (ISBN 978-953-307-774-1)")])])])])}]};var n=a("VU/8")({name:"LiuananContenten"},s,!1,function(t){a("xVlF")},"data-v-88d5ce7c",null).exports,o={name:"liuananEnglish",components:{HomeFooter:a("6BGy").a,LiuananContenten:n,HomeHeaderen:i.a},data:function(){return{activeIndex:"/people"}},methods:{myajaxs:function(){this.$axios({method:"post",url:"/people/liuananEnglish"}).then(function(t){console.log(t)}).catch(function(t){console.log(t)})}}},r={render:function(){var t=this.$createElement,e=this._self._c||t;return e("Layout",[e("Header",{staticStyle:{position:"fixed",right:"0",left:"0","z-index":"1030"}},[e("home-headeren",{attrs:{"active-name":this.activeIndex}})],1),this._v(" "),e("Content",[e("liuanan-contenten")],1),this._v(" "),e("Footer",[e("home-footer")],1)],1)},staticRenderFns:[]};var l=a("VU/8")(o,r,!1,function(t){a("mOiL")},"data-v-a13b5bd0",null);e.default=l.exports}},["NHnr"]);
//# sourceMappingURL=app.00ee5ee8ebb5c922e530.js.map